{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phoenix as px\n",
    "import litellm\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the secret key from environment variables\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "session = px.launch_app()\n",
    "\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "\n",
    "endpoint = \"http://127.0.0.1:6006/v1/traces\"\n",
    "tracer_provider = TracerProvider()\n",
    "tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter(endpoint)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the package path to the system path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Determine the absolute path to the 'src' directory\n",
    "package_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
    "\n",
    "# Add the package path to the system path if it's not already included\n",
    "if package_path not in sys.path:\n",
    "    sys.path.append(package_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation.litellm import LiteLLMInstrumentor\n",
    "LiteLLMInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple single message completion call\n",
    "litellm.completion(model=\"gpt-3.5-turbo\", \n",
    "                   messages=[{\"content\": \"What's the capital of China?\", \"role\": \"user\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple message conversation completion call with added param\n",
    "litellm.completion(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{ \"content\": \"Hello, I want to bake a cake\",\"role\": \"user\"},\n",
    "                      { \"content\": \"Hello, I can pull up some recipes for cakes.\",\"role\": \"assistant\"},\n",
    "                      { \"content\": \"No actually I want to make a pie\",\"role\": \"user\"},],\n",
    "            temperature=0.7\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple message conversation acompletion call with added params\n",
    "await litellm.acompletion(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{ \"content\": \"Hello, I want to bake a cake\",\"role\": \"user\"},\n",
    "                      { \"content\": \"Hello, I can pull up some recipes for cakes.\",\"role\": \"assistant\"},\n",
    "                      { \"content\": \"No actually I want to make a pie\",\"role\": \"user\"},],\n",
    "            temperature=0.7,\n",
    "            max_tokens=20\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litellm.completion_with_retries(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{ \"content\": \"What's the highest grossing film ever\",\"role\": \"user\"}]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litellm.embedding(model='text-embedding-ada-002', input=[\"good morning from litellm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await litellm.aembedding(model='text-embedding-ada-002', input=[\"good morning from litellm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litellm.image_generation(model='dall-e-2', prompt=\"cute baby otter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await litellm.aimage_generation(model='dall-e-2', prompt=\"cute baby otter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LiteLLMInstrumentor().uninstrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litellm.embedding(model='text-embedding-ada-002', input=[\"good morning from litellm\"])\n",
    "await litellm.acompletion(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{ \"content\": \"Hello, I want to bake a cake\",\"role\": \"user\"},\n",
    "                      { \"content\": \"Hello, I can pull up some recipes for cakes.\",\"role\": \"assistant\"},\n",
    "                      { \"content\": \"No actually I want to make a pie\",\"role\": \"user\"},],\n",
    "            temperature=0.7,\n",
    "            max_tokens=20\n",
    "        )\n",
    "litellm.completion(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{ \"content\": \"Hello, I want to bake a cake\",\"role\": \"user\"},\n",
    "                      { \"content\": \"Hello, I can pull up some recipes for cakes.\",\"role\": \"assistant\"},\n",
    "                      { \"content\": \"No actually I want to make a pie\",\"role\": \"user\"},],\n",
    "            temperature=0.7\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LiteLLMInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "litellm.embedding(model='text-embedding-ada-002', input=[\"good morning from litellm\"])\n",
    "await litellm.acompletion(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{ \"content\": \"Hello, I want to bake a cake\",\"role\": \"user\"},\n",
    "                      { \"content\": \"Hello, I can pull up some recipes for cakes.\",\"role\": \"assistant\"},\n",
    "                      { \"content\": \"No actually I want to make a pie\",\"role\": \"user\"},],\n",
    "            temperature=0.7,\n",
    "            max_tokens=20\n",
    "        )\n",
    "litellm.completion(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{ \"content\": \"Hello, I want to bake a cake\",\"role\": \"user\"},\n",
    "                      { \"content\": \"Hello, I can pull up some recipes for cakes.\",\"role\": \"assistant\"},\n",
    "                      { \"content\": \"No actually I want to make a pie\",\"role\": \"user\"},],\n",
    "            temperature=0.7\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openinference-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
