{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElevenLabs Text-to-Speech Instrumentation Example\n",
    "\n",
    "This notebook demonstrates how to use OpenInference instrumentation with ElevenLabs TTS API, sending traces to Arize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install elevenlabs arize-otel python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Environment Variables\n",
    "\n",
    "Copy `.env.example` to `.env` and fill in your keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Arize OTel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from arize.otel import register\n",
    "\n",
    "tracer_provider = register(\n",
    "    space_id=os.environ[\"ARIZE_SPACE_ID\"],\n",
    "    api_key=os.environ[\"ARIZE_API_KEY\"],\n",
    "    project_name=os.environ.get(\"ARIZE_PROJECT\", \"elevenlabs-demo\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrument ElevenLabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openinference.instrumentation.elevenlabs import ElevenLabsInstrumentor\n",
    "\n",
    "ElevenLabsInstrumentor().instrument(tracer_provider=tracer_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-to-Speech: Convert (Sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from elevenlabs import ElevenLabs\n",
    "\n",
    "client = ElevenLabs(api_key=os.environ[\"ELEVEN_API_KEY\"])\n",
    "\n",
    "# Generate speech - returns audio bytes\n",
    "audio = client.text_to_speech.convert(\n",
    "    voice_id=\"JBFqnCBsd6RMkjVDRZzb\",  # George voice\n",
    "    text=\"Hello! This is a test of ElevenLabs text to speech.\",\n",
    "    model_id=\"eleven_multilingual_v2\",\n",
    ")\n",
    "\n",
    "# Collect audio bytes\n",
    "audio_bytes = b\"\".join(audio)\n",
    "print(f\"Generated {len(audio_bytes)} bytes of audio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-to-Speech: Stream (Sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream audio chunks\n",
    "audio_stream = client.text_to_speech.stream(\n",
    "    voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n",
    "    text=\"This demonstrates streaming audio generation.\",\n",
    "    model_id=\"eleven_multilingual_v2\",\n",
    ")\n",
    "\n",
    "chunks = []\n",
    "for chunk in audio_stream:\n",
    "    chunks.append(chunk)\n",
    "\n",
    "print(f\"Received {len(chunks)} audio chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-to-Speech: Async Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from elevenlabs import AsyncElevenLabs\n\nasync_client = AsyncElevenLabs(api_key=os.environ[\"ELEVEN_API_KEY\"])\n\nasync def async_tts_example():\n    # Note: convert() returns an async generator directly, no await needed\n    audio = async_client.text_to_speech.convert(\n        voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n        text=\"This is an async text to speech call.\",\n        model_id=\"eleven_multilingual_v2\",\n    )\n    audio_bytes = b\"\".join([chunk async for chunk in audio])\n    print(f\"Async generated {len(audio_bytes)} bytes of audio\")\n\nawait async_tts_example()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-to-Speech with Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get audio with character-level timestamps\n",
    "response = client.text_to_speech.convert_with_timestamps(\n",
    "    voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n",
    "    text=\"Hello world!\",\n",
    "    model_id=\"eleven_multilingual_v2\",\n",
    ")\n",
    "\n",
    "for item in response:\n",
    "    if hasattr(item, 'audio_base64') and item.audio_base64:\n",
    "        print(f\"Audio chunk received\")\n",
    "    if hasattr(item, 'alignment') and item.alignment:\n",
    "        print(f\"Alignment: {item.alignment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Uninstrument when done (optional):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElevenLabsInstrumentor().uninstrument()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}