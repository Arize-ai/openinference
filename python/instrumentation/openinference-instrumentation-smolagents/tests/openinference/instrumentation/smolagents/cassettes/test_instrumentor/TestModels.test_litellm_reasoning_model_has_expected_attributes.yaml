interactions:
- request:
    body: ''
    headers: {}
    method: GET
    uri: https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json
  response:
    body:
      string: "{\n    \"sample_spec\": {\n        \"max_tokens\": \"LEGACY parameter.
        set to max_output_tokens if provider specifies it. IF not set to max_input_tokens,
        if provider specifies it.\",\n        \"max_input_tokens\": \"max input tokens,
        if the provider specifies it. if not default to max_tokens\",\n        \"max_output_tokens\":
        \"max output tokens, if the provider specifies it. if not default to max_tokens\",\n
        \       \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"output_cost_per_reasoning_token\": 0.0,\n        \"litellm_provider\":
        \"one of https://docs.litellm.ai/docs/providers\",\n        \"mode\": \"one
        of: chat, embedding, completion, image_generation, audio_transcription, audio_speech,
        image_generation, moderation, rerank\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_web_search\": true,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.0,\n            \"search_context_size_medium\":
        0.0,\n            \"search_context_size_high\": 0.0\n        },\n        \"file_search_cost_per_1k_calls\":
        0.0,\n        \"file_search_cost_per_gb_per_day\": 0.0,\n        \"vector_store_cost_per_gb_per_day\":
        0.0,\n        \"computer_use_input_cost_per_1k_tokens\": 0.0,\n        \"computer_use_output_cost_per_1k_tokens\":
        0.0,\n        \"code_interpreter_cost_per_session\": 0.0,\n        \"supported_regions\":
        [\n            \"global\",\n            \"us-west-2\",\n            \"eu-west-1\",\n
        \           \"ap-southeast-1\",\n            \"ap-northeast-1\"\n        ],\n
        \       \"deprecation_date\": \"date when the model becomes deprecated in
        the format YYYY-MM-DD\"\n    },\n    \"omni-moderation-latest\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        0,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"moderation\"\n
        \   },\n    \"omni-moderation-latest-intents\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        0,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"moderation\"\n
        \   },\n    \"omni-moderation-2024-09-26\": {\n        \"max_tokens\": 32768,\n
        \       \"max_input_tokens\": 32768,\n        \"max_output_tokens\": 0,\n
        \       \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"moderation\"\n
        \   },\n    \"gpt-4\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        3e-05,\n        \"output_cost_per_token\": 6e-05,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"gpt-4.1\": {\n
        \       \"max_tokens\": 32768,\n        \"max_input_tokens\": 1047576,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        8e-06,\n        \"input_cost_per_token_batches\": 1e-06,\n        \"output_cost_per_token_batches\":
        4e-06,\n        \"cache_read_input_token_cost\": 5e-07,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/batch\",\n            \"/v1/responses\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_native_streaming\": true\n    },\n    \"gpt-4.1-2025-04-14\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 1047576,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 2e-06,\n
        \       \"output_cost_per_token\": 8e-06,\n        \"input_cost_per_token_batches\":
        1e-06,\n        \"output_cost_per_token_batches\": 4e-06,\n        \"cache_read_input_token_cost\":
        5e-07,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_pdf_input\": true,\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true\n    },\n    \"gpt-4.1-mini\": {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\":
        1047576,\n        \"max_output_tokens\": 32768,\n        \"input_cost_per_token\":
        4e-07,\n        \"output_cost_per_token\": 1.6e-06,\n        \"input_cost_per_token_batches\":
        2e-07,\n        \"output_cost_per_token_batches\": 8e-07,\n        \"cache_read_input_token_cost\":
        1e-07,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_pdf_input\": true,\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true\n    },\n    \"gpt-4.1-mini-2025-04-14\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 1047576,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 4e-07,\n        \"output_cost_per_token\":
        1.6e-06,\n        \"input_cost_per_token_batches\": 2e-07,\n        \"output_cost_per_token_batches\":
        8e-07,\n        \"cache_read_input_token_cost\": 1e-07,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/batch\",\n            \"/v1/responses\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_native_streaming\": true\n    },\n    \"gpt-4.1-nano\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 1047576,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 1e-07,\n
        \       \"output_cost_per_token\": 4e-07,\n        \"input_cost_per_token_batches\":
        5e-08,\n        \"output_cost_per_token_batches\": 2e-07,\n        \"cache_read_input_token_cost\":
        2.5e-08,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_pdf_input\": true,\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true\n    },\n    \"gpt-4.1-nano-2025-04-14\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 1047576,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        4e-07,\n        \"input_cost_per_token_batches\": 5e-08,\n        \"output_cost_per_token_batches\":
        2e-07,\n        \"cache_read_input_token_cost\": 2.5e-08,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/batch\",\n            \"/v1/responses\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_native_streaming\": true\n    },\n    \"gpt-4o\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 2.5e-06,\n
        \       \"output_cost_per_token\": 1e-05,\n        \"input_cost_per_token_batches\":
        1.25e-06,\n        \"output_cost_per_token_batches\": 5e-06,\n        \"cache_read_input_token_cost\":
        1.25e-06,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"watsonx/ibm/granite-3-8b-instruct\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        1024,\n        \"input_cost_per_token\": 0.0002,\n        \"output_cost_per_token\":
        0.0002,\n        \"litellm_provider\": \"watsonx\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_parallel_function_calling\": false,\n        \"supports_vision\":
        false,\n        \"supports_audio_input\": false,\n        \"supports_audio_output\":
        false,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_system_messages\": true\n    },\n    \"watsonx/mistralai/mistral-large\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1e-05,\n        \"litellm_provider\": \"watsonx\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_tool_choice\": true,\n        \"supports_parallel_function_calling\":
        false,\n        \"supports_vision\": false,\n        \"supports_audio_input\":
        false,\n        \"supports_audio_output\": false,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_system_messages\":
        true\n    },\n    \"gpt-4o-search-preview-2025-03-11\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 2.5e-06,\n        \"output_cost_per_token\":
        1e-05,\n        \"input_cost_per_token_batches\": 1.25e-06,\n        \"output_cost_per_token_batches\":
        5e-06,\n        \"cache_read_input_token_cost\": 1.25e-06,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"gpt-4o-search-preview\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 2.5e-06,\n
        \       \"output_cost_per_token\": 1e-05,\n        \"input_cost_per_token_batches\":
        1.25e-06,\n        \"output_cost_per_token_batches\": 5e-06,\n        \"cache_read_input_token_cost\":
        1.25e-06,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_web_search\": true,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.03,\n            \"search_context_size_medium\":
        0.035,\n            \"search_context_size_high\": 0.05\n        }\n    },\n
        \   \"gpt-4.5-preview\": {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\":
        128000,\n        \"max_output_tokens\": 16384,\n        \"input_cost_per_token\":
        7.5e-05,\n        \"output_cost_per_token\": 0.00015,\n        \"input_cost_per_token_batches\":
        3.75e-05,\n        \"output_cost_per_token_batches\": 7.5e-05,\n        \"cache_read_input_token_cost\":
        3.75e-05,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4.5-preview-2025-02-27\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 7.5e-05,\n        \"output_cost_per_token\":
        0.00015,\n        \"input_cost_per_token_batches\": 3.75e-05,\n        \"output_cost_per_token_batches\":
        7.5e-05,\n        \"cache_read_input_token_cost\": 3.75e-05,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2025-07-14\"\n    },\n    \"gpt-4o-audio-preview\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 2.5e-06,\n        \"input_cost_per_audio_token\":
        0.0001,\n        \"output_cost_per_token\": 1e-05,\n        \"output_cost_per_audio_token\":
        0.0002,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4o-audio-preview-2024-12-17\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 2.5e-06,\n        \"input_cost_per_audio_token\":
        4e-05,\n        \"output_cost_per_token\": 1e-05,\n        \"output_cost_per_audio_token\":
        8e-05,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4o-audio-preview-2024-10-01\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 2.5e-06,\n        \"input_cost_per_audio_token\":
        0.0001,\n        \"output_cost_per_token\": 1e-05,\n        \"output_cost_per_audio_token\":
        0.0002,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4o-audio-preview-2025-06-03\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 2.5e-06,\n        \"input_cost_per_audio_token\":
        4e-05,\n        \"output_cost_per_token\": 1e-05,\n        \"output_cost_per_audio_token\":
        8e-05,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4o-mini-audio-preview\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 1.5e-07,\n        \"input_cost_per_audio_token\":
        1e-05,\n        \"output_cost_per_token\": 6e-07,\n        \"output_cost_per_audio_token\":
        2e-05,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4o-mini-audio-preview-2024-12-17\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 1.5e-07,\n        \"input_cost_per_audio_token\":
        1e-05,\n        \"output_cost_per_token\": 6e-07,\n        \"output_cost_per_audio_token\":
        2e-05,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4o-mini\": {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\":
        128000,\n        \"max_output_tokens\": 16384,\n        \"input_cost_per_token\":
        1.5e-07,\n        \"output_cost_per_token\": 6e-07,\n        \"input_cost_per_token_batches\":
        7.5e-08,\n        \"output_cost_per_token_batches\": 3e-07,\n        \"cache_read_input_token_cost\":
        7.5e-08,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4o-mini-search-preview-2025-03-11\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"input_cost_per_token_batches\": 7.5e-08,\n        \"output_cost_per_token_batches\":
        3e-07,\n        \"cache_read_input_token_cost\": 7.5e-08,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"gpt-4o-mini-search-preview\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 1.5e-07,\n
        \       \"output_cost_per_token\": 6e-07,\n        \"input_cost_per_token_batches\":
        7.5e-08,\n        \"output_cost_per_token_batches\": 3e-07,\n        \"cache_read_input_token_cost\":
        7.5e-08,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_web_search\": true,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.025,\n            \"search_context_size_medium\":
        0.0275,\n            \"search_context_size_high\": 0.03\n        }\n    },\n
        \   \"gpt-4o-mini-2024-07-18\": {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\":
        128000,\n        \"max_output_tokens\": 16384,\n        \"input_cost_per_token\":
        1.5e-07,\n        \"output_cost_per_token\": 6e-07,\n        \"input_cost_per_token_batches\":
        7.5e-08,\n        \"output_cost_per_token_batches\": 3e-07,\n        \"cache_read_input_token_cost\":
        7.5e-08,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        0.025,\n            \"search_context_size_medium\": 0.0275,\n            \"search_context_size_high\":
        0.03\n        }\n    },\n    \"gpt-5\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 400000,\n        \"max_output_tokens\": 128000,\n
        \       \"input_cost_per_token\": 1.25e-06,\n        \"output_cost_per_token\":
        1e-05,\n        \"cache_read_input_token_cost\": 1.25e-07,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/batch\",\n            \"/v1/responses\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_native_streaming\": true,\n        \"supports_reasoning\":
        true\n    },\n    \"gpt-5-mini\": {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\":
        400000,\n        \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        2.5e-07,\n        \"output_cost_per_token\": 2e-06,\n        \"cache_read_input_token_cost\":
        2.5e-08,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_pdf_input\": true,\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"gpt-5-nano\": {\n
        \       \"max_tokens\": 128000,\n        \"max_input_tokens\": 400000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 5e-08,\n        \"output_cost_per_token\":
        4e-07,\n        \"cache_read_input_token_cost\": 5e-09,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/batch\",\n            \"/v1/responses\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_native_streaming\": true,\n        \"supports_reasoning\":
        true\n    },\n    \"gpt-5-chat\": {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\":
        400000,\n        \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        1.25e-06,\n        \"output_cost_per_token\": 1e-05,\n        \"cache_read_input_token_cost\":
        1.25e-07,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [   \n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_pdf_input\": true,\n
        \       \"supports_function_calling\": false,\n        \"supports_parallel_function_calling\":
        false,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": false,\n        \"supports_native_streaming\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"gpt-5-chat-latest\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 400000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        1.25e-06,\n        \"output_cost_per_token\": 1e-05,\n        \"cache_read_input_token_cost\":
        1.25e-07,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_pdf_input\": true,\n
        \       \"supports_function_calling\": false,\n        \"supports_parallel_function_calling\":
        false,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": false,\n        \"supports_native_streaming\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"gpt-5-2025-08-07\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 400000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        1.25e-06,\n        \"output_cost_per_token\": 1e-05,\n        \"cache_read_input_token_cost\":
        1.25e-07,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_pdf_input\": true,\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"gpt-5-mini-2025-08-07\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 400000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        2.5e-07,\n        \"output_cost_per_token\": 2e-06,\n        \"cache_read_input_token_cost\":
        2.5e-08,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_pdf_input\": true,\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"gpt-5-nano-2025-08-07\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 400000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        5e-08,\n        \"output_cost_per_token\": 4e-07,\n        \"cache_read_input_token_cost\":
        5e-09,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_pdf_input\": true,\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"codex-mini-latest\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        1.5e-06,\n        \"output_cost_per_token\": 6e-06,\n        \"cache_read_input_token_cost\":
        3.75e-07,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"responses\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supported_endpoints\": [\n
        \           \"/v1/responses\"\n        ]\n    },\n    \"o1-pro\": {\n        \"max_tokens\":
        100000,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        100000,\n        \"input_cost_per_token\": 0.00015,\n        \"output_cost_per_token\":
        0.0006,\n        \"input_cost_per_token_batches\": 7.5e-05,\n        \"output_cost_per_token_batches\":
        0.0003,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"responses\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_native_streaming\": false,\n        \"supports_reasoning\":
        true,\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"supported_endpoints\": [\n            \"/v1/responses\",\n
        \           \"/v1/batch\"\n        ]\n    },\n    \"o1-pro-2025-03-19\": {\n
        \       \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        100000,\n        \"input_cost_per_token\": 0.00015,\n        \"output_cost_per_token\":
        0.0006,\n        \"input_cost_per_token_batches\": 7.5e-05,\n        \"output_cost_per_token_batches\":
        0.0003,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"responses\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_native_streaming\": false,\n        \"supports_reasoning\":
        true,\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"supported_endpoints\": [\n            \"/v1/responses\",\n
        \           \"/v1/batch\"\n        ]\n    },\n    \"o1\": {\n        \"max_tokens\":
        100000,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        100000,\n        \"input_cost_per_token\": 1.5e-05,\n        \"output_cost_per_token\":
        6e-05,\n        \"cache_read_input_token_cost\": 7.5e-06,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"o1-mini\": {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\":
        128000,\n        \"max_output_tokens\": 65536,\n        \"input_cost_per_token\":
        1.1e-06,\n        \"output_cost_per_token\": 4.4e-06,\n        \"cache_read_input_token_cost\":
        5.5e-07,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_vision\": true,\n        \"supports_pdf_input\": true,\n
        \       \"supports_prompt_caching\": true\n    },\n    \"computer-use-preview\":
        {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        1024,\n        \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.2e-05,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/responses\"\n        ],\n
        \       \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": false,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true\n    },\n    \"o3-deep-research\": {\n        \"max_tokens\": 100000,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 100000,\n
        \       \"input_cost_per_token\": 1e-05,\n        \"output_cost_per_token\":
        4e-05,\n        \"input_cost_per_token_batches\": 5e-06,\n        \"output_cost_per_token_batches\":
        2e-05,\n        \"cache_read_input_token_cost\": 2.5e-06,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"responses\",\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/batch\",\n            \"/v1/responses\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_native_streaming\": true\n    },\n    \"o3-deep-research-2025-06-26\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        1e-05,\n        \"output_cost_per_token\": 4e-05,\n        \"input_cost_per_token_batches\":
        5e-06,\n        \"output_cost_per_token_batches\": 2e-05,\n        \"cache_read_input_token_cost\":
        2.5e-06,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"responses\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_pdf_input\": true,\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true\n    },\n    \"o3-pro\": {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\":
        200000,\n        \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        2e-05,\n        \"input_cost_per_token_batches\": 1e-05,\n        \"output_cost_per_token_batches\":
        4e-05,\n        \"output_cost_per_token\": 8e-05,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"responses\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": false,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true,\n        \"supported_endpoints\":
        [\n            \"/v1/responses\",\n            \"/v1/batch\"\n        ],\n
        \       \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ]\n    },\n    \"o3-pro-2025-06-10\": {\n        \"max_tokens\": 100000,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 100000,\n
        \       \"input_cost_per_token\": 2e-05,\n        \"input_cost_per_token_batches\":
        1e-05,\n        \"output_cost_per_token_batches\": 4e-05,\n        \"output_cost_per_token\":
        8e-05,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"responses\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        false,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_tool_choice\":
        true,\n        \"supported_endpoints\": [\n            \"/v1/responses\",\n
        \           \"/v1/batch\"\n        ],\n        \"supported_modalities\": [\n
        \           \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ]\n    },\n    \"o3\": {\n        \"max_tokens\":
        100000,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        100000,\n        \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        8e-06,\n        \"cache_read_input_token_cost\": 5e-07,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": false,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true,\n        \"supported_endpoints\":
        [\n            \"/v1/responses\",\n            \"/v1/chat/completions\",\n
        \           \"/v1/completions\",\n            \"/v1/batch\"\n        ],\n
        \       \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ]\n    },\n    \"o3-2025-04-16\": {\n        \"max_tokens\": 100000,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 100000,\n
        \       \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        8e-06,\n        \"cache_read_input_token_cost\": 5e-07,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": false,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true,\n        \"supported_endpoints\":
        [\n            \"/v1/responses\",\n            \"/v1/chat/completions\",\n
        \           \"/v1/completions\",\n            \"/v1/batch\"\n        ],\n
        \       \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ]\n    },\n    \"o3-mini\": {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\":
        200000,\n        \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        1.1e-06,\n        \"output_cost_per_token\": 4.4e-06,\n        \"cache_read_input_token_cost\":
        5.5e-07,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        false,\n        \"supports_vision\": false,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"o3-mini-2025-01-31\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        1.1e-06,\n        \"output_cost_per_token\": 4.4e-06,\n        \"cache_read_input_token_cost\":
        5.5e-07,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        false,\n        \"supports_vision\": false,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"o4-mini\": {\n
        \       \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        100000,\n        \"input_cost_per_token\": 1.1e-06,\n        \"output_cost_per_token\":
        4.4e-06,\n        \"cache_read_input_token_cost\": 2.75e-07,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        false,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"o4-mini-deep-research\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        2e-06,\n        \"output_cost_per_token\": 8e-06,\n        \"input_cost_per_token_batches\":
        1e-06,\n        \"output_cost_per_token_batches\": 4e-06,\n        \"cache_read_input_token_cost\":
        5e-07,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"responses\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_pdf_input\": true,\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true\n    },\n    \"o4-mini-deep-research-2025-06-26\": {\n        \"max_tokens\":
        100000,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        100000,\n        \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        8e-06,\n        \"input_cost_per_token_batches\": 1e-06,\n        \"output_cost_per_token_batches\":
        4e-06,\n        \"cache_read_input_token_cost\": 5e-07,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"responses\",\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/batch\",\n            \"/v1/responses\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_native_streaming\": true\n    },\n    \"o4-mini-2025-04-16\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        1.1e-06,\n        \"output_cost_per_token\": 4.4e-06,\n        \"cache_read_input_token_cost\":
        2.75e-07,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": false,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"o1-mini-2024-09-12\": {\n        \"max_tokens\": 65536,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 65536,\n
        \       \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.2e-05,\n        \"cache_read_input_token_cost\": 1.5e-06,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_pdf_input\":
        true,\n        \"supports_vision\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_prompt_caching\": true\n    },\n    \"o1-preview\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 1.5e-05,\n
        \       \"output_cost_per_token\": 6e-05,\n        \"cache_read_input_token_cost\":
        7.5e-06,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_vision\": true,\n
        \       \"supports_reasoning\": true,\n        \"supports_prompt_caching\":
        true\n    },\n    \"o1-preview-2024-09-12\": {\n        \"max_tokens\": 32768,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 32768,\n
        \       \"input_cost_per_token\": 1.5e-05,\n        \"output_cost_per_token\":
        6e-05,\n        \"cache_read_input_token_cost\": 7.5e-06,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_pdf_input\":
        true,\n        \"supports_vision\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_prompt_caching\": true\n    },\n    \"o1-2024-12-17\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        1.5e-05,\n        \"output_cost_per_token\": 6e-05,\n        \"cache_read_input_token_cost\":
        7.5e-06,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"chatgpt-4o-latest\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 5e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4o-2024-05-13\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 5e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"input_cost_per_token_batches\": 2.5e-06,\n        \"output_cost_per_token_batches\":
        7.5e-06,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"gpt-4o-2024-08-06\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 2.5e-06,\n
        \       \"output_cost_per_token\": 1e-05,\n        \"input_cost_per_token_batches\":
        1.25e-06,\n        \"output_cost_per_token_batches\": 5e-06,\n        \"cache_read_input_token_cost\":
        1.25e-06,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4o-2024-11-20\": {\n        \"max_tokens\": 16384,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 16384,\n
        \       \"input_cost_per_token\": 2.5e-06,\n        \"output_cost_per_token\":
        1e-05,\n        \"input_cost_per_token_batches\": 1.25e-06,\n        \"output_cost_per_token_batches\":
        5e-06,\n        \"cache_read_input_token_cost\": 1.25e-06,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"gpt-4o-realtime-preview-2024-10-01\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 5e-06,\n
        \       \"input_cost_per_audio_token\": 0.0001,\n        \"cache_read_input_token_cost\":
        2.5e-06,\n        \"cache_creation_input_audio_token_cost\": 2e-05,\n        \"output_cost_per_token\":
        2e-05,\n        \"output_cost_per_audio_token\": 0.0002,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_audio_input\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"gpt-4o-realtime-preview\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 5e-06,\n
        \       \"input_cost_per_audio_token\": 4e-05,\n        \"cache_read_input_token_cost\":
        2.5e-06,\n        \"output_cost_per_token\": 2e-05,\n        \"output_cost_per_audio_token\":
        8e-05,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4o-realtime-preview-2024-12-17\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 5e-06,\n        \"input_cost_per_audio_token\":
        4e-05,\n        \"cache_read_input_token_cost\": 2.5e-06,\n        \"output_cost_per_token\":
        2e-05,\n        \"output_cost_per_audio_token\": 8e-05,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_audio_input\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"gpt-4o-realtime-preview-2025-06-03\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 5e-06,\n
        \       \"input_cost_per_audio_token\": 4e-05,\n        \"cache_read_input_token_cost\":
        2.5e-06,\n        \"output_cost_per_token\": 2e-05,\n        \"output_cost_per_audio_token\":
        8e-05,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4o-mini-realtime-preview\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 6e-07,\n        \"input_cost_per_audio_token\":
        1e-05,\n        \"cache_read_input_token_cost\": 3e-07,\n        \"cache_creation_input_audio_token_cost\":
        3e-07,\n        \"output_cost_per_token\": 2.4e-06,\n        \"output_cost_per_audio_token\":
        2e-05,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4o-mini-realtime-preview-2024-12-17\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 6e-07,\n        \"input_cost_per_audio_token\":
        1e-05,\n        \"cache_read_input_token_cost\": 3e-07,\n        \"cache_creation_input_audio_token_cost\":
        3e-07,\n        \"output_cost_per_token\": 2.4e-06,\n        \"output_cost_per_audio_token\":
        2e-05,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4-turbo-preview\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 1e-05,\n        \"output_cost_per_token\":
        3e-05,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4-0314\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        3e-05,\n        \"output_cost_per_token\": 6e-05,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4-0613\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        3e-05,\n        \"output_cost_per_token\": 6e-05,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"deprecation_date\": \"2025-06-06\",\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4-32k\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        32768,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        6e-05,\n        \"output_cost_per_token\": 0.00012,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4-32k-0314\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        32768,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        6e-05,\n        \"output_cost_per_token\": 0.00012,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4-32k-0613\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        32768,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        6e-05,\n        \"output_cost_per_token\": 0.00012,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4-turbo\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        128000,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        1e-05,\n        \"output_cost_per_token\": 3e-05,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4-turbo-2024-04-09\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 1e-05,\n        \"output_cost_per_token\":
        3e-05,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"gpt-4-1106-preview\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 1e-05,\n
        \       \"output_cost_per_token\": 3e-05,\n        \"litellm_provider\": \"openai\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4-0125-preview\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 1e-05,\n        \"output_cost_per_token\":
        3e-05,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"gpt-4-vision-preview\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 1e-05,\n
        \       \"output_cost_per_token\": 3e-05,\n        \"litellm_provider\": \"openai\",\n
        \       \"mode\": \"chat\",\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"deprecation_date\": \"2024-12-06\",\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4-1106-vision-preview\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1e-05,\n        \"output_cost_per_token\":
        3e-05,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_vision\": true,\n        \"supports_pdf_input\": true,\n
        \       \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"deprecation_date\": \"2024-12-06\",\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-3.5-turbo\": {\n        \"max_tokens\": 4097,\n        \"max_input_tokens\":
        16385,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        1.5e-06,\n        \"output_cost_per_token\": 2e-06,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"gpt-3.5-turbo-0301\":
        {\n        \"max_tokens\": 4097,\n        \"max_input_tokens\": 4097,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.5e-06,\n        \"output_cost_per_token\":
        2e-06,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"gpt-3.5-turbo-0613\":
        {\n        \"max_tokens\": 4097,\n        \"max_input_tokens\": 4097,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.5e-06,\n        \"output_cost_per_token\":
        2e-06,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-3.5-turbo-1106\": {\n        \"max_tokens\": 16385,\n
        \       \"max_input_tokens\": 16385,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 1e-06,\n        \"output_cost_per_token\":
        2e-06,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"gpt-3.5-turbo-0125\":
        {\n        \"max_tokens\": 16385,\n        \"max_input_tokens\": 16385,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 5e-07,\n
        \       \"output_cost_per_token\": 1.5e-06,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-3.5-turbo-16k\": {\n        \"max_tokens\": 16385,\n
        \       \"max_input_tokens\": 16385,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        4e-06,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"gpt-3.5-turbo-16k-0613\":
        {\n        \"max_tokens\": 16385,\n        \"max_input_tokens\": 16385,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 4e-06,\n        \"litellm_provider\": \"openai\",\n
        \       \"mode\": \"chat\",\n        \"supports_prompt_caching\": true,\n
        \       \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"ft:gpt-3.5-turbo\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 16385,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        6e-06,\n        \"input_cost_per_token_batches\": 1.5e-06,\n        \"output_cost_per_token_batches\":
        3e-06,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"ft:gpt-3.5-turbo-0125\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 16385,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        6e-06,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"ft:gpt-3.5-turbo-1106\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 16385,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        6e-06,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"ft:gpt-3.5-turbo-0613\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 4096,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        6e-06,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"ft:gpt-4-0613\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        3e-05,\n        \"output_cost_per_token\": 6e-05,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"source\": \"OpenAI needs to add pricing for this ft model,
        will be updated when added by OpenAI. Defaulting to base model pricing\",\n
        \       \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"ft:gpt-4o-2024-08-06\": {\n        \"max_tokens\": 16384,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 16384,\n
        \       \"input_cost_per_token\": 3.75e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"input_cost_per_token_batches\": 1.875e-06,\n        \"output_cost_per_token_batches\":
        7.5e-06,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"ft:gpt-4o-2024-11-20\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 3.75e-06,\n
        \       \"cache_creation_input_token_cost\": 1.875e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"ft:gpt-4o-mini-2024-07-18\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        1.2e-06,\n        \"input_cost_per_token_batches\": 1.5e-07,\n        \"output_cost_per_token_batches\":
        6e-07,\n        \"cache_read_input_token_cost\": 1.5e-07,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"ft:davinci-002\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 2e-06,\n
        \       \"output_cost_per_token\": 2e-06,\n        \"input_cost_per_token_batches\":
        1e-06,\n        \"output_cost_per_token_batches\": 1e-06,\n        \"litellm_provider\":
        \"text-completion-openai\",\n        \"mode\": \"completion\"\n    },\n    \"ft:babbage-002\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 4e-07,\n
        \       \"output_cost_per_token\": 4e-07,\n        \"input_cost_per_token_batches\":
        2e-07,\n        \"output_cost_per_token_batches\": 2e-07,\n        \"litellm_provider\":
        \"text-completion-openai\",\n        \"mode\": \"completion\"\n    },\n    \"text-embedding-3-large\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 8191,\n        \"output_vector_size\":
        3072,\n        \"input_cost_per_token\": 1.3e-07,\n        \"output_cost_per_token\":
        0.0,\n        \"input_cost_per_token_batches\": 6.5e-08,\n        \"output_cost_per_token_batches\":
        0.0,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"text-embedding-3-small\": {\n        \"max_tokens\": 8191,\n
        \       \"max_input_tokens\": 8191,\n        \"output_vector_size\": 1536,\n
        \       \"input_cost_per_token\": 2e-08,\n        \"output_cost_per_token\":
        0.0,\n        \"input_cost_per_token_batches\": 1e-08,\n        \"output_cost_per_token_batches\":
        0.0,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"text-embedding-ada-002\": {\n        \"max_tokens\": 8191,\n
        \       \"max_input_tokens\": 8191,\n        \"output_vector_size\": 1536,\n
        \       \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"text-embedding-ada-002-v2\": {\n        \"max_tokens\": 8191,\n
        \       \"max_input_tokens\": 8191,\n        \"input_cost_per_token\": 1e-07,\n
        \       \"output_cost_per_token\": 0.0,\n        \"input_cost_per_token_batches\":
        5e-08,\n        \"output_cost_per_token_batches\": 0.0,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"embedding\"\n    },\n    \"text-moderation-stable\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 0,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"openai\",\n
        \       \"mode\": \"moderation\"\n    },\n    \"text-moderation-007\": {\n
        \       \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        0,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"moderation\"\n
        \   },\n    \"text-moderation-latest\": {\n        \"max_tokens\": 32768,\n
        \       \"max_input_tokens\": 32768,\n        \"max_output_tokens\": 0,\n
        \       \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"moderation\"\n
        \   },\n    \"256-x-256/dall-e-2\": {\n        \"mode\": \"image_generation\",\n
        \       \"input_cost_per_pixel\": 2.4414e-07,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"openai\"\n    },\n    \"512-x-512/dall-e-2\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        6.86e-08,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"openai\"\n    },\n    \"1024-x-1024/dall-e-2\": {\n        \"mode\": \"image_generation\",\n
        \       \"input_cost_per_pixel\": 1.9e-08,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"openai\"\n    },\n    \"hd/1024-x-1792/dall-e-3\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        6.539e-08,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"openai\"\n    },\n    \"hd/1792-x-1024/dall-e-3\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 6.539e-08,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"openai\"\n    },\n    \"hd/1024-x-1024/dall-e-3\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        7.629e-08,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"openai\"\n    },\n    \"standard/1024-x-1792/dall-e-3\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 4.359e-08,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"openai\"\n    },\n    \"standard/1792-x-1024/dall-e-3\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        4.359e-08,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"openai\"\n    },\n    \"standard/1024-x-1024/dall-e-3\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 3.81469e-08,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"openai\"\n    },\n    \"gpt-image-1\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        4.0054321e-08,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"openai\",\n        \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ]\n    },\n    \"low/1024-x-1024/gpt-image-1\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 1.0490417e-08,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"openai\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ]\n    },\n    \"medium/1024-x-1024/gpt-image-1\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 4.0054321e-08,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"openai\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ]\n    },\n    \"high/1024-x-1024/gpt-image-1\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 1.59263611e-07,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"openai\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ]\n    },\n    \"low/1024-x-1536/gpt-image-1\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 1.0172526e-08,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"openai\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ]\n    },\n    \"medium/1024-x-1536/gpt-image-1\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 4.0054321e-08,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"openai\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ]\n    },\n    \"high/1024-x-1536/gpt-image-1\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 1.58945719e-07,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"openai\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ]\n    },\n    \"low/1536-x-1024/gpt-image-1\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 1.0172526e-08,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"openai\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ]\n    },\n    \"medium/1536-x-1024/gpt-image-1\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 4.0054321e-08,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"openai\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ]\n    },\n    \"high/1536-x-1024/gpt-image-1\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 1.58945719e-07,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"openai\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ]\n    },\n    \"gpt-4o-transcribe\": {\n        \"mode\": \"audio_transcription\",\n
        \       \"max_input_tokens\": 16000,\n        \"max_output_tokens\": 2000,\n
        \       \"input_cost_per_token\": 2.5e-06,\n        \"input_cost_per_audio_token\":
        6e-06,\n        \"output_cost_per_token\": 1e-05,\n        \"litellm_provider\":
        \"openai\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ]\n    },\n    \"gpt-4o-mini-transcribe\": {\n        \"mode\": \"audio_transcription\",\n
        \       \"max_input_tokens\": 16000,\n        \"max_output_tokens\": 2000,\n
        \       \"input_cost_per_token\": 1.25e-06,\n        \"input_cost_per_audio_token\":
        3e-06,\n        \"output_cost_per_token\": 5e-06,\n        \"litellm_provider\":
        \"openai\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ]\n    },\n    \"whisper-1\": {\n        \"mode\": \"audio_transcription\",\n
        \       \"input_cost_per_second\": 0.0001,\n        \"output_cost_per_second\":
        0.0001,\n        \"litellm_provider\": \"openai\",\n        \"supported_endpoints\":
        [\n            \"/v1/audio/transcriptions\"\n        ]\n    },\n    \"tts-1\":
        {\n        \"mode\": \"audio_speech\",\n        \"input_cost_per_character\":
        1.5e-05,\n        \"litellm_provider\": \"openai\",\n        \"supported_endpoints\":
        [\n            \"/v1/audio/speech\"\n        ]\n    },\n    \"tts-1-hd\":
        {\n        \"mode\": \"audio_speech\",\n        \"input_cost_per_character\":
        3e-05,\n        \"litellm_provider\": \"openai\",\n        \"supported_endpoints\":
        [\n            \"/v1/audio/speech\"\n        ]\n    },\n    \"gpt-4o-mini-tts\":
        {\n        \"mode\": \"audio_speech\",\n        \"input_cost_per_token\":
        2.5e-06,\n        \"output_cost_per_token\": 1e-05,\n        \"output_cost_per_audio_token\":
        1.2e-05,\n        \"output_cost_per_second\": 0.00025,\n        \"litellm_provider\":
        \"openai\",\n        \"supported_modalities\": [\n            \"text\",\n
        \           \"audio\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"audio\"\n        ],\n        \"supported_endpoints\": [\n
        \           \"/v1/audio/speech\"\n        ]\n    },\n    \"azure/gpt-5\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 272000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        1.25e-06,\n        \"output_cost_per_token\": 1e-05,\n        \"cache_read_input_token_cost\":
        1.25e-07,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_pdf_input\": true,\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"azure/gpt-5-2025-08-07\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 272000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        1.25e-06,\n        \"output_cost_per_token\": 1e-05,\n        \"cache_read_input_token_cost\":
        1.25e-07,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_pdf_input\": true,\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"azure/gpt-5-mini\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 272000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        2.5e-07,\n        \"output_cost_per_token\": 2e-06,\n        \"cache_read_input_token_cost\":
        2.5e-08,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_pdf_input\": true,\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"azure/gpt-5-mini-2025-08-07\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 272000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        2.5e-07,\n        \"output_cost_per_token\": 2e-06,\n        \"cache_read_input_token_cost\":
        2.5e-08,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_pdf_input\": true,\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"azure/gpt-5-nano-2025-08-07\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 272000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        5e-08,\n        \"output_cost_per_token\": 4e-07,\n        \"cache_read_input_token_cost\":
        5e-09,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_pdf_input\": true,\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"azure/gpt-5-nano\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 272000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        5e-08,\n        \"output_cost_per_token\": 4e-07,\n        \"cache_read_input_token_cost\":
        5e-09,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_pdf_input\": true,\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"azure/gpt-5-chat\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 272000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        1.25e-06,\n        \"output_cost_per_token\": 1e-05,\n        \"cache_read_input_token_cost\":
        1.25e-07,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_pdf_input\": true,\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": false,\n        \"supports_native_streaming\":
        true,\n        \"supports_reasoning\": true,\n        \"source\": \"https://azure.microsoft.com/en-us/blog/gpt-5-in-azure-ai-foundry-the-future-of-ai-apps-and-agents-starts-here/\"\n
        \   },\n    \"azure/gpt-5-chat-latest\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 272000,\n        \"max_output_tokens\": 128000,\n
        \       \"input_cost_per_token\": 1.25e-06,\n        \"output_cost_per_token\":
        1e-05,\n        \"cache_read_input_token_cost\": 1.25e-07,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/batch\",\n            \"/v1/responses\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        false,\n        \"supports_native_streaming\": true,\n        \"supports_reasoning\":
        true\n    },\n    \"azure/gpt-4o-mini-tts\": {\n        \"mode\": \"audio_speech\",\n
        \       \"input_cost_per_token\": 2.5e-06,\n        \"output_cost_per_token\":
        1e-05,\n        \"output_cost_per_audio_token\": 1.2e-05,\n        \"output_cost_per_second\":
        0.00025,\n        \"litellm_provider\": \"azure\",\n        \"supported_modalities\":
        [\n            \"text\",\n            \"audio\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"audio\"\n        ],\n        \"supported_endpoints\": [\n
        \           \"/v1/audio/speech\"\n        ]\n    },\n    \"azure/computer-use-preview\":
        {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        1024,\n        \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.2e-05,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/responses\"\n        ],\n
        \       \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": false,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true\n    },\n    \"azure/gpt-4o-audio-preview-2024-12-17\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 2.5e-06,\n        \"input_cost_per_audio_token\":
        4e-05,\n        \"output_cost_per_token\": 1e-05,\n        \"output_cost_per_audio_token\":
        8e-05,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"audio\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\",\n
        \           \"audio\"\n        ],\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        false,\n        \"supports_vision\": false,\n        \"supports_prompt_caching\":
        false,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_native_streaming\": true,\n        \"supports_reasoning\":
        false\n    },\n    \"azure/gpt-4o-mini-audio-preview-2024-12-17\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 2.5e-06,\n        \"input_cost_per_audio_token\":
        4e-05,\n        \"output_cost_per_token\": 1e-05,\n        \"output_cost_per_audio_token\":
        8e-05,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"audio\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\",\n
        \           \"audio\"\n        ],\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        false,\n        \"supports_vision\": false,\n        \"supports_prompt_caching\":
        false,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_native_streaming\": true,\n        \"supports_reasoning\":
        false\n    },\n    \"azure/gpt-4.1\": {\n        \"max_tokens\": 32768,\n
        \       \"max_input_tokens\": 1047576,\n        \"max_output_tokens\": 32768,\n
        \       \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        8e-06,\n        \"input_cost_per_token_batches\": 1e-06,\n        \"output_cost_per_token_batches\":
        4e-06,\n        \"cache_read_input_token_cost\": 5e-07,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/batch\",\n            \"/v1/responses\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true,\n        \"supports_web_search\": true,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.03,\n            \"search_context_size_medium\":
        0.035,\n            \"search_context_size_high\": 0.05\n        }\n    },\n
        \   \"azure/gpt-4.1-2025-04-14\": {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\":
        1047576,\n        \"max_output_tokens\": 32768,\n        \"input_cost_per_token\":
        2e-06,\n        \"output_cost_per_token\": 8e-06,\n        \"input_cost_per_token_batches\":
        1e-06,\n        \"output_cost_per_token_batches\": 4e-06,\n        \"cache_read_input_token_cost\":
        5e-07,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_native_streaming\": true,\n        \"supports_web_search\":
        true,\n        \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        0.03,\n            \"search_context_size_medium\": 0.035,\n            \"search_context_size_high\":
        0.05\n        }\n    },\n    \"azure/gpt-4.1-mini\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 1047576,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 4e-07,\n        \"output_cost_per_token\":
        1.6e-06,\n        \"input_cost_per_token_batches\": 2e-07,\n        \"output_cost_per_token_batches\":
        8e-07,\n        \"cache_read_input_token_cost\": 1e-07,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/batch\",\n            \"/v1/responses\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true,\n        \"supports_web_search\": true,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.025,\n            \"search_context_size_medium\":
        0.0275,\n            \"search_context_size_high\": 0.03\n        }\n    },\n
        \   \"azure/gpt-4.1-mini-2025-04-14\": {\n        \"max_tokens\": 32768,\n
        \       \"max_input_tokens\": 1047576,\n        \"max_output_tokens\": 32768,\n
        \       \"input_cost_per_token\": 4e-07,\n        \"output_cost_per_token\":
        1.6e-06,\n        \"input_cost_per_token_batches\": 2e-07,\n        \"output_cost_per_token_batches\":
        8e-07,\n        \"cache_read_input_token_cost\": 1e-07,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/batch\",\n            \"/v1/responses\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true,\n        \"supports_web_search\": true,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.025,\n            \"search_context_size_medium\":
        0.0275,\n            \"search_context_size_high\": 0.03\n        }\n    },\n
        \   \"azure/gpt-4.1-nano\": {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\":
        1047576,\n        \"max_output_tokens\": 32768,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 4e-07,\n        \"input_cost_per_token_batches\":
        5e-08,\n        \"output_cost_per_token_batches\": 2e-07,\n        \"cache_read_input_token_cost\":
        2.5e-08,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_native_streaming\": true\n    },\n    \"azure/gpt-4.1-nano-2025-04-14\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 1047576,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 1e-07,\n
        \       \"output_cost_per_token\": 4e-07,\n        \"input_cost_per_token_batches\":
        5e-08,\n        \"output_cost_per_token_batches\": 2e-07,\n        \"cache_read_input_token_cost\":
        2.5e-08,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_native_streaming\": true\n    },\n    \"azure/o3-pro\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        2e-05,\n        \"output_cost_per_token\": 8e-05,\n        \"input_cost_per_token_batches\":
        1e-05,\n        \"output_cost_per_token_batches\": 4e-05,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"responses\",\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/batch\",\n            \"/v1/responses\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        false,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        false,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/o3-pro-2025-06-10\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        2e-05,\n        \"output_cost_per_token\": 8e-05,\n        \"input_cost_per_token_batches\":
        1e-05,\n        \"output_cost_per_token_batches\": 4e-05,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"responses\",\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/batch\",\n            \"/v1/responses\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        false,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        false,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/o3\": {\n
        \       \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        100000,\n        \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        8e-06,\n        \"cache_read_input_token_cost\": 5e-07,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/batch\",\n            \"/v1/responses\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        false,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/o3-2025-04-16\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        1e-05,\n        \"output_cost_per_token\": 4e-05,\n        \"cache_read_input_token_cost\":
        2.5e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/batch\",\n            \"/v1/responses\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": false,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/o3-deep-research\": {\n        \"max_tokens\": 100000,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 100000,\n
        \       \"input_cost_per_token\": 1e-05,\n        \"output_cost_per_token\":
        4e-05,\n        \"cache_read_input_token_cost\": 2.5e-06,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"responses\",\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/batch\",\n            \"/v1/responses\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_web_search\":
        true\n    },\n    \"azure/o4-mini\": {\n        \"max_tokens\": 100000,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 100000,\n
        \       \"input_cost_per_token\": 1.1e-06,\n        \"output_cost_per_token\":
        4.4e-06,\n        \"cache_read_input_token_cost\": 2.75e-07,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/batch\",\n            \"/v1/responses\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        false,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/gpt-4o-mini-realtime-preview-2024-12-17\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 6e-07,\n
        \       \"input_cost_per_audio_token\": 1e-05,\n        \"cache_read_input_token_cost\":
        3e-07,\n        \"cache_creation_input_audio_token_cost\": 3e-07,\n        \"output_cost_per_token\":
        2.4e-06,\n        \"output_cost_per_audio_token\": 2e-05,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_audio_input\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/eu/gpt-4o-mini-realtime-preview-2024-12-17\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 6.6e-07,\n
        \       \"input_cost_per_audio_token\": 1.1e-05,\n        \"cache_read_input_token_cost\":
        3.3e-07,\n        \"cache_creation_input_audio_token_cost\": 3.3e-07,\n        \"output_cost_per_token\":
        2.64e-06,\n        \"output_cost_per_audio_token\": 2.2e-05,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_audio_input\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/us/gpt-4o-mini-realtime-preview-2024-12-17\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 6.6e-07,\n
        \       \"input_cost_per_audio_token\": 1.1e-05,\n        \"cache_read_input_token_cost\":
        3.3e-07,\n        \"cache_creation_input_audio_token_cost\": 3.3e-07,\n        \"output_cost_per_token\":
        2.64e-06,\n        \"output_cost_per_audio_token\": 2.2e-05,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_audio_input\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/gpt-4o-realtime-preview-2024-12-17\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 5e-06,\n
        \       \"input_cost_per_audio_token\": 4e-05,\n        \"cache_read_input_token_cost\":
        2.5e-06,\n        \"output_cost_per_token\": 2e-05,\n        \"output_cost_per_audio_token\":
        8e-05,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_modalities\": [\n            \"text\",\n            \"audio\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\",\n
        \           \"audio\"\n        ],\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_audio_input\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/us/gpt-4o-realtime-preview-2024-12-17\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 5.5e-06,\n
        \       \"input_cost_per_audio_token\": 4.4e-05,\n        \"cache_read_input_token_cost\":
        2.75e-06,\n        \"cache_read_input_audio_token_cost\": 2.5e-06,\n        \"output_cost_per_token\":
        2.2e-05,\n        \"output_cost_per_audio_token\": 8e-05,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supported_modalities\":
        [\n            \"text\",\n            \"audio\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\",\n            \"audio\"\n        ],\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_audio_input\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/eu/gpt-4o-realtime-preview-2024-12-17\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 5.5e-06,\n
        \       \"input_cost_per_audio_token\": 4.4e-05,\n        \"cache_read_input_token_cost\":
        2.75e-06,\n        \"cache_read_input_audio_token_cost\": 2.5e-06,\n        \"output_cost_per_token\":
        2.2e-05,\n        \"output_cost_per_audio_token\": 8e-05,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supported_modalities\":
        [\n            \"text\",\n            \"audio\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\",\n            \"audio\"\n        ],\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_audio_input\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/gpt-4o-realtime-preview-2024-10-01\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 5e-06,\n
        \       \"input_cost_per_audio_token\": 0.0001,\n        \"cache_read_input_token_cost\":
        2.5e-06,\n        \"cache_creation_input_audio_token_cost\": 2e-05,\n        \"output_cost_per_token\":
        2e-05,\n        \"output_cost_per_audio_token\": 0.0002,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_audio_input\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/us/gpt-4o-realtime-preview-2024-10-01\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 5.5e-06,\n
        \       \"input_cost_per_audio_token\": 0.00011,\n        \"cache_read_input_token_cost\":
        2.75e-06,\n        \"cache_creation_input_audio_token_cost\": 2.2e-05,\n        \"output_cost_per_token\":
        2.2e-05,\n        \"output_cost_per_audio_token\": 0.00022,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_audio_input\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/eu/gpt-4o-realtime-preview-2024-10-01\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 5.5e-06,\n
        \       \"input_cost_per_audio_token\": 0.00011,\n        \"cache_read_input_token_cost\":
        2.75e-06,\n        \"cache_creation_input_audio_token_cost\": 2.2e-05,\n        \"output_cost_per_token\":
        2.2e-05,\n        \"output_cost_per_audio_token\": 0.00022,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_audio_input\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/o4-mini-2025-04-16\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        1.1e-06,\n        \"output_cost_per_token\": 4.4e-06,\n        \"cache_read_input_token_cost\":
        2.75e-07,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        false,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/o3-mini-2025-01-31\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        1.1e-06,\n        \"output_cost_per_token\": 4.4e-06,\n        \"cache_read_input_token_cost\":
        5.5e-07,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_reasoning\": true,\n        \"supports_vision\": false,\n
        \       \"supports_prompt_caching\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/us/o3-mini-2025-01-31\": {\n        \"max_tokens\":
        100000,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        100000,\n        \"input_cost_per_token\": 1.21e-06,\n        \"input_cost_per_token_batches\":
        6.05e-07,\n        \"output_cost_per_token\": 4.84e-06,\n        \"output_cost_per_token_batches\":
        2.42e-06,\n        \"cache_read_input_token_cost\": 6.05e-07,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_vision\": false,\n
        \       \"supports_reasoning\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/eu/o3-mini-2025-01-31\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        1.21e-06,\n        \"input_cost_per_token_batches\": 6.05e-07,\n        \"output_cost_per_token\":
        4.84e-06,\n        \"output_cost_per_token_batches\": 2.42e-06,\n        \"cache_read_input_token_cost\":
        6.05e-07,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_vision\": false,\n        \"supports_reasoning\": true,\n
        \       \"supports_prompt_caching\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/tts-1\": {\n        \"mode\": \"audio_speech\",\n
        \       \"input_cost_per_character\": 1.5e-05,\n        \"litellm_provider\":
        \"azure\"\n    },\n    \"azure/tts-1-hd\": {\n        \"mode\": \"audio_speech\",\n
        \       \"input_cost_per_character\": 3e-05,\n        \"litellm_provider\":
        \"azure\"\n    },\n    \"azure/whisper-1\": {\n        \"mode\": \"audio_transcription\",\n
        \       \"input_cost_per_second\": 0.0001,\n        \"output_cost_per_second\":
        0.0001,\n        \"litellm_provider\": \"azure\"\n    },\n    \"azure/gpt-4o-transcribe\":
        {\n        \"mode\": \"audio_transcription\",\n        \"max_input_tokens\":
        16000,\n        \"max_output_tokens\": 2000,\n        \"input_cost_per_token\":
        2.5e-06,\n        \"input_cost_per_audio_token\": 6e-06,\n        \"output_cost_per_token\":
        1e-05,\n        \"litellm_provider\": \"azure\",\n        \"supported_endpoints\":
        [\n            \"/v1/audio/transcriptions\"\n        ]\n    },\n    \"azure/gpt-4o-mini-transcribe\":
        {\n        \"mode\": \"audio_transcription\",\n        \"max_input_tokens\":
        16000,\n        \"max_output_tokens\": 2000,\n        \"input_cost_per_token\":
        1.25e-06,\n        \"input_cost_per_audio_token\": 3e-06,\n        \"output_cost_per_token\":
        5e-06,\n        \"litellm_provider\": \"azure\",\n        \"supported_endpoints\":
        [\n            \"/v1/audio/transcriptions\"\n        ]\n    },\n    \"azure/o3-mini\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        1.1e-06,\n        \"output_cost_per_token\": 4.4e-06,\n        \"cache_read_input_token_cost\":
        5.5e-07,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_vision\": false,\n        \"supports_prompt_caching\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/o1-mini\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 65536,\n        \"input_cost_per_token\": 1.21e-06,\n
        \       \"output_cost_per_token\": 4.84e-06,\n        \"cache_read_input_token_cost\":
        6.05e-07,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": false,\n        \"supports_reasoning\":
        true,\n        \"supports_prompt_caching\": true\n    },\n    \"azure/o1-mini-2024-09-12\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 65536,\n        \"input_cost_per_token\": 1.1e-06,\n
        \       \"output_cost_per_token\": 4.4e-06,\n        \"cache_read_input_token_cost\":
        5.5e-07,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": false,\n        \"supports_reasoning\":
        true,\n        \"supports_prompt_caching\": true\n    },\n    \"azure/us/o1-mini-2024-09-12\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 65536,\n        \"input_cost_per_token\": 1.21e-06,\n
        \       \"input_cost_per_token_batches\": 6.05e-07,\n        \"output_cost_per_token\":
        4.84e-06,\n        \"output_cost_per_token_batches\": 2.42e-06,\n        \"cache_read_input_token_cost\":
        6.05e-07,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": false,\n        \"supports_prompt_caching\":
        true\n    },\n    \"azure/eu/o1-mini-2024-09-12\": {\n        \"max_tokens\":
        65536,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        65536,\n        \"input_cost_per_token\": 1.21e-06,\n        \"input_cost_per_token_batches\":
        6.05e-07,\n        \"output_cost_per_token\": 4.84e-06,\n        \"output_cost_per_token_batches\":
        2.42e-06,\n        \"cache_read_input_token_cost\": 6.05e-07,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        false,\n        \"supports_prompt_caching\": true\n    },\n    \"azure/o1\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        1.5e-05,\n        \"output_cost_per_token\": 6e-05,\n        \"cache_read_input_token_cost\":
        7.5e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/o1-2024-12-17\": {\n        \"max_tokens\": 100000,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 100000,\n
        \       \"input_cost_per_token\": 1.5e-05,\n        \"output_cost_per_token\":
        6e-05,\n        \"cache_read_input_token_cost\": 7.5e-06,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/us/o1-2024-12-17\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        1.65e-05,\n        \"output_cost_per_token\": 6.6e-05,\n        \"cache_read_input_token_cost\":
        8.25e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/eu/o1-2024-12-17\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        1.65e-05,\n        \"output_cost_per_token\": 6.6e-05,\n        \"cache_read_input_token_cost\":
        8.25e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/codex-mini\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        1.5e-06,\n        \"output_cost_per_token\": 6e-06,\n        \"cache_read_input_token_cost\":
        3.75e-07,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"responses\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"supported_endpoints\": [\n
        \           \"/v1/responses\"\n        ]\n    },\n    \"azure/o1-preview\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 1.5e-05,\n
        \       \"output_cost_per_token\": 6e-05,\n        \"cache_read_input_token_cost\":
        7.5e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": false,\n        \"supports_reasoning\":
        true,\n        \"supports_prompt_caching\": true\n    },\n    \"azure/o1-preview-2024-09-12\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 1.5e-05,\n
        \       \"output_cost_per_token\": 6e-05,\n        \"cache_read_input_token_cost\":
        7.5e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        false,\n        \"supports_reasoning\": true,\n        \"supports_prompt_caching\":
        true\n    },\n    \"azure/us/o1-preview-2024-09-12\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 1.65e-05,\n        \"output_cost_per_token\":
        6.6e-05,\n        \"cache_read_input_token_cost\": 8.25e-06,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        false,\n        \"supports_prompt_caching\": true\n    },\n    \"azure/eu/o1-preview-2024-09-12\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 1.65e-05,\n
        \       \"output_cost_per_token\": 6.6e-05,\n        \"cache_read_input_token_cost\":
        8.25e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": false,\n        \"supports_prompt_caching\":
        true\n    },\n    \"azure/gpt-4.5-preview\": {\n        \"max_tokens\": 16384,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 16384,\n
        \       \"input_cost_per_token\": 7.5e-05,\n        \"output_cost_per_token\":
        0.00015,\n        \"input_cost_per_token_batches\": 3.75e-05,\n        \"output_cost_per_token_batches\":
        7.5e-05,\n        \"cache_read_input_token_cost\": 3.75e-05,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-4o\": {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\":
        128000,\n        \"max_output_tokens\": 16384,\n        \"input_cost_per_token\":
        2.5e-06,\n        \"output_cost_per_token\": 1e-05,\n        \"cache_read_input_token_cost\":
        1.25e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/global/gpt-4o-2024-11-20\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 2.5e-06,\n        \"output_cost_per_token\":
        1e-05,\n        \"cache_read_input_token_cost\": 1.25e-06,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/gpt-4o-2024-08-06\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 2.5e-06,\n
        \       \"output_cost_per_token\": 1e-05,\n        \"cache_read_input_token_cost\":
        1.25e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/global/gpt-4o-2024-08-06\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 2.5e-06,\n        \"output_cost_per_token\":
        1e-05,\n        \"cache_read_input_token_cost\": 1.25e-06,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/gpt-4o-2024-11-20\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 2.75e-06,\n
        \       \"output_cost_per_token\": 1.1e-05,\n        \"cache_read_input_token_cost\":
        1.25e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/us/gpt-4o-2024-11-20\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 2.75e-06,\n        \"cache_creation_input_token_cost\":
        1.38e-06,\n        \"output_cost_per_token\": 1.1e-05,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/eu/gpt-4o-2024-11-20\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 2.75e-06,\n        \"cache_creation_input_token_cost\":
        1.38e-06,\n        \"output_cost_per_token\": 1.1e-05,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-4o-2024-05-13\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 5e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/global-standard/gpt-4o-2024-08-06\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 2.5e-06,\n
        \       \"output_cost_per_token\": 1e-05,\n        \"cache_read_input_token_cost\":
        1.25e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_tool_choice\":
        true,\n        \"deprecation_date\": \"2025-08-20\"\n    },\n    \"azure/us/gpt-4o-2024-08-06\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 2.75e-06,\n
        \       \"output_cost_per_token\": 1.1e-05,\n        \"cache_read_input_token_cost\":
        1.375e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/eu/gpt-4o-2024-08-06\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 2.75e-06,\n        \"output_cost_per_token\":
        1.1e-05,\n        \"cache_read_input_token_cost\": 1.375e-06,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/global-standard/gpt-4o-2024-11-20\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 2.5e-06,\n
        \       \"output_cost_per_token\": 1e-05,\n        \"cache_read_input_token_cost\":
        1.25e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2025-12-20\"\n    },\n    \"azure/global-standard/gpt-4o-mini\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/gpt-4o-mini\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 1.65e-07,\n
        \       \"output_cost_per_token\": 6.6e-07,\n        \"cache_read_input_token_cost\":
        7.5e-08,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-4o-mini-2024-07-18\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 1.65e-07,\n        \"output_cost_per_token\":
        6.6e-07,\n        \"cache_read_input_token_cost\": 7.5e-08,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/us/gpt-4o-mini-2024-07-18\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 1.65e-07,\n
        \       \"output_cost_per_token\": 6.6e-07,\n        \"cache_read_input_token_cost\":
        8.3e-08,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/eu/gpt-4o-mini-2024-07-18\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 1.65e-07,\n        \"output_cost_per_token\":
        6.6e-07,\n        \"cache_read_input_token_cost\": 8.3e-08,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/gpt-4-turbo-2024-04-09\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 1e-05,\n
        \       \"output_cost_per_token\": 3e-05,\n        \"litellm_provider\": \"azure\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/gpt-4-0125-preview\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 1e-05,\n
        \       \"output_cost_per_token\": 3e-05,\n        \"litellm_provider\": \"azure\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-4-1106-preview\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1e-05,\n        \"output_cost_per_token\":
        3e-05,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/gpt-4-0613\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 3e-05,\n        \"output_cost_per_token\":
        6e-05,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-4-32k-0613\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 32768,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 6e-05,\n        \"output_cost_per_token\":
        0.00012,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure/gpt-4-32k\": {\n
        \       \"max_tokens\": 4096,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 6e-05,\n        \"output_cost_per_token\":
        0.00012,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure/gpt-4\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 3e-05,\n        \"output_cost_per_token\":
        6e-05,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-4-turbo\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 1e-05,\n        \"output_cost_per_token\":
        3e-05,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/gpt-4-turbo-vision-preview\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 1e-05,\n
        \       \"output_cost_per_token\": 3e-05,\n        \"litellm_provider\": \"azure\",\n
        \       \"mode\": \"chat\",\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-35-turbo-16k-0613\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 16385,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        4e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-35-turbo-1106\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1e-06,\n        \"output_cost_per_token\":
        2e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"deprecation_date\": \"2025-03-31\",\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-35-turbo-0613\": {\n        \"max_tokens\":
        4097,\n        \"max_input_tokens\": 4097,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.5e-06,\n        \"output_cost_per_token\":
        2e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"deprecation_date\": \"2025-02-13\",\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-35-turbo-0301\": {\n        \"max_tokens\":
        4097,\n        \"max_input_tokens\": 4097,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        2e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"deprecation_date\": \"2025-02-13\",\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-35-turbo-0125\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 5e-07,\n        \"output_cost_per_token\":
        1.5e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"deprecation_date\": \"2025-05-31\",\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-3.5-turbo-0125\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 5e-07,\n        \"output_cost_per_token\":
        1.5e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"deprecation_date\": \"2025-03-31\",\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-35-turbo-16k\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 16385,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        4e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure/gpt-35-turbo\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4097,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 5e-07,\n        \"output_cost_per_token\":
        1.5e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-3.5-turbo\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 4097,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 5e-07,\n        \"output_cost_per_token\":
        1.5e-06,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-3.5-turbo-instruct-0914\": {\n        \"max_tokens\":
        4097,\n        \"max_input_tokens\": 4097,\n        \"input_cost_per_token\":
        1.5e-06,\n        \"output_cost_per_token\": 2e-06,\n        \"litellm_provider\":
        \"azure_text\",\n        \"mode\": \"completion\"\n    },\n    \"azure/gpt-35-turbo-instruct\":
        {\n        \"max_tokens\": 4097,\n        \"max_input_tokens\": 4097,\n        \"input_cost_per_token\":
        1.5e-06,\n        \"output_cost_per_token\": 2e-06,\n        \"litellm_provider\":
        \"azure_text\",\n        \"mode\": \"completion\"\n    },\n    \"azure/gpt-35-turbo-instruct-0914\":
        {\n        \"max_tokens\": 4097,\n        \"max_input_tokens\": 4097,\n        \"input_cost_per_token\":
        1.5e-06,\n        \"output_cost_per_token\": 2e-06,\n        \"litellm_provider\":
        \"azure_text\",\n        \"mode\": \"completion\"\n    },\n    \"azure/mistral-large-latest\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 32000,\n
        \       \"input_cost_per_token\": 8e-06,\n        \"output_cost_per_token\":
        2.4e-05,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"azure/mistral-large-2402\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 32000,\n
        \       \"input_cost_per_token\": 8e-06,\n        \"output_cost_per_token\":
        2.4e-05,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"azure/command-r-plus\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true\n    },\n    \"azure/ada\": {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\":
        8191,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"azure/text-embedding-ada-002\": {\n        \"max_tokens\": 8191,\n
        \       \"max_input_tokens\": 8191,\n        \"input_cost_per_token\": 1e-07,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"azure\",\n
        \       \"mode\": \"embedding\"\n    },\n    \"azure/text-embedding-3-large\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 8191,\n        \"input_cost_per_token\":
        1.3e-07,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"embedding\"\n    },\n    \"azure/text-embedding-3-small\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 8191,\n        \"input_cost_per_token\":
        2e-08,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"embedding\"\n    },\n    \"azure/gpt-image-1\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        4.0054321e-08,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"azure\",\n        \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ]\n    },\n    \"azure/low/1024-x-1024/gpt-image-1\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 1.0490417e-08,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"azure\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ]\n    },\n    \"azure/medium/1024-x-1024/gpt-image-1\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 4.0054321e-08,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"azure\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ]\n    },\n    \"azure/high/1024-x-1024/gpt-image-1\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 1.59263611e-07,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"azure\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ]\n    },\n    \"azure/low/1024-x-1536/gpt-image-1\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 1.0172526e-08,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"azure\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ]\n    },\n    \"azure/medium/1024-x-1536/gpt-image-1\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 4.0054321e-08,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"azure\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ]\n    },\n    \"azure/high/1024-x-1536/gpt-image-1\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 1.58945719e-07,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"azure\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ]\n    },\n    \"azure/low/1536-x-1024/gpt-image-1\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 1.0172526e-08,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"azure\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ]\n    },\n    \"azure/medium/1536-x-1024/gpt-image-1\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 4.0054321e-08,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"azure\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ]\n    },\n    \"azure/high/1536-x-1024/gpt-image-1\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 1.58945719e-07,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"azure\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ]\n    },\n    \"azure/standard/1024-x-1024/dall-e-3\": {\n        \"input_cost_per_pixel\":
        3.81469e-08,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"image_generation\"\n    },\n    \"azure/hd/1024-x-1024/dall-e-3\":
        {\n        \"input_cost_per_pixel\": 7.629e-08,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"azure/standard/1024-x-1792/dall-e-3\": {\n        \"input_cost_per_pixel\":
        4.359e-08,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"image_generation\"\n    },\n    \"azure/standard/1792-x-1024/dall-e-3\":
        {\n        \"input_cost_per_pixel\": 4.359e-08,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"azure/hd/1024-x-1792/dall-e-3\": {\n        \"input_cost_per_pixel\":
        6.539e-08,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"image_generation\"\n    },\n    \"azure/hd/1792-x-1024/dall-e-3\":
        {\n        \"input_cost_per_pixel\": 6.539e-08,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"azure/standard/1024-x-1024/dall-e-2\": {\n        \"input_cost_per_pixel\":
        0.0,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"image_generation\"\n    },\n    \"azure_ai/grok-3\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        3.3e-06,\n        \"output_cost_per_token\": 1.65e-05,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://devblogs.microsoft.com/foundry/announcing-grok-3-and-grok-3-mini-on-azure-ai-foundry/\",\n
        \       \"supports_web_search\": true\n    },\n    \"azure_ai/global/grok-3\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        3e-06,\n        \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://devblogs.microsoft.com/foundry/announcing-grok-3-and-grok-3-mini-on-azure-ai-foundry/\",\n
        \       \"supports_web_search\": true\n    },\n    \"azure_ai/global/grok-3-mini\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        2.5e-07,\n        \"output_cost_per_token\": 1.27e-06,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_response_schema\": false,\n        \"source\": \"https://devblogs.microsoft.com/foundry/announcing-grok-3-and-grok-3-mini-on-azure-ai-foundry/\",\n
        \       \"supports_web_search\": true\n    },\n    \"azure_ai/grok-3-mini\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        2.75e-07,\n        \"output_cost_per_token\": 1.38e-06,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_response_schema\": false,\n        \"source\": \"https://devblogs.microsoft.com/foundry/announcing-grok-3-and-grok-3-mini-on-azure-ai-foundry/\",\n
        \       \"supports_web_search\": true\n    },\n    \"azure_ai/deepseek-r1\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 1.35e-06,\n
        \       \"output_cost_per_token\": 5.4e-06,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"source\": \"https://techcommunity.microsoft.com/blog/machinelearningblog/deepseek-r1-improved-performance-higher-limits-and-transparent-pricing/4386367\"\n
        \   },\n    \"azure_ai/deepseek-v3\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        128000,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        1.14e-06,\n        \"output_cost_per_token\": 4.56e-06,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true,\n        \"source\": \"https://techcommunity.microsoft.com/blog/machinelearningblog/announcing-deepseek-v3-on-azure-ai-foundry-and-github/4390438\"\n
        \   },\n    \"azure_ai/deepseek-v3-0324\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 1.14e-06,\n        \"output_cost_per_token\":
        4.56e-06,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"source\": \"https://techcommunity.microsoft.com/blog/machinelearningblog/announcing-deepseek-v3-on-azure-ai-foundry-and-github/4390438\"\n
        \   },\n    \"azure_ai/jamba-instruct\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 70000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 5e-07,\n        \"output_cost_per_token\":
        7e-07,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/jais-30b-chat\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0032,\n        \"output_cost_per_token\":
        0.00971,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://azure.microsoft.com/en-us/products/ai-services/ai-foundry/models/jais-30b-chat\"\n
        \   },\n    \"azure_ai/mistral-nemo\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        1.5e-07,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"source\": \"https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-nemo-12b-2407?tab=PlansAndPrice\"\n
        \   },\n    \"azure_ai/mistral-medium-2505\": {\n        \"max_tokens\": 8191,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 8191,\n
        \       \"input_cost_per_token\": 4e-07,\n        \"output_cost_per_token\":
        2e-06,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure_ai/mistral-large\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 4e-06,\n        \"output_cost_per_token\":
        1.2e-05,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure_ai/mistral-small\": {\n        \"max_tokens\": 8191,\n
        \       \"max_input_tokens\": 32000,\n        \"max_output_tokens\": 8191,\n
        \       \"input_cost_per_token\": 1e-06,\n        \"output_cost_per_token\":
        3e-06,\n        \"litellm_provider\": \"azure_ai\",\n        \"supports_function_calling\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"azure_ai/mistral-small-2503\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 128000,\n
        \       \"input_cost_per_token\": 1e-06,\n        \"output_cost_per_token\":
        3e-06,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure_ai/mistral-large-2407\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 2e-06,\n
        \       \"output_cost_per_token\": 6e-06,\n        \"litellm_provider\": \"azure_ai\",\n
        \       \"supports_function_calling\": true,\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/mistral-large-latest\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 2e-06,\n
        \       \"output_cost_per_token\": 6e-06,\n        \"litellm_provider\": \"azure_ai\",\n
        \       \"supports_function_calling\": true,\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/ministral-3b\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 4e-08,\n
        \       \"output_cost_per_token\": 4e-08,\n        \"litellm_provider\": \"azure_ai\",\n
        \       \"supports_function_calling\": true,\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.ministral-3b-2410-offer?tab=Overview\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Llama-3.2-11B-Vision-Instruct\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 2048,\n        \"input_cost_per_token\": 3.7e-07,\n
        \       \"output_cost_per_token\": 3.7e-07,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"mode\": \"chat\",\n        \"source\": \"https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-11b-vision-instruct-offer?tab=Overview\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Llama-3.3-70B-Instruct\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 2048,\n        \"input_cost_per_token\": 7.1e-07,\n
        \       \"output_cost_per_token\": 7.1e-07,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"supports_function_calling\": true,\n        \"mode\":
        \"chat\",\n        \"source\": \"https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.llama-3-3-70b-instruct-offer?tab=Overview\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Llama-4-Scout-17B-16E-Instruct\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 10000000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 2e-07,\n
        \       \"output_cost_per_token\": 7.8e-07,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"mode\": \"chat\",\n        \"source\": \"https://azure.microsoft.com/en-us/blog/introducing-the-llama-4-herd-in-azure-ai-foundry-and-azure-databricks/\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Llama-4-Maverick-17B-128E-Instruct-FP8\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 1.41e-06,\n
        \       \"output_cost_per_token\": 3.5e-07,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"mode\": \"chat\",\n        \"source\": \"https://azure.microsoft.com/en-us/blog/introducing-the-llama-4-herd-in-azure-ai-foundry-and-azure-databricks/\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Llama-3.2-90B-Vision-Instruct\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 2048,\n        \"input_cost_per_token\": 2.04e-06,\n
        \       \"output_cost_per_token\": 2.04e-06,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"mode\": \"chat\",\n        \"source\": \"https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-90b-vision-instruct-offer?tab=Overview\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Meta-Llama-3-70B-Instruct\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        2048,\n        \"input_cost_per_token\": 1.1e-06,\n        \"output_cost_per_token\":
        3.7e-07,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Meta-Llama-3.1-8B-Instruct\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 2048,\n        \"input_cost_per_token\": 3e-07,\n
        \       \"output_cost_per_token\": 6.1e-07,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"source\": \"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-8b-instruct-offer?tab=PlansAndPrice\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Meta-Llama-3.1-70B-Instruct\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 2048,\n        \"input_cost_per_token\": 2.68e-06,\n
        \       \"output_cost_per_token\": 3.54e-06,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"source\": \"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-70b-instruct-offer?tab=PlansAndPrice\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Meta-Llama-3.1-405B-Instruct\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 2048,\n        \"input_cost_per_token\": 5.33e-06,\n
        \       \"output_cost_per_token\": 1.6e-05,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"source\": \"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-405b-instruct-offer?tab=PlansAndPrice\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Phi-4-mini-instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 7.5e-08,\n
        \       \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\": \"azure_ai\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"source\": \"https://techcommunity.microsoft.com/blog/Azure-AI-Services-blog/announcing-new-phi-pricing-empowering-your-business-with-small-language-models/4395112\"\n
        \   },\n    \"azure_ai/Phi-4-multimodal-instruct\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 8e-08,\n        \"input_cost_per_audio_token\":
        4e-06,\n        \"output_cost_per_token\": 3.2e-07,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_audio_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"source\": \"https://techcommunity.microsoft.com/blog/Azure-AI-Services-blog/announcing-new-phi-pricing-empowering-your-business-with-small-language-models/4395112\"\n
        \   },\n    \"azure_ai/Phi-4\": {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\":
        16384,\n        \"max_output_tokens\": 16384,\n        \"input_cost_per_token\":
        1.25e-07,\n        \"output_cost_per_token\": 5e-07,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_vision\": false,\n
        \       \"source\": \"https://techcommunity.microsoft.com/blog/machinelearningblog/affordable-innovation-unveiling-the-pricing-of-phi-3-slms-on-models-as-a-service/4156495\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure_ai/Phi-3.5-mini-instruct\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.3e-07,\n        \"output_cost_per_token\":
        5.2e-07,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"chat\",\n
        \       \"supports_vision\": false,\n        \"source\": \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Phi-3.5-vision-instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 1.3e-07,\n
        \       \"output_cost_per_token\": 5.2e-07,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_vision\": true,\n
        \       \"source\": \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Phi-3.5-MoE-instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 1.6e-07,\n
        \       \"output_cost_per_token\": 6.4e-07,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_vision\": false,\n
        \       \"source\": \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Phi-3-mini-4k-instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.3e-07,\n        \"output_cost_per_token\":
        5.2e-07,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"chat\",\n
        \       \"supports_vision\": false,\n        \"source\": \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Phi-3-mini-128k-instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 1.3e-07,\n
        \       \"output_cost_per_token\": 5.2e-07,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_vision\": false,\n
        \       \"source\": \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Phi-3-small-8k-instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"chat\",\n
        \       \"supports_vision\": false,\n        \"source\": \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Phi-3-small-128k-instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 1.5e-07,\n
        \       \"output_cost_per_token\": 6e-07,\n        \"litellm_provider\": \"azure_ai\",\n
        \       \"mode\": \"chat\",\n        \"supports_vision\": false,\n        \"source\":
        \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\",\n        \"supports_tool_choice\":
        true\n    },\n    \"azure_ai/Phi-3-medium-4k-instruct\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.7e-07,\n        \"output_cost_per_token\":
        6.8e-07,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"chat\",\n
        \       \"supports_vision\": false,\n        \"source\": \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Phi-3-medium-128k-instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 1.7e-07,\n
        \       \"output_cost_per_token\": 6.8e-07,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_vision\": false,\n
        \       \"source\": \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/cohere-rerank-v3.5\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"max_query_tokens\": 2048,\n        \"input_cost_per_token\":
        0.0,\n        \"input_cost_per_query\": 0.002,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"rerank\"\n
        \   },\n    \"azure_ai/cohere-rerank-v3-multilingual\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"max_query_tokens\": 2048,\n        \"input_cost_per_token\":
        0.0,\n        \"input_cost_per_query\": 0.002,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"rerank\"\n
        \   },\n    \"azure_ai/cohere-rerank-v3-english\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"max_query_tokens\": 2048,\n        \"input_cost_per_token\":
        0.0,\n        \"input_cost_per_query\": 0.002,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"rerank\"\n
        \   },\n    \"azure_ai/Cohere-embed-v3-english\": {\n        \"max_tokens\":
        512,\n        \"max_input_tokens\": 512,\n        \"output_vector_size\":
        1024,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"embedding\",\n
        \       \"supports_embedding_image_input\": true,\n        \"source\": \"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice\"\n
        \   },\n    \"azure_ai/Cohere-embed-v3-multilingual\": {\n        \"max_tokens\":
        512,\n        \"max_input_tokens\": 512,\n        \"output_vector_size\":
        1024,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"embedding\",\n
        \       \"supports_embedding_image_input\": true,\n        \"source\": \"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice\"\n
        \   },\n    \"azure_ai/embed-v-4-0\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"output_vector_size\": 3072,\n
        \       \"input_cost_per_token\": 1.2e-07,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"embedding\",\n
        \       \"supports_embedding_image_input\": true,\n        \"supported_endpoints\":
        [\n            \"/v1/embeddings\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"source\":
        \"https://azuremarketplace.microsoft.com/pt-br/marketplace/apps/cohere.cohere-embed-4-offer?tab=PlansAndPrice\"\n
        \   },\n    \"azure_ai/FLUX-1.1-pro\": {\n        \"output_cost_per_image\":
        0.04,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"image_generation\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ],\n        \"source\": \"https://techcommunity.microsoft.com/blog/azure-ai-foundry-blog/black-forest-labs-flux-1-kontext-pro-and-flux1-1-pro-now-available-in-azure-ai-f/4434659\"\n
        \   },\n    \"azure_ai/FLUX.1-Kontext-pro\": {\n        \"output_cost_per_image\":
        0.04,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"image_generation\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ],\n        \"source\": \"https://azuremarketplace.microsoft.com/pt-br/marketplace/apps/cohere.cohere-embed-4-offer?tab=PlansAndPrice\"\n
        \   },\n    \"babbage-002\": {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\":
        16384,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        4e-07,\n        \"output_cost_per_token\": 4e-07,\n        \"litellm_provider\":
        \"text-completion-openai\",\n        \"mode\": \"completion\"\n    },\n    \"davinci-002\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 2e-06,\n
        \       \"output_cost_per_token\": 2e-06,\n        \"litellm_provider\": \"text-completion-openai\",\n
        \       \"mode\": \"completion\"\n    },\n    \"gpt-3.5-turbo-instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.5e-06,\n        \"output_cost_per_token\":
        2e-06,\n        \"litellm_provider\": \"text-completion-openai\",\n        \"mode\":
        \"completion\"\n    },\n    \"gpt-3.5-turbo-instruct-0914\": {\n        \"max_tokens\":
        4097,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        4097,\n        \"input_cost_per_token\": 1.5e-06,\n        \"output_cost_per_token\":
        2e-06,\n        \"litellm_provider\": \"text-completion-openai\",\n        \"mode\":
        \"completion\"\n    },\n    \"mistral/mistral-tiny\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 2.5e-07,\n        \"output_cost_per_token\":
        2.5e-07,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"mistral/mistral-small\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        3e-07,\n        \"litellm_provider\": \"mistral\",\n        \"supports_function_calling\":
        true,\n        \"mode\": \"chat\",\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"mistral/mistral-small-latest\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        3e-07,\n        \"litellm_provider\": \"mistral\",\n        \"supports_function_calling\":
        true,\n        \"mode\": \"chat\",\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"mistral/mistral-medium\": {\n        \"max_tokens\": 8191,\n
        \       \"max_input_tokens\": 32000,\n        \"max_output_tokens\": 8191,\n
        \       \"input_cost_per_token\": 2.7e-06,\n        \"output_cost_per_token\":
        8.1e-06,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"mistral/mistral-medium-latest\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 4e-07,\n
        \       \"output_cost_per_token\": 2e-06,\n        \"litellm_provider\": \"mistral\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"mistral/mistral-medium-2505\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 4e-07,\n
        \       \"output_cost_per_token\": 2e-06,\n        \"litellm_provider\": \"mistral\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"mistral/mistral-medium-2312\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 2.7e-06,\n        \"output_cost_per_token\":
        8.1e-06,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"mistral/mistral-large-latest\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        2e-06,\n        \"output_cost_per_token\": 6e-06,\n        \"litellm_provider\":
        \"mistral\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"mistral/mistral-large-2411\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        2e-06,\n        \"output_cost_per_token\": 6e-06,\n        \"litellm_provider\":
        \"mistral\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"mistral/mistral-large-2402\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 4e-06,\n        \"output_cost_per_token\":
        1.2e-05,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"mistral/mistral-large-2407\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        9e-06,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"mistral/pixtral-large-latest\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        6e-06,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"mistral/pixtral-large-2411\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        2e-06,\n        \"output_cost_per_token\": 6e-06,\n        \"litellm_provider\":
        \"mistral\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"mistral/pixtral-12b-2409\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        1.5e-07,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"mistral/open-mistral-7b\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 2.5e-07,\n        \"output_cost_per_token\":
        2.5e-07,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"mistral/open-mixtral-8x7b\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 7e-07,\n        \"output_cost_per_token\":
        7e-07,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"mistral/open-mixtral-8x22b\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 65336,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        6e-06,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"mistral/codestral-latest\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 1e-06,\n        \"output_cost_per_token\":
        3e-06,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"mistral/codestral-2405\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 1e-06,\n        \"output_cost_per_token\":
        3e-06,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"mistral/open-mistral-nemo\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        3e-07,\n        \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\":
        \"mistral\",\n        \"mode\": \"chat\",\n        \"source\": \"https://mistral.ai/technology/\",\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"mistral/open-mistral-nemo-2407\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        3e-07,\n        \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\":
        \"mistral\",\n        \"mode\": \"chat\",\n        \"source\": \"https://mistral.ai/technology/\",\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"mistral/open-codestral-mamba\":
        {\n        \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n
        \       \"max_output_tokens\": 256000,\n        \"input_cost_per_token\":
        2.5e-07,\n        \"output_cost_per_token\": 2.5e-07,\n        \"litellm_provider\":
        \"mistral\",\n        \"mode\": \"chat\",\n        \"source\": \"https://mistral.ai/technology/\",\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"mistral/codestral-mamba-latest\": {\n        \"max_tokens\":
        256000,\n        \"max_input_tokens\": 256000,\n        \"max_output_tokens\":
        256000,\n        \"input_cost_per_token\": 2.5e-07,\n        \"output_cost_per_token\":
        2.5e-07,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://mistral.ai/technology/\",\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"mistral/devstral-small-2505\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\":
        \"mistral\",\n        \"mode\": \"chat\",\n        \"source\": \"https://mistral.ai/news/devstral\",\n
        \       \"supports_function_calling\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"mistral/devstral-small-2507\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        3e-07,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://mistral.ai/news/devstral\",\n        \"supports_function_calling\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"mistral/devstral-medium-2507\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        4e-07,\n        \"output_cost_per_token\": 2e-06,\n        \"litellm_provider\":
        \"mistral\",\n        \"mode\": \"chat\",\n        \"source\": \"https://mistral.ai/news/devstral\",\n
        \       \"supports_function_calling\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"mistral/magistral-medium-latest\": {\n        \"max_tokens\":
        40000,\n        \"max_input_tokens\": 40000,\n        \"max_output_tokens\":
        40000,\n        \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        5e-06,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://mistral.ai/news/magistral\",\n        \"supports_function_calling\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"mistral/magistral-medium-2506\": {\n        \"max_tokens\":
        40000,\n        \"max_input_tokens\": 40000,\n        \"max_output_tokens\":
        40000,\n        \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        5e-06,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://mistral.ai/news/magistral\",\n        \"supports_function_calling\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"mistral/magistral-small-latest\": {\n        \"max_tokens\":
        40000,\n        \"max_input_tokens\": 40000,\n        \"max_output_tokens\":
        40000,\n        \"input_cost_per_token\": 5e-07,\n        \"output_cost_per_token\":
        1.5e-06,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://mistral.ai/pricing#api-pricing\",\n        \"supports_function_calling\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"mistral/magistral-small-2506\": {\n        \"max_tokens\":
        40000,\n        \"max_input_tokens\": 40000,\n        \"max_output_tokens\":
        40000,\n        \"input_cost_per_token\": 5e-07,\n        \"output_cost_per_token\":
        1.5e-06,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://mistral.ai/pricing#api-pricing\",\n        \"supports_function_calling\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"mistral/mistral-embed\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 8192,\n        \"input_cost_per_token\": 1e-07,\n
        \       \"litellm_provider\": \"mistral\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"deepseek/deepseek-reasoner\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 65536,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 5.5e-07,\n        \"input_cost_per_token_cache_hit\":
        1.4e-07,\n        \"output_cost_per_token\": 2.19e-06,\n        \"litellm_provider\":
        \"deepseek\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_prompt_caching\":
        true\n    },\n    \"deepseek/deepseek-chat\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 65536,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 2.7e-07,\n        \"input_cost_per_token_cache_hit\":
        7e-08,\n        \"cache_read_input_token_cost\": 7e-08,\n        \"cache_creation_input_token_cost\":
        0.0,\n        \"output_cost_per_token\": 1.1e-06,\n        \"litellm_provider\":
        \"deepseek\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_prompt_caching\": true\n    },\n    \"deepseek/deepseek-r1\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 65536,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 5.5e-07,\n        \"input_cost_per_token_cache_hit\":
        1.4e-07,\n        \"output_cost_per_token\": 2.19e-06,\n        \"litellm_provider\":
        \"deepseek\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_prompt_caching\":
        true\n    },\n    \"deepseek/deepseek-v3\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 65536,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 2.7e-07,\n        \"input_cost_per_token_cache_hit\":
        7e-08,\n        \"cache_read_input_token_cost\": 7e-08,\n        \"cache_creation_input_token_cost\":
        0.0,\n        \"output_cost_per_token\": 1.1e-06,\n        \"litellm_provider\":
        \"deepseek\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_prompt_caching\": true\n    },\n    \"codestral/codestral-latest\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"codestral\",\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://docs.mistral.ai/capabilities/code_generation/\",\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"codestral/codestral-2405\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"codestral\",\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://docs.mistral.ai/capabilities/code_generation/\",\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"text-completion-codestral/codestral-latest\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"text-completion-codestral\",\n        \"mode\":
        \"completion\",\n        \"source\": \"https://docs.mistral.ai/capabilities/code_generation/\"\n
        \   },\n    \"text-completion-codestral/codestral-2405\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"text-completion-codestral\",\n        \"mode\":
        \"completion\",\n        \"source\": \"https://docs.mistral.ai/capabilities/code_generation/\"\n
        \   },\n    \"xai/grok-beta\": {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\":
        131072,\n        \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        5e-06,\n        \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_web_search\": true\n    },\n    \"xai/grok-2-vision-1212\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 2e-06,\n
        \       \"input_cost_per_image\": 2e-06,\n        \"output_cost_per_token\":
        1e-05,\n        \"litellm_provider\": \"xai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_web_search\":
        true\n    },\n    \"xai/grok-2-vision-latest\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 2e-06,\n        \"input_cost_per_image\":
        2e-06,\n        \"output_cost_per_token\": 1e-05,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_web_search\": true\n    },\n    \"xai/grok-2-vision\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 2e-06,\n
        \       \"input_cost_per_image\": 2e-06,\n        \"output_cost_per_token\":
        1e-05,\n        \"litellm_provider\": \"xai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_web_search\":
        true\n    },\n    \"xai/grok-3\": {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\":
        131072,\n        \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        3e-06,\n        \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://x.ai/api#pricing\",\n        \"supports_web_search\":
        true\n    },\n    \"xai/grok-3-latest\": {\n        \"max_tokens\": 131072,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 131072,\n
        \       \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"litellm_provider\": \"xai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": false,\n        \"source\": \"https://x.ai/api#pricing\",\n
        \       \"supports_web_search\": true\n    },\n    \"xai/grok-3-beta\": {\n
        \       \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"litellm_provider\": \"xai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": false,\n        \"source\": \"https://x.ai/api#pricing\",\n
        \       \"supports_web_search\": true\n    },\n    \"xai/grok-3-fast-beta\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        5e-06,\n        \"output_cost_per_token\": 2.5e-05,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://x.ai/api#pricing\",\n        \"supports_web_search\":
        true\n    },\n    \"xai/grok-3-fast-latest\": {\n        \"max_tokens\": 131072,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 131072,\n
        \       \"input_cost_per_token\": 5e-06,\n        \"output_cost_per_token\":
        2.5e-05,\n        \"litellm_provider\": \"xai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": false,\n        \"source\": \"https://x.ai/api#pricing\",\n
        \       \"supports_web_search\": true\n    },\n    \"xai/grok-3-mini\": {\n
        \       \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        5e-07,\n        \"litellm_provider\": \"xai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://x.ai/api#pricing\",\n        \"supports_web_search\":
        true\n    },\n    \"xai/grok-3-mini-latest\": {\n        \"max_tokens\": 131072,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 131072,\n
        \       \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        5e-07,\n        \"litellm_provider\": \"xai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://x.ai/api#pricing\",\n        \"supports_web_search\":
        true\n    },\n    \"xai/grok-3-mini-fast\": {\n        \"max_tokens\": 131072,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 131072,\n
        \       \"input_cost_per_token\": 6e-07,\n        \"output_cost_per_token\":
        4e-06,\n        \"litellm_provider\": \"xai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://x.ai/api#pricing\",\n        \"supports_web_search\":
        true\n    },\n    \"xai/grok-3-mini-fast-latest\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 6e-07,\n        \"output_cost_per_token\":
        4e-06,\n        \"litellm_provider\": \"xai\",\n        \"mode\": \"chat\",\n
        \       \"supports_reasoning\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://x.ai/api#pricing\",\n        \"supports_web_search\":
        true\n    },\n    \"xai/grok-3-mini-beta\": {\n        \"max_tokens\": 131072,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 131072,\n
        \       \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        5e-07,\n        \"litellm_provider\": \"xai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://x.ai/api#pricing\",\n        \"supports_web_search\":
        true\n    },\n    \"xai/grok-3-mini-fast-beta\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 6e-07,\n        \"output_cost_per_token\":
        4e-06,\n        \"litellm_provider\": \"xai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://x.ai/api#pricing\",\n        \"supports_web_search\":
        true\n    },\n    \"xai/grok-vision-beta\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 8192,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 5e-06,\n        \"input_cost_per_image\":
        5e-06,\n        \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_web_search\": true\n    },\n    \"xai/grok-2-1212\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        2e-06,\n        \"output_cost_per_token\": 1e-05,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_web_search\":
        true\n    },\n    \"xai/grok-2\": {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\":
        131072,\n        \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        2e-06,\n        \"output_cost_per_token\": 1e-05,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_web_search\":
        true\n    },\n    \"xai/grok-2-latest\": {\n        \"max_tokens\": 131072,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 131072,\n
        \       \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        1e-05,\n        \"litellm_provider\": \"xai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_web_search\": true\n    },\n    \"xai/grok-4\":
        {\n        \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n
        \       \"max_output_tokens\": 256000,\n        \"input_cost_per_token\":
        3e-06,\n        \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"source\": \"https://docs.x.ai/docs/models\",\n        \"supports_web_search\":
        true\n    },\n    \"xai/grok-4-0709\": {\n        \"max_tokens\": 256000,\n
        \       \"max_input_tokens\": 256000,\n        \"max_output_tokens\": 256000,\n
        \       \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"litellm_provider\": \"xai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"source\": \"https://docs.x.ai/docs/models\",\n
        \       \"supports_web_search\": true\n    },\n    \"xai/grok-4-latest\":
        {\n        \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n
        \       \"max_output_tokens\": 256000,\n        \"input_cost_per_token\":
        3e-06,\n        \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"source\": \"https://docs.x.ai/docs/models\",\n        \"supports_web_search\":
        true\n    },\n    \"deepseek/deepseek-coder\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.4e-07,\n        \"input_cost_per_token_cache_hit\":
        1.4e-08,\n        \"output_cost_per_token\": 2.8e-07,\n        \"litellm_provider\":
        \"deepseek\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_prompt_caching\": true\n    },\n    \"groq/deepseek-r1-distill-llama-70b\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        7.5e-07,\n        \"output_cost_per_token\": 9.9e-07,\n        \"litellm_provider\":
        \"groq\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"groq/llama-3.3-70b-versatile\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 5.9e-07,\n
        \       \"output_cost_per_token\": 7.9e-07,\n        \"litellm_provider\":
        \"groq\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"groq/llama-3.3-70b-specdec\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 5.9e-07,\n        \"output_cost_per_token\":
        9.9e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true,\n        \"deprecation_date\": \"2025-04-14\"\n
        \   },\n    \"groq/llama-guard-3-8b\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 8192,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        2e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\"\n
        \   },\n    \"groq/llama2-70b-4096\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        4096,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        7e-07,\n        \"output_cost_per_token\": 8e-07,\n        \"litellm_provider\":
        \"groq\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"groq/llama3-8b-8192\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 8192,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 5e-08,\n        \"output_cost_per_token\":
        8e-08,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"groq/llama-3.2-1b-preview\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 4e-08,\n        \"output_cost_per_token\":
        4e-08,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2025-04-14\"\n    },\n    \"groq/llama-3.2-3b-preview\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 6e-08,\n        \"output_cost_per_token\":
        6e-08,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2025-04-14\"\n    },\n    \"groq/llama-3.2-11b-text-preview\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 1.8e-07,\n        \"output_cost_per_token\":
        1.8e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2024-10-28\"\n    },\n    \"groq/llama-3.2-11b-vision-preview\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 1.8e-07,\n        \"output_cost_per_token\":
        1.8e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true,\n        \"deprecation_date\": \"2025-04-14\"\n    },\n    \"groq/llama-3.2-90b-text-preview\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 9e-07,\n        \"output_cost_per_token\":
        9e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2024-11-25\"\n    },\n    \"groq/llama-3.2-90b-vision-preview\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 9e-07,\n        \"output_cost_per_token\":
        9e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true,\n        \"deprecation_date\": \"2025-04-14\"\n    },\n    \"groq/llama3-70b-8192\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 5.9e-07,\n        \"output_cost_per_token\":
        7.9e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"groq/llama-3.1-8b-instant\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 5e-08,\n        \"output_cost_per_token\":
        8e-08,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"groq/llama-3.1-70b-versatile\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 5.9e-07,\n        \"output_cost_per_token\":
        7.9e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2025-01-24\"\n    },\n    \"groq/llama-3.1-405b-reasoning\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 5.9e-07,\n        \"output_cost_per_token\":
        7.9e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"groq/meta-llama/llama-4-scout-17b-16e-instruct\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 1.1e-07,\n
        \       \"output_cost_per_token\": 3.4e-07,\n        \"litellm_provider\":
        \"groq\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"groq/meta-llama/llama-4-maverick-17b-128e-instruct\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 2e-07,\n
        \       \"output_cost_per_token\": 6e-07,\n        \"litellm_provider\": \"groq\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"groq/mistral-saba-24b\": {\n        \"max_tokens\": 32000,\n
        \       \"max_input_tokens\": 32000,\n        \"max_output_tokens\": 32000,\n
        \       \"input_cost_per_token\": 7.9e-07,\n        \"output_cost_per_token\":
        7.9e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\"\n
        \   },\n    \"groq/mixtral-8x7b-32768\": {\n        \"max_tokens\": 32768,\n
        \       \"max_input_tokens\": 32768,\n        \"max_output_tokens\": 32768,\n
        \       \"input_cost_per_token\": 2.4e-07,\n        \"output_cost_per_token\":
        2.4e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2025-03-20\"\n    },\n    \"groq/gemma-7b-it\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 7e-08,\n        \"output_cost_per_token\":
        7e-08,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2024-12-18\"\n    },\n    \"groq/gemma2-9b-it\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        2e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": false,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": false\n    },\n    \"groq/llama3-groq-70b-8192-tool-use-preview\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 8.9e-07,\n        \"output_cost_per_token\":
        8.9e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2025-01-06\"\n    },\n    \"groq/llama3-groq-8b-8192-tool-use-preview\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 1.9e-07,\n        \"output_cost_per_token\":
        1.9e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2025-01-06\"\n    },\n    \"groq/qwen/qwen3-32b\": {\n        \"max_tokens\":
        131000,\n        \"max_input_tokens\": 131000,\n        \"max_output_tokens\":
        131000,\n        \"input_cost_per_token\": 2.9e-07,\n        \"output_cost_per_token\":
        5.9e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"groq/moonshotai/kimi-k2-instruct\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 1e-06,\n        \"output_cost_per_token\":
        3e-06,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"groq/playai-tts\":
        {\n        \"max_tokens\": 10000,\n        \"max_input_tokens\": 10000,\n
        \       \"max_output_tokens\": 10000,\n        \"input_cost_per_character\":
        5e-05,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"audio_speech\"\n
        \   },\n    \"groq/whisper-large-v3\": {\n        \"input_cost_per_second\":
        3.083e-05,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"groq\",\n        \"mode\": \"audio_transcription\"\n    },\n    \"groq/whisper-large-v3-turbo\":
        {\n        \"input_cost_per_second\": 1.111e-05,\n        \"output_cost_per_second\":
        0.0,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"audio_transcription\"\n
        \   },\n    \"groq/distil-whisper-large-v3-en\": {\n        \"input_cost_per_second\":
        5.56e-06,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"groq\",\n        \"mode\": \"audio_transcription\"\n    },\n    \"groq/openai/gpt-oss-20b\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 1e-07,\n
        \       \"output_cost_per_token\": 5e-07,\n        \"litellm_provider\": \"groq\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_web_search\": true\n    },\n    \"groq/openai/gpt-oss-120b\":
        {\n        \"max_tokens\": 32766,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 32766,\n        \"input_cost_per_token\": 1.5e-07,\n
        \       \"output_cost_per_token\": 7.5e-07,\n        \"litellm_provider\":
        \"groq\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_web_search\": true\n    },\n    \"cerebras/llama3.1-8b\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 1e-07,\n        \"litellm_provider\":
        \"cerebras\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"cerebras/llama3.1-70b\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        6e-07,\n        \"output_cost_per_token\": 6e-07,\n        \"litellm_provider\":
        \"cerebras\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"cerebras/llama-3.3-70b\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        8.5e-07,\n        \"output_cost_per_token\": 1.2e-06,\n        \"litellm_provider\":
        \"cerebras\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"cerebras/qwen-3-32b\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        4e-07,\n        \"output_cost_per_token\": 8e-07,\n        \"litellm_provider\":
        \"cerebras\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"source\": \"https://inference-docs.cerebras.ai/support/pricing\"\n
        \   },\n    \"cerebras/openai/gpt-oss-20b\": {\n        \"max_tokens\": 32768,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 32768,\n
        \       \"input_cost_per_token\": 7e-08,\n        \"output_cost_per_token\":
        3e-07,\n        \"litellm_provider\": \"cerebras\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true,\n        \"source\": \"https://inference-docs.cerebras.ai/support/pricing\"\n
        \   },\n    \"cerebras/openai/gpt-oss-120b\": {\n        \"max_tokens\": 32768,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 32768,\n
        \       \"input_cost_per_token\": 2.5e-07,\n        \"output_cost_per_token\":
        6.9e-07,\n        \"litellm_provider\": \"cerebras\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true,\n        \"source\": \"https://www.cerebras.ai/blog/openai-gpt-oss-120b-runs-fastest-on-cerebras\"\n
        \   },\n    \"friendliai/meta-llama-3.1-8b-instruct\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        1e-07,\n        \"litellm_provider\": \"friendliai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"friendliai/meta-llama-3.1-70b-instruct\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 6e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"litellm_provider\": \"friendliai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"claude-3-haiku-20240307\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 2.5e-07,\n
        \       \"output_cost_per_token\": 1.25e-06,\n        \"cache_creation_input_token_cost\":
        3e-07,\n        \"cache_read_input_token_cost\": 3e-08,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        264,\n        \"supports_assistant_prefill\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"deprecation_date\":
        \"2025-03-01\",\n        \"supports_tool_choice\": true\n    },\n    \"claude-3-5-haiku-20241022\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 8e-07,\n
        \       \"output_cost_per_token\": 4e-06,\n        \"cache_creation_input_token_cost\":
        1e-06,\n        \"cache_read_input_token_cost\": 8e-08,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.01,\n            \"search_context_size_medium\":
        0.01,\n            \"search_context_size_high\": 0.01\n        },\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        264,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"deprecation_date\": \"2025-10-01\",\n        \"supports_tool_choice\":
        true,\n        \"supports_web_search\": true\n    },\n    \"claude-3-5-haiku-latest\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 1e-06,\n
        \       \"output_cost_per_token\": 5e-06,\n        \"cache_creation_input_token_cost\":
        1.25e-06,\n        \"cache_read_input_token_cost\": 1e-07,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.01,\n            \"search_context_size_medium\":
        0.01,\n            \"search_context_size_high\": 0.01\n        },\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        264,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"deprecation_date\": \"2025-10-01\",\n        \"supports_tool_choice\":
        true,\n        \"supports_web_search\": true\n    },\n    \"claude-3-opus-latest\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 1.5e-05,\n
        \       \"output_cost_per_token\": 7.5e-05,\n        \"cache_creation_input_token_cost\":
        1.875e-05,\n        \"cache_read_input_token_cost\": 1.5e-06,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        395,\n        \"supports_assistant_prefill\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"deprecation_date\":
        \"2025-03-01\",\n        \"supports_tool_choice\": true\n    },\n    \"claude-3-opus-20240229\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 1.5e-05,\n
        \       \"output_cost_per_token\": 7.5e-05,\n        \"cache_creation_input_token_cost\":
        1.875e-05,\n        \"cache_read_input_token_cost\": 1.5e-06,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        395,\n        \"supports_assistant_prefill\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"deprecation_date\":
        \"2025-03-01\",\n        \"supports_tool_choice\": true\n    },\n    \"claude-3-5-sonnet-latest\":
        {\n        \"supports_computer_use\": true,\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"cache_creation_input_token_cost\": 3.75e-06,\n        \"cache_read_input_token_cost\":
        3e-07,\n        \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        0.01,\n            \"search_context_size_medium\": 0.01,\n            \"search_context_size_high\":
        0.01\n        },\n        \"litellm_provider\": \"anthropic\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"tool_use_system_prompt_tokens\": 159,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"deprecation_date\":
        \"2025-06-01\",\n        \"supports_tool_choice\": true,\n        \"supports_web_search\":
        true\n    },\n    \"claude-3-5-sonnet-20240620\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"cache_creation_input_token_cost\": 3.75e-06,\n        \"cache_read_input_token_cost\":
        3e-07,\n        \"litellm_provider\": \"anthropic\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"tool_use_system_prompt_tokens\": 159,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"deprecation_date\":
        \"2025-06-01\",\n        \"supports_tool_choice\": true\n    },\n    \"claude-opus-4-20250514\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 32000,\n        \"input_cost_per_token\": 1.5e-05,\n
        \       \"output_cost_per_token\": 7.5e-05,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.01,\n            \"search_context_size_medium\":
        0.01,\n            \"search_context_size_high\": 0.01\n        },\n        \"cache_creation_input_token_cost\":
        1.875e-05,\n        \"cache_read_input_token_cost\": 1.5e-06,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"claude-opus-4-1\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 32000,\n        \"input_cost_per_token\": 1.5e-05,\n
        \       \"output_cost_per_token\": 7.5e-05,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.01,\n            \"search_context_size_medium\":
        0.01,\n            \"search_context_size_high\": 0.01\n        },\n        \"cache_creation_input_token_cost\":
        1.875e-05,\n        \"cache_read_input_token_cost\": 1.5e-06,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"claude-opus-4-1-20250805\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 32000,\n        \"input_cost_per_token\": 1.5e-05,\n
        \       \"output_cost_per_token\": 7.5e-05,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.01,\n            \"search_context_size_medium\":
        0.01,\n            \"search_context_size_high\": 0.01\n        },\n        \"cache_creation_input_token_cost\":
        1.875e-05,\n        \"cache_read_input_token_cost\": 1.5e-06,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"claude-sonnet-4-20250514\":
        {\n        \"max_tokens\": 64000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 64000,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.01,\n            \"search_context_size_medium\":
        0.01,\n            \"search_context_size_high\": 0.01\n        },\n        \"cache_creation_input_token_cost\":
        3.75e-06,\n        \"cache_read_input_token_cost\": 3e-07,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"claude-4-opus-20250514\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 32000,\n        \"input_cost_per_token\": 1.5e-05,\n
        \       \"output_cost_per_token\": 7.5e-05,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.01,\n            \"search_context_size_medium\":
        0.01,\n            \"search_context_size_high\": 0.01\n        },\n        \"cache_creation_input_token_cost\":
        1.875e-05,\n        \"cache_read_input_token_cost\": 1.5e-06,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"claude-4-sonnet-20250514\":
        {\n        \"max_tokens\": 1000000,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 1000000,\n        \"input_cost_per_token\":
        3e-06,\n        \"output_cost_per_token\": 1.5e-05,\n        \"input_cost_per_token_above_200k_tokens\":
        6e-06,\n        \"output_cost_per_token_above_200k_tokens\": 2.25e-05,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.01,\n            \"search_context_size_medium\":
        0.01,\n            \"search_context_size_high\": 0.01\n        },\n        \"cache_creation_input_token_cost\":
        3.75e-06,\n        \"cache_read_input_token_cost\": 3e-07,\n        \"cache_creation_input_token_cost_above_200k_tokens\":
        7.5e-06,\n        \"cache_read_input_token_cost_above_200k_tokens\": 6e-07,\n
        \       \"litellm_provider\": \"anthropic\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"tool_use_system_prompt_tokens\": 159,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_computer_use\":
        true\n    },\n    \"claude-3-7-sonnet-latest\": {\n        \"supports_computer_use\":
        true,\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        3e-06,\n        \"output_cost_per_token\": 1.5e-05,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.01,\n            \"search_context_size_medium\":
        0.01,\n            \"search_context_size_high\": 0.01\n        },\n        \"cache_creation_input_token_cost\":
        3.75e-06,\n        \"cache_read_input_token_cost\": 3e-07,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"deprecation_date\": \"2025-06-01\",\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"claude-3-7-sonnet-20250219\":
        {\n        \"supports_computer_use\": true,\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 128000,\n
        \       \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"cache_creation_input_token_cost\": 3.75e-06,\n        \"cache_read_input_token_cost\":
        3e-07,\n        \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        0.01,\n            \"search_context_size_medium\": 0.01,\n            \"search_context_size_high\":
        0.01\n        },\n        \"litellm_provider\": \"anthropic\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"tool_use_system_prompt_tokens\": 159,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"deprecation_date\":
        \"2026-02-01\",\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_web_search\": true\n    },\n    \"claude-3-5-sonnet-20241022\":
        {\n        \"supports_computer_use\": true,\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"cache_creation_input_token_cost\": 3.75e-06,\n        \"cache_read_input_token_cost\":
        3e-07,\n        \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        0.01,\n            \"search_context_size_medium\": 0.01,\n            \"search_context_size_high\":
        0.01\n        },\n        \"litellm_provider\": \"anthropic\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"tool_use_system_prompt_tokens\": 159,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"deprecation_date\":
        \"2025-10-01\",\n        \"supports_tool_choice\": true,\n        \"supports_web_search\":
        true\n    },\n    \"text-bison\": {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 2048,\n        \"input_cost_per_character\":
        2.5e-07,\n        \"output_cost_per_character\": 5e-07,\n        \"litellm_provider\":
        \"vertex_ai-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"text-bison@001\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_character\":
        2.5e-07,\n        \"output_cost_per_character\": 5e-07,\n        \"litellm_provider\":
        \"vertex_ai-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"text-bison@002\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_character\":
        2.5e-07,\n        \"output_cost_per_character\": 5e-07,\n        \"litellm_provider\":
        \"vertex_ai-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"text-bison32k\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        1.25e-07,\n        \"output_cost_per_token\": 1.25e-07,\n        \"input_cost_per_character\":
        2.5e-07,\n        \"output_cost_per_character\": 5e-07,\n        \"litellm_provider\":
        \"vertex_ai-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"text-bison32k@002\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        1.25e-07,\n        \"output_cost_per_token\": 1.25e-07,\n        \"input_cost_per_character\":
        2.5e-07,\n        \"output_cost_per_character\": 5e-07,\n        \"litellm_provider\":
        \"vertex_ai-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"text-unicorn\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        1e-05,\n        \"output_cost_per_token\": 2.8e-05,\n        \"litellm_provider\":
        \"vertex_ai-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"text-unicorn@001\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        1e-05,\n        \"output_cost_per_token\": 2.8e-05,\n        \"litellm_provider\":
        \"vertex_ai-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"chat-bison\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        1.25e-07,\n        \"output_cost_per_token\": 1.25e-07,\n        \"input_cost_per_character\":
        2.5e-07,\n        \"output_cost_per_character\": 5e-07,\n        \"litellm_provider\":
        \"vertex_ai-chat-models\",\n        \"mode\": \"chat\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"chat-bison@001\": {\n
        \       \"max_tokens\": 4096,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.25e-07,\n        \"output_cost_per_token\":
        1.25e-07,\n        \"input_cost_per_character\": 2.5e-07,\n        \"output_cost_per_character\":
        5e-07,\n        \"litellm_provider\": \"vertex_ai-chat-models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"chat-bison@002\": {\n
        \       \"max_tokens\": 4096,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.25e-07,\n        \"output_cost_per_token\":
        1.25e-07,\n        \"input_cost_per_character\": 2.5e-07,\n        \"output_cost_per_character\":
        5e-07,\n        \"litellm_provider\": \"vertex_ai-chat-models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"deprecation_date\": \"2025-04-09\",\n        \"supports_tool_choice\":
        true\n    },\n    \"chat-bison-32k\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        32000,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        1.25e-07,\n        \"output_cost_per_token\": 1.25e-07,\n        \"input_cost_per_character\":
        2.5e-07,\n        \"output_cost_per_character\": 5e-07,\n        \"litellm_provider\":
        \"vertex_ai-chat-models\",\n        \"mode\": \"chat\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"chat-bison-32k@002\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 1.25e-07,\n        \"output_cost_per_token\":
        1.25e-07,\n        \"input_cost_per_character\": 2.5e-07,\n        \"output_cost_per_character\":
        5e-07,\n        \"litellm_provider\": \"vertex_ai-chat-models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"code-bison\": {\n        \"max_tokens\":
        1024,\n        \"max_input_tokens\": 6144,\n        \"max_output_tokens\":
        1024,\n        \"input_cost_per_token\": 1.25e-07,\n        \"output_cost_per_token\":
        1.25e-07,\n        \"input_cost_per_character\": 2.5e-07,\n        \"output_cost_per_character\":
        5e-07,\n        \"litellm_provider\": \"vertex_ai-code-text-models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"code-bison@001\": {\n
        \       \"max_tokens\": 1024,\n        \"max_input_tokens\": 6144,\n        \"max_output_tokens\":
        1024,\n        \"input_cost_per_token\": 1.25e-07,\n        \"output_cost_per_token\":
        1.25e-07,\n        \"input_cost_per_character\": 2.5e-07,\n        \"output_cost_per_character\":
        5e-07,\n        \"litellm_provider\": \"vertex_ai-code-text-models\",\n        \"mode\":
        \"completion\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-bison@002\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        6144,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        1.25e-07,\n        \"output_cost_per_token\": 1.25e-07,\n        \"input_cost_per_character\":
        2.5e-07,\n        \"output_cost_per_character\": 5e-07,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-bison32k\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        6144,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        1.25e-07,\n        \"output_cost_per_token\": 1.25e-07,\n        \"input_cost_per_character\":
        2.5e-07,\n        \"output_cost_per_character\": 5e-07,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-bison-32k@002\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        6144,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        1.25e-07,\n        \"output_cost_per_token\": 1.25e-07,\n        \"input_cost_per_character\":
        2.5e-07,\n        \"output_cost_per_character\": 5e-07,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-gecko@001\": {\n        \"max_tokens\": 64,\n        \"max_input_tokens\":
        2048,\n        \"max_output_tokens\": 64,\n        \"input_cost_per_token\":
        1.25e-07,\n        \"output_cost_per_token\": 1.25e-07,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-gecko@002\": {\n        \"max_tokens\": 64,\n        \"max_input_tokens\":
        2048,\n        \"max_output_tokens\": 64,\n        \"input_cost_per_token\":
        1.25e-07,\n        \"output_cost_per_token\": 1.25e-07,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-gecko\": {\n        \"max_tokens\": 64,\n        \"max_input_tokens\":
        2048,\n        \"max_output_tokens\": 64,\n        \"input_cost_per_token\":
        1.25e-07,\n        \"output_cost_per_token\": 1.25e-07,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-gecko-latest\": {\n        \"max_tokens\": 64,\n        \"max_input_tokens\":
        2048,\n        \"max_output_tokens\": 64,\n        \"input_cost_per_token\":
        1.25e-07,\n        \"output_cost_per_token\": 1.25e-07,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"codechat-bison@latest\": {\n        \"max_tokens\": 1024,\n
        \       \"max_input_tokens\": 6144,\n        \"max_output_tokens\": 1024,\n
        \       \"input_cost_per_token\": 1.25e-07,\n        \"output_cost_per_token\":
        1.25e-07,\n        \"input_cost_per_character\": 2.5e-07,\n        \"output_cost_per_character\":
        5e-07,\n        \"litellm_provider\": \"vertex_ai-code-chat-models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"codechat-bison\": {\n
        \       \"max_tokens\": 1024,\n        \"max_input_tokens\": 6144,\n        \"max_output_tokens\":
        1024,\n        \"input_cost_per_token\": 1.25e-07,\n        \"output_cost_per_token\":
        1.25e-07,\n        \"input_cost_per_character\": 2.5e-07,\n        \"output_cost_per_character\":
        5e-07,\n        \"litellm_provider\": \"vertex_ai-code-chat-models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"codechat-bison@001\":
        {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\": 6144,\n        \"max_output_tokens\":
        1024,\n        \"input_cost_per_token\": 1.25e-07,\n        \"output_cost_per_token\":
        1.25e-07,\n        \"input_cost_per_character\": 2.5e-07,\n        \"output_cost_per_character\":
        5e-07,\n        \"litellm_provider\": \"vertex_ai-code-chat-models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"codechat-bison@002\":
        {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\": 6144,\n        \"max_output_tokens\":
        1024,\n        \"input_cost_per_token\": 1.25e-07,\n        \"output_cost_per_token\":
        1.25e-07,\n        \"input_cost_per_character\": 2.5e-07,\n        \"output_cost_per_character\":
        5e-07,\n        \"litellm_provider\": \"vertex_ai-code-chat-models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"codechat-bison-32k\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 1.25e-07,\n        \"output_cost_per_token\":
        1.25e-07,\n        \"input_cost_per_character\": 2.5e-07,\n        \"output_cost_per_character\":
        5e-07,\n        \"litellm_provider\": \"vertex_ai-code-chat-models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"codechat-bison-32k@002\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 1.25e-07,\n        \"output_cost_per_token\":
        1.25e-07,\n        \"input_cost_per_character\": 2.5e-07,\n        \"output_cost_per_character\":
        5e-07,\n        \"litellm_provider\": \"vertex_ai-code-chat-models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 10000000,\n
        \       \"max_output_tokens\": 4028,\n        \"litellm_provider\": \"meta_llama\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"source\": \"https://llama.developer.meta.com/docs/models\",\n        \"supports_tool_choice\":
        true,\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ]\n    },\n    \"meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 4028,\n        \"litellm_provider\": \"meta_llama\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"source\": \"https://llama.developer.meta.com/docs/models\",\n        \"supports_tool_choice\":
        true,\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ]\n    },\n    \"meta_llama/Llama-3.3-70B-Instruct\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4028,\n        \"litellm_provider\": \"meta_llama\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"source\": \"https://llama.developer.meta.com/docs/models\",\n
        \       \"supports_tool_choice\": true,\n        \"supported_modalities\":
        [\n            \"text\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ]\n    },\n    \"meta_llama/Llama-3.3-8B-Instruct\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4028,\n        \"litellm_provider\": \"meta_llama\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"source\": \"https://llama.developer.meta.com/docs/models\",\n        \"supports_tool_choice\":
        true,\n        \"supported_modalities\": [\n            \"text\"\n        ],\n
        \       \"supported_output_modalities\": [\n            \"text\"\n        ]\n
        \   },\n    \"gemini-pro\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        32760,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_image\":
        0.0025,\n        \"input_cost_per_video_per_second\": 0.002,\n        \"input_cost_per_token\":
        5e-07,\n        \"input_cost_per_character\": 1.25e-07,\n        \"output_cost_per_token\":
        1.5e-06,\n        \"output_cost_per_character\": 3.75e-07,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\",\n        \"supports_tool_choice\":
        true\n    },\n    \"gemini-1.0-pro\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        32760,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_image\":
        0.0025,\n        \"input_cost_per_video_per_second\": 0.002,\n        \"input_cost_per_token\":
        5e-07,\n        \"input_cost_per_character\": 1.25e-07,\n        \"output_cost_per_token\":
        1.5e-06,\n        \"output_cost_per_character\": 3.75e-07,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing#google_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini-1.0-pro-001\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 32760,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_image\": 0.0025,\n        \"input_cost_per_video_per_second\":
        0.002,\n        \"input_cost_per_token\": 5e-07,\n        \"input_cost_per_character\":
        1.25e-07,\n        \"output_cost_per_token\": 1.5e-06,\n        \"output_cost_per_character\":
        3.75e-07,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"deprecation_date\": \"2025-04-09\",\n        \"supports_tool_choice\":
        true,\n        \"supports_parallel_function_calling\": true\n    },\n    \"gemini-1.0-ultra\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        2048,\n        \"input_cost_per_image\": 0.0025,\n        \"input_cost_per_video_per_second\":
        0.002,\n        \"input_cost_per_token\": 5e-07,\n        \"input_cost_per_character\":
        1.25e-07,\n        \"output_cost_per_token\": 1.5e-06,\n        \"output_cost_per_character\":
        3.75e-07,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"source\": \"As of Jun, 2024. There is no available doc on vertex
        ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens
        info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true,\n        \"supports_parallel_function_calling\":
        true\n    },\n    \"gemini-1.0-ultra-001\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 8192,\n        \"max_output_tokens\": 2048,\n
        \       \"input_cost_per_image\": 0.0025,\n        \"input_cost_per_video_per_second\":
        0.002,\n        \"input_cost_per_token\": 5e-07,\n        \"input_cost_per_character\":
        1.25e-07,\n        \"output_cost_per_token\": 1.5e-06,\n        \"output_cost_per_character\":
        3.75e-07,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"source\": \"As of Jun, 2024. There is no available doc on vertex
        ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens
        info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true,\n        \"supports_parallel_function_calling\":
        true\n    },\n    \"gemini-1.0-pro-002\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 32760,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_image\": 0.0025,\n        \"input_cost_per_video_per_second\":
        0.002,\n        \"input_cost_per_token\": 5e-07,\n        \"input_cost_per_character\":
        1.25e-07,\n        \"output_cost_per_token\": 1.5e-06,\n        \"output_cost_per_character\":
        3.75e-07,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"deprecation_date\": \"2025-04-09\",\n        \"supports_tool_choice\":
        true,\n        \"supports_parallel_function_calling\": true\n    },\n    \"gemini-1.5-pro\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 2097152,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_image\": 0.00032875,\n
        \       \"input_cost_per_audio_per_second\": 3.125e-05,\n        \"input_cost_per_video_per_second\":
        0.00032875,\n        \"input_cost_per_token\": 1.25e-06,\n        \"input_cost_per_character\":
        3.125e-07,\n        \"input_cost_per_image_above_128k_tokens\": 0.0006575,\n
        \       \"input_cost_per_video_per_second_above_128k_tokens\": 0.0006575,\n
        \       \"input_cost_per_audio_per_second_above_128k_tokens\": 6.25e-05,\n
        \       \"input_cost_per_token_above_128k_tokens\": 2.5e-06,\n        \"input_cost_per_character_above_128k_tokens\":
        6.25e-07,\n        \"output_cost_per_token\": 5e-06,\n        \"output_cost_per_character\":
        1.25e-06,\n        \"output_cost_per_token_above_128k_tokens\": 1e-05,\n        \"output_cost_per_character_above_128k_tokens\":
        2.5e-06,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_parallel_function_calling\": true\n    },\n    \"gemini-1.5-pro-002\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 2097152,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_image\": 0.00032875,\n
        \       \"input_cost_per_audio_per_second\": 3.125e-05,\n        \"input_cost_per_video_per_second\":
        0.00032875,\n        \"input_cost_per_token\": 1.25e-06,\n        \"input_cost_per_character\":
        3.125e-07,\n        \"input_cost_per_image_above_128k_tokens\": 0.0006575,\n
        \       \"input_cost_per_video_per_second_above_128k_tokens\": 0.0006575,\n
        \       \"input_cost_per_audio_per_second_above_128k_tokens\": 6.25e-05,\n
        \       \"input_cost_per_token_above_128k_tokens\": 2.5e-06,\n        \"input_cost_per_character_above_128k_tokens\":
        6.25e-07,\n        \"output_cost_per_token\": 5e-06,\n        \"output_cost_per_character\":
        1.25e-06,\n        \"output_cost_per_token_above_128k_tokens\": 1e-05,\n        \"output_cost_per_character_above_128k_tokens\":
        2.5e-06,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_vision\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-pro\",\n
        \       \"deprecation_date\": \"2025-09-24\",\n        \"supports_parallel_function_calling\":
        true\n    },\n    \"gemini-1.5-pro-001\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 1000000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_image\": 0.00032875,\n        \"input_cost_per_audio_per_second\":
        3.125e-05,\n        \"input_cost_per_video_per_second\": 0.00032875,\n        \"input_cost_per_token\":
        1.25e-06,\n        \"input_cost_per_character\": 3.125e-07,\n        \"input_cost_per_image_above_128k_tokens\":
        0.0006575,\n        \"input_cost_per_video_per_second_above_128k_tokens\":
        0.0006575,\n        \"input_cost_per_audio_per_second_above_128k_tokens\":
        6.25e-05,\n        \"input_cost_per_token_above_128k_tokens\": 2.5e-06,\n
        \       \"input_cost_per_character_above_128k_tokens\": 6.25e-07,\n        \"output_cost_per_token\":
        5e-06,\n        \"output_cost_per_character\": 1.25e-06,\n        \"output_cost_per_token_above_128k_tokens\":
        1e-05,\n        \"output_cost_per_character_above_128k_tokens\": 2.5e-06,\n
        \       \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_vision\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"deprecation_date\": \"2025-05-24\",\n        \"supports_parallel_function_calling\":
        true\n    },\n    \"gemini-1.5-pro-preview-0514\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1000000,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_image\": 0.00032875,\n        \"input_cost_per_audio_per_second\":
        3.125e-05,\n        \"input_cost_per_video_per_second\": 0.00032875,\n        \"input_cost_per_token\":
        7.8125e-08,\n        \"input_cost_per_character\": 3.125e-07,\n        \"input_cost_per_image_above_128k_tokens\":
        0.0006575,\n        \"input_cost_per_video_per_second_above_128k_tokens\":
        0.0006575,\n        \"input_cost_per_audio_per_second_above_128k_tokens\":
        6.25e-05,\n        \"input_cost_per_token_above_128k_tokens\": 1.5625e-07,\n
        \       \"input_cost_per_character_above_128k_tokens\": 6.25e-07,\n        \"output_cost_per_token\":
        3.125e-07,\n        \"output_cost_per_character\": 1.25e-06,\n        \"output_cost_per_token_above_128k_tokens\":
        6.25e-07,\n        \"output_cost_per_character_above_128k_tokens\": 2.5e-06,\n
        \       \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_parallel_function_calling\": true\n    },\n    \"gemini-1.5-pro-preview-0215\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_image\": 0.00032875,\n
        \       \"input_cost_per_audio_per_second\": 3.125e-05,\n        \"input_cost_per_video_per_second\":
        0.00032875,\n        \"input_cost_per_token\": 7.8125e-08,\n        \"input_cost_per_character\":
        3.125e-07,\n        \"input_cost_per_image_above_128k_tokens\": 0.0006575,\n
        \       \"input_cost_per_video_per_second_above_128k_tokens\": 0.0006575,\n
        \       \"input_cost_per_audio_per_second_above_128k_tokens\": 6.25e-05,\n
        \       \"input_cost_per_token_above_128k_tokens\": 1.5625e-07,\n        \"input_cost_per_character_above_128k_tokens\":
        6.25e-07,\n        \"output_cost_per_token\": 3.125e-07,\n        \"output_cost_per_character\":
        1.25e-06,\n        \"output_cost_per_token_above_128k_tokens\": 6.25e-07,\n
        \       \"output_cost_per_character_above_128k_tokens\": 2.5e-06,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_parallel_function_calling\": true\n    },\n    \"gemini-1.5-pro-preview-0409\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_image\": 0.00032875,\n
        \       \"input_cost_per_audio_per_second\": 3.125e-05,\n        \"input_cost_per_video_per_second\":
        0.00032875,\n        \"input_cost_per_token\": 7.8125e-08,\n        \"input_cost_per_character\":
        3.125e-07,\n        \"input_cost_per_image_above_128k_tokens\": 0.0006575,\n
        \       \"input_cost_per_video_per_second_above_128k_tokens\": 0.0006575,\n
        \       \"input_cost_per_audio_per_second_above_128k_tokens\": 6.25e-05,\n
        \       \"input_cost_per_token_above_128k_tokens\": 1.5625e-07,\n        \"input_cost_per_character_above_128k_tokens\":
        6.25e-07,\n        \"output_cost_per_token\": 3.125e-07,\n        \"output_cost_per_character\":
        1.25e-06,\n        \"output_cost_per_token_above_128k_tokens\": 6.25e-07,\n
        \       \"output_cost_per_character_above_128k_tokens\": 2.5e-06,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_parallel_function_calling\": true\n    },\n    \"gemini-1.5-flash\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_image\": 2e-05,\n
        \       \"input_cost_per_video_per_second\": 2e-05,\n        \"input_cost_per_audio_per_second\":
        2e-06,\n        \"input_cost_per_token\": 7.5e-08,\n        \"input_cost_per_character\":
        1.875e-08,\n        \"input_cost_per_token_above_128k_tokens\": 1e-06,\n        \"input_cost_per_character_above_128k_tokens\":
        2.5e-07,\n        \"input_cost_per_image_above_128k_tokens\": 4e-05,\n        \"input_cost_per_video_per_second_above_128k_tokens\":
        4e-05,\n        \"input_cost_per_audio_per_second_above_128k_tokens\": 4e-06,\n
        \       \"output_cost_per_token\": 3e-07,\n        \"output_cost_per_character\":
        7.5e-08,\n        \"output_cost_per_token_above_128k_tokens\": 6e-07,\n        \"output_cost_per_character_above_128k_tokens\":
        1.5e-07,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true,\n        \"supports_parallel_function_calling\":
        true\n    },\n    \"gemini-1.5-flash-exp-0827\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1000000,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_image\": 2e-05,\n        \"input_cost_per_video_per_second\":
        2e-05,\n        \"input_cost_per_audio_per_second\": 2e-06,\n        \"input_cost_per_token\":
        4.688e-09,\n        \"input_cost_per_character\": 1.875e-08,\n        \"input_cost_per_token_above_128k_tokens\":
        1e-06,\n        \"input_cost_per_character_above_128k_tokens\": 2.5e-07,\n
        \       \"input_cost_per_image_above_128k_tokens\": 4e-05,\n        \"input_cost_per_video_per_second_above_128k_tokens\":
        4e-05,\n        \"input_cost_per_audio_per_second_above_128k_tokens\": 4e-06,\n
        \       \"output_cost_per_token\": 4.6875e-09,\n        \"output_cost_per_character\":
        1.875e-08,\n        \"output_cost_per_token_above_128k_tokens\": 9.375e-09,\n
        \       \"output_cost_per_character_above_128k_tokens\": 3.75e-08,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true,\n        \"supports_parallel_function_calling\":
        true\n    },\n    \"gemini-1.5-flash-002\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 1048576,\n        \"max_output_tokens\": 8192,\n
        \       \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_image\": 2e-05,\n        \"input_cost_per_video_per_second\":
        2e-05,\n        \"input_cost_per_audio_per_second\": 2e-06,\n        \"input_cost_per_token\":
        7.5e-08,\n        \"input_cost_per_character\": 1.875e-08,\n        \"input_cost_per_token_above_128k_tokens\":
        1e-06,\n        \"input_cost_per_character_above_128k_tokens\": 2.5e-07,\n
        \       \"input_cost_per_image_above_128k_tokens\": 4e-05,\n        \"input_cost_per_video_per_second_above_128k_tokens\":
        4e-05,\n        \"input_cost_per_audio_per_second_above_128k_tokens\": 4e-06,\n
        \       \"output_cost_per_token\": 3e-07,\n        \"output_cost_per_character\":
        7.5e-08,\n        \"output_cost_per_token_above_128k_tokens\": 6e-07,\n        \"output_cost_per_character_above_128k_tokens\":
        1.5e-07,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-flash\",\n
        \       \"deprecation_date\": \"2025-09-24\",\n        \"supports_tool_choice\":
        true,\n        \"supports_parallel_function_calling\": true\n    },\n    \"gemini-1.5-flash-001\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_image\": 2e-05,\n
        \       \"input_cost_per_video_per_second\": 2e-05,\n        \"input_cost_per_audio_per_second\":
        2e-06,\n        \"input_cost_per_token\": 7.5e-08,\n        \"input_cost_per_character\":
        1.875e-08,\n        \"input_cost_per_token_above_128k_tokens\": 1e-06,\n        \"input_cost_per_character_above_128k_tokens\":
        2.5e-07,\n        \"input_cost_per_image_above_128k_tokens\": 4e-05,\n        \"input_cost_per_video_per_second_above_128k_tokens\":
        4e-05,\n        \"input_cost_per_audio_per_second_above_128k_tokens\": 4e-06,\n
        \       \"output_cost_per_token\": 3e-07,\n        \"output_cost_per_character\":
        7.5e-08,\n        \"output_cost_per_token_above_128k_tokens\": 6e-07,\n        \"output_cost_per_character_above_128k_tokens\":
        1.5e-07,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"deprecation_date\": \"2025-05-24\",\n        \"supports_tool_choice\":
        true,\n        \"supports_parallel_function_calling\": true\n    },\n    \"gemini-1.5-flash-preview-0514\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_image\": 2e-05,\n
        \       \"input_cost_per_video_per_second\": 2e-05,\n        \"input_cost_per_audio_per_second\":
        2e-06,\n        \"input_cost_per_token\": 7.5e-08,\n        \"input_cost_per_character\":
        1.875e-08,\n        \"input_cost_per_token_above_128k_tokens\": 1e-06,\n        \"input_cost_per_character_above_128k_tokens\":
        2.5e-07,\n        \"input_cost_per_image_above_128k_tokens\": 4e-05,\n        \"input_cost_per_video_per_second_above_128k_tokens\":
        4e-05,\n        \"input_cost_per_audio_per_second_above_128k_tokens\": 4e-06,\n
        \       \"output_cost_per_token\": 4.6875e-09,\n        \"output_cost_per_character\":
        1.875e-08,\n        \"output_cost_per_token_above_128k_tokens\": 9.375e-09,\n
        \       \"output_cost_per_character_above_128k_tokens\": 3.75e-08,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true,\n        \"supports_parallel_function_calling\":
        true\n    },\n    \"gemini-pro-experimental\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1000000,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0,\n        \"output_cost_per_token\":
        0,\n        \"input_cost_per_character\": 0,\n        \"output_cost_per_character\":
        0,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": false,\n        \"supports_tool_choice\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental\",\n
        \       \"supports_parallel_function_calling\": true\n    },\n    \"gemini-flash-experimental\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0,\n
        \       \"output_cost_per_token\": 0,\n        \"input_cost_per_character\":
        0,\n        \"output_cost_per_character\": 0,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        false,\n        \"supports_tool_choice\": true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental\",\n
        \       \"supports_parallel_function_calling\": true\n    },\n    \"gemini-pro-vision\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        2048,\n        \"max_images_per_prompt\": 16,\n        \"max_videos_per_prompt\":
        1,\n        \"max_video_length\": 2,\n        \"input_cost_per_token\": 5e-07,\n
        \       \"output_cost_per_token\": 1.5e-06,\n        \"input_cost_per_image\":
        0.0025,\n        \"litellm_provider\": \"vertex_ai-vision-models\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true,\n        \"supports_parallel_function_calling\":
        true\n    },\n    \"gemini-1.0-pro-vision\": {\n        \"max_tokens\": 2048,\n
        \       \"max_input_tokens\": 16384,\n        \"max_output_tokens\": 2048,\n
        \       \"max_images_per_prompt\": 16,\n        \"max_videos_per_prompt\":
        1,\n        \"max_video_length\": 2,\n        \"input_cost_per_token\": 5e-07,\n
        \       \"output_cost_per_token\": 1.5e-06,\n        \"input_cost_per_image\":
        0.0025,\n        \"litellm_provider\": \"vertex_ai-vision-models\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true,\n        \"supports_parallel_function_calling\":
        true\n    },\n    \"gemini-1.0-pro-vision-001\": {\n        \"max_tokens\":
        2048,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        2048,\n        \"max_images_per_prompt\": 16,\n        \"max_videos_per_prompt\":
        1,\n        \"max_video_length\": 2,\n        \"input_cost_per_token\": 5e-07,\n
        \       \"output_cost_per_token\": 1.5e-06,\n        \"input_cost_per_image\":
        0.0025,\n        \"litellm_provider\": \"vertex_ai-vision-models\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"deprecation_date\": \"2025-04-09\",\n        \"supports_tool_choice\":
        true,\n        \"supports_parallel_function_calling\": true\n    },\n    \"medlm-medium\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_character\": 5e-07,\n        \"output_cost_per_character\":
        1e-06,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"medlm-large\": {\n        \"max_tokens\":
        1024,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        1024,\n        \"input_cost_per_character\": 5e-06,\n        \"output_cost_per_character\":
        1.5e-05,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini-2.5-pro-exp-03-25\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_token\": 1.25e-06,\n
        \       \"input_cost_per_token_above_200k_tokens\": 2.5e-06,\n        \"output_cost_per_token\":
        1e-05,\n        \"output_cost_per_token_above_200k_tokens\": 1.5e-05,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_video_input\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/completions\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"image\",\n
        \           \"audio\",\n            \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\",\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_web_search\":
        true,\n        \"cache_read_input_token_cost\": 3.125e-07,\n        \"supports_prompt_caching\":
        true\n    },\n    \"gemini-2.0-pro-exp-02-05\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 2097152,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_token\": 1.25e-06,\n        \"input_cost_per_token_above_200k_tokens\":
        2.5e-06,\n        \"output_cost_per_token\": 1e-05,\n        \"output_cost_per_token_above_200k_tokens\":
        1.5e-05,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_audio_input\":
        true,\n        \"supports_video_input\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true,\n        \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/completions\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\",\n            \"audio\",\n
        \           \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\",\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_web_search\":
        true,\n        \"cache_read_input_token_cost\": 3.125e-07,\n        \"supports_prompt_caching\":
        true\n    },\n    \"gemini-2.0-flash-exp\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 1048576,\n        \"max_output_tokens\": 8192,\n
        \       \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_image\": 0,\n        \"input_cost_per_video_per_second\":
        0,\n        \"input_cost_per_audio_per_second\": 0,\n        \"input_cost_per_token\":
        1.5e-07,\n        \"input_cost_per_character\": 0,\n        \"input_cost_per_token_above_128k_tokens\":
        0,\n        \"input_cost_per_character_above_128k_tokens\": 0,\n        \"input_cost_per_image_above_128k_tokens\":
        0,\n        \"input_cost_per_video_per_second_above_128k_tokens\": 0,\n        \"input_cost_per_audio_per_second_above_128k_tokens\":
        0,\n        \"output_cost_per_token\": 6e-07,\n        \"output_cost_per_character\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_character_above_128k_tokens\":
        0,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": true,\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\",\n            \"audio\",\n
        \           \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\",\n        \"supports_tool_choice\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_web_search\":
        true,\n        \"cache_read_input_token_cost\": 3.75e-08,\n        \"supports_prompt_caching\":
        true\n    },\n    \"gemini-2.0-flash-001\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 1048576,\n        \"max_output_tokens\": 8192,\n
        \       \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 1e-06,\n        \"input_cost_per_token\":
        1.5e-07,\n        \"output_cost_per_token\": 6e-07,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_tool_choice\": true,\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\",\n            \"audio\",\n
        \           \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\",\n        \"deprecation_date\":
        \"2026-02-05\",\n        \"supports_parallel_function_calling\": true,\n        \"supports_web_search\":
        true,\n        \"cache_read_input_token_cost\": 3.75e-08,\n        \"supports_prompt_caching\":
        true\n    },\n    \"gemini-2.0-flash-thinking-exp\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_image\": 0,\n        \"input_cost_per_video_per_second\":
        0,\n        \"input_cost_per_audio_per_second\": 0,\n        \"input_cost_per_token\":
        0,\n        \"input_cost_per_character\": 0,\n        \"input_cost_per_token_above_128k_tokens\":
        0,\n        \"input_cost_per_character_above_128k_tokens\": 0,\n        \"input_cost_per_image_above_128k_tokens\":
        0,\n        \"input_cost_per_video_per_second_above_128k_tokens\": 0,\n        \"input_cost_per_audio_per_second_above_128k_tokens\":
        0,\n        \"output_cost_per_token\": 0,\n        \"output_cost_per_character\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_character_above_128k_tokens\":
        0,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": true,\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\",\n            \"audio\",\n
        \           \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash\",\n
        \       \"supports_tool_choice\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_web_search\": true,\n        \"cache_read_input_token_cost\":
        0.0,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini-2.0-flash-thinking-exp-01-21\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65536,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_image\": 0,\n
        \       \"input_cost_per_video_per_second\": 0,\n        \"input_cost_per_audio_per_second\":
        0,\n        \"input_cost_per_token\": 0,\n        \"input_cost_per_character\":
        0,\n        \"input_cost_per_token_above_128k_tokens\": 0,\n        \"input_cost_per_character_above_128k_tokens\":
        0,\n        \"input_cost_per_image_above_128k_tokens\": 0,\n        \"input_cost_per_video_per_second_above_128k_tokens\":
        0,\n        \"input_cost_per_audio_per_second_above_128k_tokens\": 0,\n        \"output_cost_per_token\":
        0,\n        \"output_cost_per_character\": 0,\n        \"output_cost_per_token_above_128k_tokens\":
        0,\n        \"output_cost_per_character_above_128k_tokens\": 0,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": false,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": false,\n        \"supports_audio_output\":
        false,\n        \"supported_modalities\": [\n            \"text\",\n            \"image\",\n
        \           \"audio\",\n            \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash\",\n
        \       \"supports_tool_choice\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_web_search\": true,\n        \"cache_read_input_token_cost\":
        0.0,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini-2.5-pro\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_token\": 1.25e-06,\n
        \       \"input_cost_per_token_above_200k_tokens\": 2.5e-06,\n        \"output_cost_per_token\":
        1e-05,\n        \"output_cost_per_token_above_200k_tokens\": 1.5e-05,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_video_input\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/completions\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\",\n            \"audio\",\n
        \           \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\",\n
        \       \"supports_web_search\": true,\n        \"cache_read_input_token_cost\":
        3.125e-07,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini/gemini-2.5-pro-exp-03-25\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_token\": 0.0,\n
        \       \"input_cost_per_token_above_200k_tokens\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"output_cost_per_token_above_200k_tokens\": 0.0,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"rpm\": 5,\n        \"tpm\":
        250000,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_audio_input\":
        true,\n        \"supports_video_input\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true,\n        \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/completions\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\",\n            \"audio\",\n
        \           \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\",\n
        \       \"supports_web_search\": true,\n        \"cache_read_input_token_cost\":
        0.0,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini/gemini-2.5-pro\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_token\": 1.25e-06,\n
        \       \"input_cost_per_token_above_200k_tokens\": 2.5e-06,\n        \"output_cost_per_token\":
        1e-05,\n        \"output_cost_per_token_above_200k_tokens\": 1.5e-05,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"rpm\": 2000,\n        \"tpm\":
        800000,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_audio_input\":
        true,\n        \"supports_video_input\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/completions\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"image\",\n
        \           \"audio\",\n            \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\",\n
        \       \"supports_web_search\": true,\n        \"cache_read_input_token_cost\":
        3.125e-07,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini/gemini-2.5-flash\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        1e-06,\n        \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        2.5e-06,\n        \"output_cost_per_reasoning_token\": 2.5e-06,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_reasoning\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": false,\n        \"supports_tool_choice\":
        true,\n        \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/completions\",\n            \"/v1/batch\"\n        ],\n
        \       \"supported_modalities\": [\n            \"text\",\n            \"image\",\n
        \           \"audio\",\n            \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\",\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_web_search\":
        true,\n        \"supports_url_context\": true,\n        \"tpm\": 8000000,\n
        \       \"rpm\": 100000,\n        \"supports_pdf_input\": true,\n        \"cache_read_input_token_cost\":
        7.5e-08,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini-2.5-flash\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        1e-06,\n        \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        2.5e-06,\n        \"output_cost_per_reasoning_token\": 2.5e-06,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_reasoning\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": false,\n        \"supports_tool_choice\":
        true,\n        \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/completions\",\n            \"/v1/batch\"\n        ],\n
        \       \"supported_modalities\": [\n            \"text\",\n            \"image\",\n
        \           \"audio\",\n            \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\",\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_web_search\":
        true,\n        \"supports_url_context\": true,\n        \"supports_pdf_input\":
        true,\n        \"cache_read_input_token_cost\": 7.5e-08,\n        \"supports_prompt_caching\":
        true\n    },\n    \"gemini/gemini-2.0-flash-live-001\": {\n        \"max_tokens\":
        65535,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        65535,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_token\": 3.5e-07,\n        \"input_cost_per_audio_token\":
        2.1e-06,\n        \"input_cost_per_image\": 2.1e-06,\n        \"input_cost_per_video_per_second\":
        2.1e-06,\n        \"output_cost_per_token\": 1.5e-06,\n        \"output_cost_per_audio_token\":
        8.5e-06,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"rpm\": 10,\n        \"tpm\": 250000,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_tool_choice\":
        true,\n        \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/completions\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\",\n            \"audio\",\n
        \           \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\",\n            \"audio\"\n        ],\n        \"source\":
        \"https://ai.google.dev/gemini-api/docs/models#gemini-2-0-flash-live-001\",\n
        \       \"supports_web_search\": true,\n        \"supports_url_context\":
        true,\n        \"supports_pdf_input\": true,\n        \"cache_read_input_token_cost\":
        7.5e-08,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini/gemini-2.5-flash-preview-tts\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        1e-06,\n        \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"output_cost_per_reasoning_token\": 3.5e-06,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"rpm\": 10,\n        \"tpm\":
        250000,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/completions\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\"\n        ],\n
        \       \"supported_output_modalities\": [\n            \"audio\"\n        ],\n
        \       \"source\": \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\",\n
        \       \"supports_web_search\": true,\n        \"cache_read_input_token_cost\":
        3.75e-08,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini/gemini-2.5-flash-preview-05-20\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        1e-06,\n        \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        2.5e-06,\n        \"output_cost_per_reasoning_token\": 2.5e-06,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"rpm\": 10,\n        \"tpm\":
        250000,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/completions\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"image\",\n
        \           \"audio\",\n            \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\",\n
        \       \"supports_web_search\": true,\n        \"supports_url_context\":
        true,\n        \"supports_pdf_input\": true,\n        \"cache_read_input_token_cost\":
        7.5e-08,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini/gemini-2.5-flash-preview-04-17\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        1e-06,\n        \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"output_cost_per_reasoning_token\": 3.5e-06,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"rpm\": 10,\n        \"tpm\":
        250000,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/completions\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"image\",\n
        \           \"audio\",\n            \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\",\n
        \       \"supports_web_search\": true,\n        \"supports_pdf_input\": true,\n
        \       \"cache_read_input_token_cost\": 3.75e-08,\n        \"supports_prompt_caching\":
        true\n    },\n    \"gemini/gemini-2.5-flash-lite-preview-06-17\": {\n        \"max_tokens\":
        65535,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        65535,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 5e-07,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 4e-07,\n        \"output_cost_per_reasoning_token\":
        4e-07,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"rpm\": 15,\n        \"tpm\": 250000,\n        \"supports_reasoning\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": false,\n        \"supports_tool_choice\":
        true,\n        \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/completions\",\n            \"/v1/batch\"\n        ],\n
        \       \"supported_modalities\": [\n            \"text\",\n            \"image\",\n
        \           \"audio\",\n            \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-lite\",\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_web_search\":
        true,\n        \"supports_url_context\": true,\n        \"supports_pdf_input\":
        true,\n        \"cache_read_input_token_cost\": 2.5e-08,\n        \"supports_prompt_caching\":
        true\n    },\n    \"gemini/gemini-2.5-flash-lite\": {\n        \"max_tokens\":
        65535,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        65535,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 5e-07,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 4e-07,\n        \"output_cost_per_reasoning_token\":
        4e-07,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"rpm\": 15,\n        \"tpm\": 250000,\n        \"supports_reasoning\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": false,\n        \"supports_tool_choice\":
        true,\n        \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/completions\",\n            \"/v1/batch\"\n        ],\n
        \       \"supported_modalities\": [\n            \"text\",\n            \"image\",\n
        \           \"audio\",\n            \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-lite\",\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_web_search\":
        true,\n        \"supports_url_context\": true,\n        \"supports_pdf_input\":
        true,\n        \"cache_read_input_token_cost\": 2.5e-08,\n        \"supports_prompt_caching\":
        true\n    },\n    \"gemini-2.5-flash-preview-05-20\": {\n        \"max_tokens\":
        65535,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        65535,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 1e-06,\n        \"input_cost_per_token\":
        3e-07,\n        \"output_cost_per_token\": 2.5e-06,\n        \"output_cost_per_reasoning_token\":
        2.5e-06,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_reasoning\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/completions\",\n
        \           \"/v1/batch\"\n        ],\n        \"supported_modalities\": [\n
        \           \"text\",\n            \"image\",\n            \"audio\",\n            \"video\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\",\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_web_search\":
        true,\n        \"supports_url_context\": true,\n        \"supports_pdf_input\":
        true,\n        \"cache_read_input_token_cost\": 7.5e-08,\n        \"supports_prompt_caching\":
        true\n    },\n    \"gemini-2.5-flash-preview-04-17\": {\n        \"max_tokens\":
        65535,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        65535,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 1e-06,\n        \"input_cost_per_token\":
        1.5e-07,\n        \"output_cost_per_token\": 6e-07,\n        \"output_cost_per_reasoning_token\":
        3.5e-06,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_reasoning\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/completions\",\n
        \           \"/v1/batch\"\n        ],\n        \"supported_modalities\": [\n
        \           \"text\",\n            \"image\",\n            \"audio\",\n            \"video\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\",\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_web_search\":
        true,\n        \"supports_pdf_input\": true,\n        \"cache_read_input_token_cost\":
        3.75e-08,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini-2.5-flash-lite-preview-06-17\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        5e-07,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        4e-07,\n        \"output_cost_per_reasoning_token\": 4e-07,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_reasoning\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": false,\n        \"supports_tool_choice\":
        true,\n        \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/completions\",\n            \"/v1/batch\"\n        ],\n
        \       \"supported_modalities\": [\n            \"text\",\n            \"image\",\n
        \           \"audio\",\n            \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\",\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_web_search\":
        true,\n        \"supports_url_context\": true,\n        \"supports_pdf_input\":
        true,\n        \"cache_read_input_token_cost\": 2.5e-08,\n        \"supports_prompt_caching\":
        true\n    },\n    \"gemini-2.5-flash-lite\": {\n        \"max_tokens\": 65535,\n
        \       \"max_input_tokens\": 1048576,\n        \"max_output_tokens\": 65535,\n
        \       \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 5e-07,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 4e-07,\n        \"output_cost_per_reasoning_token\":
        4e-07,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_reasoning\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/completions\",\n
        \           \"/v1/batch\"\n        ],\n        \"supported_modalities\": [\n
        \           \"text\",\n            \"image\",\n            \"audio\",\n            \"video\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\",\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_web_search\":
        true,\n        \"supports_url_context\": true,\n        \"supports_pdf_input\":
        true,\n        \"cache_read_input_token_cost\": 2.5e-08,\n        \"supports_prompt_caching\":
        true\n    },\n    \"gemini-2.0-flash\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 1048576,\n        \"max_output_tokens\": 8192,\n
        \       \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 7e-07,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 4e-07,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_audio_input\": true,\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\",\n            \"audio\",\n
        \           \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supports_tool_choice\":
        true,\n        \"source\": \"https://ai.google.dev/pricing#2_0flash\",\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_web_search\": true,\n        \"supports_url_context\":
        true,\n        \"cache_read_input_token_cost\": 2.5e-08,\n        \"supports_prompt_caching\":
        true\n    },\n    \"gemini-2.0-flash-lite\": {\n        \"max_input_tokens\":
        1048576,\n        \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 50,\n        \"input_cost_per_audio_token\":
        7.5e-08,\n        \"input_cost_per_token\": 7.5e-08,\n        \"output_cost_per_token\":
        3e-07,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": true,\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\",\n            \"audio\",\n
        \           \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash\",\n
        \       \"supports_tool_choice\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_web_search\": true,\n        \"cache_read_input_token_cost\":
        1.875e-08,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini-2.0-flash-lite-001\":
        {\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 50,\n
        \       \"input_cost_per_audio_token\": 7.5e-08,\n        \"input_cost_per_token\":
        7.5e-08,\n        \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        true,\n        \"supported_modalities\": [\n            \"text\",\n            \"image\",\n
        \           \"audio\",\n            \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash\",\n
        \       \"supports_tool_choice\": true,\n        \"deprecation_date\": \"2026-02-25\",\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_web_search\":
        true,\n        \"cache_read_input_token_cost\": 1.875e-08,\n        \"supports_prompt_caching\":
        true\n    },\n    \"gemini-2.5-pro-preview-06-05\": {\n        \"max_tokens\":
        65535,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        65535,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 1.25e-06,\n        \"input_cost_per_token\":
        1.25e-06,\n        \"input_cost_per_token_above_200k_tokens\": 2.5e-06,\n
        \       \"output_cost_per_token\": 1e-05,\n        \"output_cost_per_token_above_200k_tokens\":
        1.5e-05,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_reasoning\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/completions\",\n
        \           \"/v1/batch\"\n        ],\n        \"supported_modalities\": [\n
        \           \"text\",\n            \"image\",\n            \"audio\",\n            \"video\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\",\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_web_search\":
        true,\n        \"supports_pdf_input\": true,\n        \"cache_read_input_token_cost\":
        3.125e-07,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini-2.5-pro-preview-05-06\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        1.25e-06,\n        \"input_cost_per_token\": 1.25e-06,\n        \"input_cost_per_token_above_200k_tokens\":
        2.5e-06,\n        \"output_cost_per_token\": 1e-05,\n        \"output_cost_per_token_above_200k_tokens\":
        1.5e-05,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_reasoning\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/completions\",\n
        \           \"/v1/batch\"\n        ],\n        \"supported_modalities\": [\n
        \           \"text\",\n            \"image\",\n            \"audio\",\n            \"video\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"supported_regions\": [\n            \"global\"\n        ],\n
        \       \"source\": \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\",\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_web_search\":
        true,\n        \"supports_pdf_input\": true,\n        \"cache_read_input_token_cost\":
        3.125e-07,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini-2.5-pro-preview-03-25\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        1.25e-06,\n        \"input_cost_per_token\": 1.25e-06,\n        \"input_cost_per_token_above_200k_tokens\":
        2.5e-06,\n        \"output_cost_per_token\": 1e-05,\n        \"output_cost_per_token_above_200k_tokens\":
        1.5e-05,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_reasoning\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_endpoints\":
        [\n            \"/v1/chat/completions\",\n            \"/v1/completions\",\n
        \           \"/v1/batch\"\n        ],\n        \"supported_modalities\": [\n
        \           \"text\",\n            \"image\",\n            \"audio\",\n            \"video\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\"\n
        \       ],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\",\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_web_search\":
        true,\n        \"supports_pdf_input\": true,\n        \"cache_read_input_token_cost\":
        3.125e-07,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini-2.0-flash-preview-image-generation\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        7e-07,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        4e-07,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_audio_input\":
        true,\n        \"supported_modalities\": [\n            \"text\",\n            \"image\",\n
        \           \"audio\",\n            \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supports_tool_choice\":
        true,\n        \"source\": \"https://ai.google.dev/pricing#2_0flash\",\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_web_search\": true,\n        \"cache_read_input_token_cost\":
        2.5e-08,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini-2.5-pro-preview-tts\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        7e-07,\n        \"input_cost_per_token\": 1.25e-06,\n        \"input_cost_per_token_above_200k_tokens\":
        2.5e-06,\n        \"output_cost_per_token\": 1e-05,\n        \"output_cost_per_token_above_200k_tokens\":
        1.5e-05,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": false,\n        \"supports_tool_choice\":
        true,\n        \"supported_modalities\": [\n            \"text\"\n        ],\n
        \       \"supported_output_modalities\": [\n            \"audio\"\n        ],\n
        \       \"source\": \"https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview\",\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_web_search\":
        true,\n        \"cache_read_input_token_cost\": 3.125e-07,\n        \"supports_prompt_caching\":
        true\n    },\n    \"gemini/gemini-2.0-pro-exp-02-05\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 2097152,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_image\": 0,\n        \"input_cost_per_video_per_second\":
        0,\n        \"input_cost_per_audio_per_second\": 0,\n        \"input_cost_per_token\":
        0,\n        \"input_cost_per_character\": 0,\n        \"input_cost_per_token_above_128k_tokens\":
        0,\n        \"input_cost_per_character_above_128k_tokens\": 0,\n        \"input_cost_per_image_above_128k_tokens\":
        0,\n        \"input_cost_per_video_per_second_above_128k_tokens\": 0,\n        \"input_cost_per_audio_per_second_above_128k_tokens\":
        0,\n        \"output_cost_per_token\": 0,\n        \"output_cost_per_character\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_character_above_128k_tokens\":
        0,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"rpm\": 2,\n        \"tpm\": 1000000,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_video_input\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\",\n
        \       \"supports_web_search\": true,\n        \"cache_read_input_token_cost\":
        0.0,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini/gemini-2.0-flash-preview-image-generation\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        7e-07,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        4e-07,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"rpm\": 10000,\n        \"tpm\": 10000000,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_audio_input\": true,\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\",\n            \"audio\",\n
        \           \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supports_tool_choice\":
        true,\n        \"source\": \"https://ai.google.dev/pricing#2_0flash\",\n        \"supports_web_search\":
        true,\n        \"cache_read_input_token_cost\": 2.5e-08,\n        \"supports_prompt_caching\":
        true\n    },\n    \"gemini/gemini-2.0-flash\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 7e-07,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 4e-07,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"rpm\": 10000,\n        \"tpm\":
        10000000,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_audio_input\":
        true,\n        \"supported_modalities\": [\n            \"text\",\n            \"image\",\n
        \           \"audio\",\n            \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supports_tool_choice\":
        true,\n        \"source\": \"https://ai.google.dev/pricing#2_0flash\",\n        \"supports_web_search\":
        true,\n        \"supports_url_context\": true,\n        \"cache_read_input_token_cost\":
        2.5e-08,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini/gemini-2.0-flash-lite\":
        {\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 50,\n
        \       \"input_cost_per_audio_token\": 7.5e-08,\n        \"input_cost_per_token\":
        7.5e-08,\n        \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"tpm\": 4000000,\n        \"rpm\":
        4000,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_tool_choice\":
        true,\n        \"supported_modalities\": [\n            \"text\",\n            \"image\",\n
        \           \"audio\",\n            \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/pricing#gemini-2.0-flash-lite\",\n
        \       \"supports_web_search\": true,\n        \"cache_read_input_token_cost\":
        1.875e-08,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini/gemini-2.0-flash-001\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        7e-07,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        4e-07,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"rpm\": 10000,\n        \"tpm\": 10000000,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\",\n            \"audio\",\n
        \           \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"source\":
        \"https://ai.google.dev/pricing#2_0flash\",\n        \"supports_web_search\":
        true,\n        \"cache_read_input_token_cost\": 2.5e-08,\n        \"supports_prompt_caching\":
        true\n    },\n    \"gemini/gemini-2.5-pro-preview-tts\": {\n        \"max_tokens\":
        65535,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        65535,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 7e-07,\n        \"input_cost_per_token\":
        1.25e-06,\n        \"input_cost_per_token_above_200k_tokens\": 2.5e-06,\n
        \       \"output_cost_per_token\": 1e-05,\n        \"output_cost_per_token_above_200k_tokens\":
        1.5e-05,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"rpm\": 10000,\n        \"tpm\": 10000000,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_modalities\":
        [\n            \"text\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"audio\"\n        ],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview\",\n
        \       \"supports_web_search\": true,\n        \"cache_read_input_token_cost\":
        3.125e-07,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini/gemini-2.5-pro-preview-06-05\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        7e-07,\n        \"input_cost_per_token\": 1.25e-06,\n        \"input_cost_per_token_above_200k_tokens\":
        2.5e-06,\n        \"output_cost_per_token\": 1e-05,\n        \"output_cost_per_token_above_200k_tokens\":
        1.5e-05,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"rpm\": 10000,\n        \"tpm\": 10000000,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\",\n            \"audio\",\n
        \           \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview\",\n
        \       \"supports_web_search\": true,\n        \"supports_url_context\":
        true,\n        \"supports_pdf_input\": true,\n        \"cache_read_input_token_cost\":
        3.125e-07,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini/gemini-2.5-pro-preview-05-06\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        7e-07,\n        \"input_cost_per_token\": 1.25e-06,\n        \"input_cost_per_token_above_200k_tokens\":
        2.5e-06,\n        \"output_cost_per_token\": 1e-05,\n        \"output_cost_per_token_above_200k_tokens\":
        1.5e-05,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"rpm\": 10000,\n        \"tpm\": 10000000,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\",\n            \"audio\",\n
        \           \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview\",\n
        \       \"supports_web_search\": true,\n        \"supports_url_context\":
        true,\n        \"supports_pdf_input\": true,\n        \"cache_read_input_token_cost\":
        3.125e-07,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini/gemini-2.5-pro-preview-03-25\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        7e-07,\n        \"input_cost_per_token\": 1.25e-06,\n        \"input_cost_per_token_above_200k_tokens\":
        2.5e-06,\n        \"output_cost_per_token\": 1e-05,\n        \"output_cost_per_token_above_200k_tokens\":
        1.5e-05,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"rpm\": 10000,\n        \"tpm\": 10000000,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\",\n            \"audio\",\n
        \           \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview\",\n
        \       \"supports_web_search\": true,\n        \"supports_pdf_input\": true,\n
        \       \"cache_read_input_token_cost\": 3.125e-07,\n        \"supports_prompt_caching\":
        true\n    },\n    \"gemini/gemini-2.0-flash-exp\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_image\": 0,\n        \"input_cost_per_video_per_second\":
        0,\n        \"input_cost_per_audio_per_second\": 0,\n        \"input_cost_per_token\":
        0,\n        \"input_cost_per_character\": 0,\n        \"input_cost_per_token_above_128k_tokens\":
        0,\n        \"input_cost_per_character_above_128k_tokens\": 0,\n        \"input_cost_per_image_above_128k_tokens\":
        0,\n        \"input_cost_per_video_per_second_above_128k_tokens\": 0,\n        \"input_cost_per_audio_per_second_above_128k_tokens\":
        0,\n        \"output_cost_per_token\": 0,\n        \"output_cost_per_character\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_character_above_128k_tokens\":
        0,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": true,\n        \"tpm\": 4000000,\n
        \       \"rpm\": 10,\n        \"supported_modalities\": [\n            \"text\",\n
        \           \"image\",\n            \"audio\",\n            \"video\"\n        ],\n
        \       \"supported_output_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash\",\n
        \       \"supports_tool_choice\": true,\n        \"supports_web_search\":
        true,\n        \"cache_read_input_token_cost\": 0.0,\n        \"supports_prompt_caching\":
        true\n    },\n    \"gemini/gemini-2.0-flash-lite-preview-02-05\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 7.5e-08,\n        \"input_cost_per_token\":
        7.5e-08,\n        \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"rpm\": 60000,\n        \"tpm\":
        10000000,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": false,\n        \"supports_tool_choice\":
        true,\n        \"supported_modalities\": [\n            \"text\",\n            \"image\",\n
        \           \"audio\",\n            \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\"\n        ],\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash-lite\",\n
        \       \"supports_web_search\": true,\n        \"cache_read_input_token_cost\":
        1.875e-08,\n        \"supports_prompt_caching\": true\n    },\n    \"gemini/gemini-2.0-flash-thinking-exp\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65536,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_image\": 0,\n
        \       \"input_cost_per_video_per_second\": 0,\n        \"input_cost_per_audio_per_second\":
        0,\n        \"input_cost_per_token\": 0,\n        \"input_cost_per_character\":
        0,\n        \"input_cost_per_token_above_128k_tokens\": 0,\n        \"input_cost_per_character_above_128k_tokens\":
        0,\n        \"input_cost_per_image_above_128k_tokens\": 0,\n        \"input_cost_per_video_per_second_above_128k_tokens\":
        0,\n        \"input_cost_per_audio_per_second_above_128k_tokens\": 0,\n        \"output_cost_per_token\":
        0,\n        \"output_cost_per_character\": 0,\n        \"output_cost_per_token_above_128k_tokens\":
        0,\n        \"output_cost_per_character_above_128k_tokens\": 0,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        true,\n        \"tpm\": 4000000,\n        \"rpm\": 10,\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\",\n            \"audio\",\n
        \           \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash\",\n
        \       \"supports_tool_choice\": true,\n        \"supports_web_search\":
        true,\n        \"cache_read_input_token_cost\": 0.0,\n        \"supports_prompt_caching\":
        true\n    },\n    \"gemini/gemini-2.0-flash-thinking-exp-01-21\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        65536,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_image\": 0,\n        \"input_cost_per_video_per_second\":
        0,\n        \"input_cost_per_audio_per_second\": 0,\n        \"input_cost_per_token\":
        0,\n        \"input_cost_per_character\": 0,\n        \"input_cost_per_token_above_128k_tokens\":
        0,\n        \"input_cost_per_character_above_128k_tokens\": 0,\n        \"input_cost_per_image_above_128k_tokens\":
        0,\n        \"input_cost_per_video_per_second_above_128k_tokens\": 0,\n        \"input_cost_per_audio_per_second_above_128k_tokens\":
        0,\n        \"output_cost_per_token\": 0,\n        \"output_cost_per_character\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_character_above_128k_tokens\":
        0,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": true,\n        \"tpm\": 4000000,\n
        \       \"rpm\": 10,\n        \"supported_modalities\": [\n            \"text\",\n
        \           \"image\",\n            \"audio\",\n            \"video\"\n        ],\n
        \       \"supported_output_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash\",\n
        \       \"supports_tool_choice\": true,\n        \"supports_web_search\":
        true,\n        \"cache_read_input_token_cost\": 0.0,\n        \"supports_prompt_caching\":
        true\n    },\n    \"gemini/gemma-3-27b-it\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_image\": 0,\n        \"input_cost_per_video_per_second\":
        0,\n        \"input_cost_per_audio_per_second\": 0,\n        \"input_cost_per_token\":
        0,\n        \"input_cost_per_character\": 0,\n        \"input_cost_per_token_above_128k_tokens\":
        0,\n        \"input_cost_per_character_above_128k_tokens\": 0,\n        \"input_cost_per_image_above_128k_tokens\":
        0,\n        \"input_cost_per_video_per_second_above_128k_tokens\": 0,\n        \"input_cost_per_audio_per_second_above_128k_tokens\":
        0,\n        \"output_cost_per_token\": 0,\n        \"output_cost_per_character\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_character_above_128k_tokens\":
        0,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": false,\n        \"source\": \"https://aistudio.google.com\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini/learnlm-1.5-pro-experimental\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 32767,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_image\": 0,\n        \"input_cost_per_video_per_second\":
        0,\n        \"input_cost_per_audio_per_second\": 0,\n        \"input_cost_per_token\":
        0,\n        \"input_cost_per_character\": 0,\n        \"input_cost_per_token_above_128k_tokens\":
        0,\n        \"input_cost_per_character_above_128k_tokens\": 0,\n        \"input_cost_per_image_above_128k_tokens\":
        0,\n        \"input_cost_per_video_per_second_above_128k_tokens\": 0,\n        \"input_cost_per_audio_per_second_above_128k_tokens\":
        0,\n        \"output_cost_per_token\": 0,\n        \"output_cost_per_character\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_character_above_128k_tokens\":
        0,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": false,\n        \"source\": \"https://aistudio.google.com\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"vertex_ai/claude-opus-4-1\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 15e-06,\n
        \       \"output_cost_per_token\": 75e-06,\n        \"input_cost_per_token_batches\":
        7.5e-06,\n        \"output_cost_per_token_batches\": 37.5e-06,\n        \"cache_creation_input_token_cost\":
        1.875e-05,\n        \"cache_read_input_token_cost\": 1.5e-06,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/claude-opus-4-1@20250805\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 15e-06,\n
        \       \"output_cost_per_token\": 75e-06,\n        \"input_cost_per_token_batches\":
        7.5e-06,\n        \"output_cost_per_token_batches\": 37.5e-06,\n        \"cache_creation_input_token_cost\":
        1.875e-05,\n        \"cache_read_input_token_cost\": 1.5e-06,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/claude-3-sonnet\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"gemini-2.0-flash-live-preview-04-09\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_token\": 5e-07,\n
        \       \"input_cost_per_audio_token\": 3e-06,\n        \"input_cost_per_image\":
        3e-06,\n        \"input_cost_per_video_per_second\": 3e-06,\n        \"output_cost_per_token\":
        2e-06,\n        \"output_cost_per_audio_token\": 1.2e-05,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"rpm\":
        10,\n        \"tpm\": 250000,\n        \"supports_system_messages\": true,\n
        \       \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_tool_choice\":
        true,\n        \"supported_endpoints\": [\n            \"/v1/chat/completions\",\n
        \           \"/v1/completions\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\",\n            \"audio\",\n
        \           \"video\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\",\n            \"audio\"\n        ],\n        \"source\":
        \"https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini#gemini-2-0-flash-live-preview-04-09\",\n
        \       \"supports_web_search\": true,\n        \"supports_url_context\":
        true,\n        \"supports_pdf_input\": true,\n        \"cache_read_input_token_cost\":
        7.5e-08,\n        \"supports_prompt_caching\": true\n    },\n    \"vertex_ai/claude-3-sonnet@20240229\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/claude-3-5-sonnet\":
        {\n        \"supports_computer_use\": true,\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"litellm_provider\": \"vertex_ai-anthropic_models\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_pdf_input\": true,\n        \"supports_vision\": true,\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/claude-3-5-sonnet@20240620\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"litellm_provider\": \"vertex_ai-anthropic_models\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_pdf_input\": true,\n        \"supports_vision\": true,\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/claude-3-5-sonnet-v2\": {\n        \"supports_computer_use\":
        true,\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_vision\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/claude-3-5-sonnet-v2@20241022\": {\n        \"supports_computer_use\":
        true,\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_vision\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/claude-3-7-sonnet@20250219\": {\n        \"supports_computer_use\":
        true,\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"cache_creation_input_token_cost\":
        3.75e-06,\n        \"cache_read_input_token_cost\": 3e-07,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_vision\":
        true,\n        \"tool_use_system_prompt_tokens\": 159,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"deprecation_date\": \"2025-06-01\",\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/claude-opus-4\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 32000,\n        \"input_cost_per_token\": 1.5e-05,\n
        \       \"output_cost_per_token\": 7.5e-05,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.01,\n            \"search_context_size_medium\":
        0.01,\n            \"search_context_size_high\": 0.01\n        },\n        \"cache_creation_input_token_cost\":
        1.875e-05,\n        \"cache_read_input_token_cost\": 1.5e-06,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"vertex_ai/claude-opus-4@20250514\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 32000,\n        \"input_cost_per_token\": 1.5e-05,\n
        \       \"output_cost_per_token\": 7.5e-05,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.01,\n            \"search_context_size_medium\":
        0.01,\n            \"search_context_size_high\": 0.01\n        },\n        \"cache_creation_input_token_cost\":
        1.875e-05,\n        \"cache_read_input_token_cost\": 1.5e-06,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"vertex_ai/claude-sonnet-4\":
        {\n        \"max_tokens\": 64000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 64000,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.01,\n            \"search_context_size_medium\":
        0.01,\n            \"search_context_size_high\": 0.01\n        },\n        \"cache_creation_input_token_cost\":
        3.75e-06,\n        \"cache_read_input_token_cost\": 3e-07,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"vertex_ai/claude-sonnet-4@20250514\":
        {\n        \"max_tokens\": 64000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 64000,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.01,\n            \"search_context_size_medium\":
        0.01,\n            \"search_context_size_high\": 0.01\n        },\n        \"cache_creation_input_token_cost\":
        3.75e-06,\n        \"cache_read_input_token_cost\": 3e-07,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"vertex_ai/claude-3-haiku\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 2.5e-07,\n
        \       \"output_cost_per_token\": 1.25e-06,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/claude-3-haiku@20240307\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 2.5e-07,\n
        \       \"output_cost_per_token\": 1.25e-06,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/claude-3-5-haiku\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 1e-06,\n
        \       \"output_cost_per_token\": 5e-06,\n        \"litellm_provider\": \"vertex_ai-anthropic_models\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_pdf_input\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/claude-3-5-haiku@20241022\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 1e-06,\n
        \       \"output_cost_per_token\": 5e-06,\n        \"litellm_provider\": \"vertex_ai-anthropic_models\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_pdf_input\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/claude-3-opus\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 1.5e-05,\n
        \       \"output_cost_per_token\": 7.5e-05,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/claude-3-opus@20240229\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 1.5e-05,\n
        \       \"output_cost_per_token\": 7.5e-05,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/deepseek-ai/deepseek-r1-0528-maas\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 65336,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 1.35e-06,\n        \"output_cost_per_token\":
        5.4e-06,\n        \"litellm_provider\": \"vertex_ai-deepseek_models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\",\n
        \       \"supports_function_calling\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_prompt_caching\": true\n    },\n    \"vertex_ai/qwen/qwen3-coder-480b-a35b-instruct-maas\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 262144,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 1e-06,\n
        \       \"output_cost_per_token\": 4e-06,\n        \"litellm_provider\": \"vertex_ai-qwen_models\",\n
        \       \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/qwen/qwen3-235b-a22b-instruct-2507-maas\": {\n
        \       \"max_tokens\": 16384,\n        \"max_input_tokens\": 262144,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.25e-06,\n        \"output_cost_per_token\":
        1e-06,\n        \"litellm_provider\": \"vertex_ai-qwen_models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/meta/llama3-405b-instruct-maas\": {\n        \"max_tokens\":
        32000,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        32000,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"vertex_ai-llama_models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"vertex_ai/meta/llama-4-scout-17b-16e-instruct-maas\":
        {\n        \"max_tokens\": 10000000,\n        \"max_input_tokens\": 10000000,\n
        \       \"max_output_tokens\": 10000000,\n        \"input_cost_per_token\":
        2.5e-07,\n        \"output_cost_per_token\": 7e-07,\n        \"litellm_provider\":
        \"vertex_ai-llama_models\",\n        \"mode\": \"chat\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\",\n
        \       \"supports_tool_choice\": true,\n        \"supports_function_calling\":
        true,\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\",\n
        \           \"code\"\n        ]\n    },\n    \"vertex_ai/meta/llama-4-scout-17b-128e-instruct-maas\":
        {\n        \"max_tokens\": 10000000,\n        \"max_input_tokens\": 10000000,\n
        \       \"max_output_tokens\": 10000000,\n        \"input_cost_per_token\":
        2.5e-07,\n        \"output_cost_per_token\": 7e-07,\n        \"litellm_provider\":
        \"vertex_ai-llama_models\",\n        \"mode\": \"chat\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\",\n
        \       \"supports_tool_choice\": true,\n        \"supports_function_calling\":
        true,\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\",\n
        \           \"code\"\n        ]\n    },\n    \"vertex_ai/meta/llama-4-maverick-17b-128e-instruct-maas\":
        {\n        \"max_tokens\": 1000000,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 1000000,\n        \"input_cost_per_token\":
        3.5e-07,\n        \"output_cost_per_token\": 1.15e-06,\n        \"litellm_provider\":
        \"vertex_ai-llama_models\",\n        \"mode\": \"chat\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\",\n
        \       \"supports_tool_choice\": true,\n        \"supports_function_calling\":
        true,\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\",\n
        \           \"code\"\n        ]\n    },\n    \"vertex_ai/meta/llama-4-maverick-17b-16e-instruct-maas\":
        {\n        \"max_tokens\": 1000000,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 1000000,\n        \"input_cost_per_token\":
        3.5e-07,\n        \"output_cost_per_token\": 1.15e-06,\n        \"litellm_provider\":
        \"vertex_ai-llama_models\",\n        \"mode\": \"chat\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\",\n
        \       \"supports_tool_choice\": true,\n        \"supports_function_calling\":
        true,\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\",\n
        \           \"code\"\n        ]\n    },\n    \"vertex_ai/meta/llama3-70b-instruct-maas\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 32000,\n
        \       \"max_output_tokens\": 32000,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"vertex_ai-llama_models\",\n
        \       \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"vertex_ai/meta/llama3-8b-instruct-maas\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 32000,\n
        \       \"max_output_tokens\": 32000,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"vertex_ai-llama_models\",\n
        \       \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"vertex_ai/meta/llama-3.1-8b-instruct-maas\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 2048,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"vertex_ai-llama_models\",\n
        \       \"mode\": \"chat\",\n        \"supports_system_messages\": true,\n
        \       \"supports_vision\": true,\n        \"source\": \"https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas\",\n
        \       \"supports_tool_choice\": true,\n        \"metadata\": {\n            \"notes\":
        \"VertexAI states that The Llama 3.1 API service for llama-3.1-70b-instruct-maas
        and llama-3.1-8b-instruct-maas are in public preview and at no cost.\"\n        }\n
        \   },\n    \"vertex_ai/meta/llama-3.1-70b-instruct-maas\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        2048,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"vertex_ai-llama_models\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_vision\":
        true,\n        \"source\": \"https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"vertex_ai/meta/llama-3.1-405b-instruct-maas\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 2048,\n        \"input_cost_per_token\": 5e-06,\n
        \       \"output_cost_per_token\": 1.6e-05,\n        \"litellm_provider\":
        \"vertex_ai-llama_models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_vision\": true,\n        \"source\": \"https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"vertex_ai/meta/llama-3.2-90b-vision-instruct-maas\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 2048,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"vertex_ai-llama_models\",\n
        \       \"mode\": \"chat\",\n        \"supports_system_messages\": true,\n
        \       \"supports_vision\": true,\n        \"source\": \"https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas\",\n
        \       \"supports_tool_choice\": true,\n        \"metadata\": {\n            \"notes\":
        \"VertexAI states that The Llama 3.2 API service is at no cost during public
        preview, and will be priced as per dollar-per-1M-tokens at GA.\"\n        }\n
        \   },\n    \"vertex_ai/mistral-large@latest\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        6e-06,\n        \"litellm_provider\": \"vertex_ai-mistral_models\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/mistral-large@2411-001\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        6e-06,\n        \"litellm_provider\": \"vertex_ai-mistral_models\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/mistral-large-2411\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        6e-06,\n        \"litellm_provider\": \"vertex_ai-mistral_models\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/mistral-large@2407\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        6e-06,\n        \"litellm_provider\": \"vertex_ai-mistral_models\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/mistral-nemo@latest\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        1.5e-07,\n        \"litellm_provider\": \"vertex_ai-mistral_models\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/mistral-small-2503@001\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 1e-06,\n        \"output_cost_per_token\":
        3e-06,\n        \"litellm_provider\": \"vertex_ai-mistral_models\",\n        \"supports_function_calling\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"vertex_ai/mistral-small-2503\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 128000,\n
        \       \"input_cost_per_token\": 1e-06,\n        \"output_cost_per_token\":
        3e-06,\n        \"litellm_provider\": \"vertex_ai-mistral_models\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/jamba-1.5-mini@001\":
        {\n        \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n
        \       \"max_output_tokens\": 256000,\n        \"input_cost_per_token\":
        2e-07,\n        \"output_cost_per_token\": 4e-07,\n        \"litellm_provider\":
        \"vertex_ai-ai21_models\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/jamba-1.5-large@001\": {\n        \"max_tokens\":
        256000,\n        \"max_input_tokens\": 256000,\n        \"max_output_tokens\":
        256000,\n        \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        8e-06,\n        \"litellm_provider\": \"vertex_ai-ai21_models\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/jamba-1.5\":
        {\n        \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n
        \       \"max_output_tokens\": 256000,\n        \"input_cost_per_token\":
        2e-07,\n        \"output_cost_per_token\": 4e-07,\n        \"litellm_provider\":
        \"vertex_ai-ai21_models\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/jamba-1.5-mini\": {\n        \"max_tokens\":
        256000,\n        \"max_input_tokens\": 256000,\n        \"max_output_tokens\":
        256000,\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        4e-07,\n        \"litellm_provider\": \"vertex_ai-ai21_models\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/jamba-1.5-large\":
        {\n        \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n
        \       \"max_output_tokens\": 256000,\n        \"input_cost_per_token\":
        2e-06,\n        \"output_cost_per_token\": 8e-06,\n        \"litellm_provider\":
        \"vertex_ai-ai21_models\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/mistral-nemo@2407\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        3e-06,\n        \"litellm_provider\": \"vertex_ai-mistral_models\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/codestral@latest\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"litellm_provider\": \"vertex_ai-mistral_models\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/codestral@2405\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"litellm_provider\": \"vertex_ai-mistral_models\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/codestral-2501\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"litellm_provider\": \"vertex_ai-mistral_models\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/imagegeneration@006\": {\n        \"output_cost_per_image\":
        0.02,\n        \"litellm_provider\": \"vertex_ai-image-models\",\n        \"mode\":
        \"image_generation\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n
        \   },\n    \"vertex_ai/imagen-4.0-generate-001\": {\n        \"output_cost_per_image\":
        0.04,\n        \"litellm_provider\": \"vertex_ai-image-models\",\n        \"mode\":
        \"image_generation\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n
        \   },\n    \"vertex_ai/imagen-4.0-generate-preview-06-06\": {\n        \"output_cost_per_image\":
        0.04,\n        \"litellm_provider\": \"vertex_ai-image-models\",\n        \"mode\":
        \"image_generation\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n
        \   },\n    \"vertex_ai/imagen-4.0-ultra-generate-preview-06-06\": {\n        \"output_cost_per_image\":
        0.06,\n        \"litellm_provider\": \"vertex_ai-image-models\",\n        \"mode\":
        \"image_generation\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n
        \   },\n    \"vertex_ai/imagen-4.0-ultra-generate-001\": {\n        \"output_cost_per_image\":
        0.06,\n        \"litellm_provider\": \"vertex_ai-image-models\",\n        \"mode\":
        \"image_generation\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n
        \   },\n    \"vertex_ai/imagen-4.0-fast-generate-001\": {\n        \"output_cost_per_image\":
        0.02,\n        \"litellm_provider\": \"vertex_ai-image-models\",\n        \"mode\":
        \"image_generation\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n
        \   },\n    \"vertex_ai/imagen-4.0-fast-generate-preview-06-06\": {\n        \"output_cost_per_image\":
        0.02,\n        \"litellm_provider\": \"vertex_ai-image-models\",\n        \"mode\":
        \"image_generation\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n
        \   },\n    \"vertex_ai/imagen-3.0-generate-002\": {\n        \"output_cost_per_image\":
        0.04,\n        \"litellm_provider\": \"vertex_ai-image-models\",\n        \"mode\":
        \"image_generation\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n
        \   },\n    \"vertex_ai/imagen-3.0-generate-001\": {\n        \"output_cost_per_image\":
        0.04,\n        \"litellm_provider\": \"vertex_ai-image-models\",\n        \"mode\":
        \"image_generation\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n
        \   },\n    \"vertex_ai/imagen-3.0-fast-generate-001\": {\n        \"output_cost_per_image\":
        0.02,\n        \"litellm_provider\": \"vertex_ai-image-models\",\n        \"mode\":
        \"image_generation\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n
        \   },\n    \"text-embedding-004\": {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\":
        2048,\n        \"output_vector_size\": 768,\n        \"input_cost_per_character\":
        2.5e-08,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        0,\n        \"litellm_provider\": \"vertex_ai-embedding-models\",\n        \"mode\":
        \"embedding\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\"\n
        \   },\n    \"gemini-embedding-001\": {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\":
        2048,\n        \"output_vector_size\": 3072,\n        \"input_cost_per_token\":
        1.5e-07,\n        \"output_cost_per_token\": 0,\n        \"litellm_provider\":
        \"vertex_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\"\n    },\n
        \   \"text-embedding-005\": {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\":
        2048,\n        \"output_vector_size\": 768,\n        \"input_cost_per_character\":
        2.5e-08,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        0,\n        \"litellm_provider\": \"vertex_ai-embedding-models\",\n        \"mode\":
        \"embedding\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\"\n
        \   },\n    \"text-multilingual-embedding-002\": {\n        \"max_tokens\":
        2048,\n        \"max_input_tokens\": 2048,\n        \"output_vector_size\":
        768,\n        \"input_cost_per_character\": 2.5e-08,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 0,\n        \"litellm_provider\":
        \"vertex_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\"\n    },\n
        \   \"multimodalembedding\": {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\":
        2048,\n        \"output_vector_size\": 768,\n        \"input_cost_per_character\":
        2e-07,\n        \"input_cost_per_image\": 0.0001,\n        \"input_cost_per_video_per_second\":
        0.0005,\n        \"input_cost_per_video_per_second_above_8s_interval\": 0.001,\n
        \       \"input_cost_per_video_per_second_above_15s_interval\": 0.002,\n        \"input_cost_per_token\":
        8e-07,\n        \"output_cost_per_token\": 0,\n        \"litellm_provider\":
        \"vertex_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"supported_endpoints\":
        [\n            \"/v1/embeddings\"\n        ],\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\",\n            \"video\"\n
        \       ],\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\"\n
        \   },\n    \"multimodalembedding@001\": {\n        \"max_tokens\": 2048,\n
        \       \"max_input_tokens\": 2048,\n        \"output_vector_size\": 768,\n
        \       \"input_cost_per_character\": 2e-07,\n        \"input_cost_per_image\":
        0.0001,\n        \"input_cost_per_video_per_second\": 0.0005,\n        \"input_cost_per_video_per_second_above_8s_interval\":
        0.001,\n        \"input_cost_per_video_per_second_above_15s_interval\": 0.002,\n
        \       \"input_cost_per_token\": 8e-07,\n        \"output_cost_per_token\":
        0,\n        \"litellm_provider\": \"vertex_ai-embedding-models\",\n        \"mode\":
        \"embedding\",\n        \"supported_endpoints\": [\n            \"/v1/embeddings\"\n
        \       ],\n        \"supported_modalities\": [\n            \"text\",\n            \"image\",\n
        \           \"video\"\n        ],\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\"\n
        \   },\n    \"text-embedding-large-exp-03-07\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"output_vector_size\":
        3072,\n        \"input_cost_per_character\": 2.5e-08,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 0,\n        \"litellm_provider\":
        \"vertex_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\"\n    },\n
        \   \"textembedding-gecko\": {\n        \"max_tokens\": 3072,\n        \"max_input_tokens\":
        3072,\n        \"output_vector_size\": 768,\n        \"input_cost_per_character\":
        2.5e-08,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        0,\n        \"litellm_provider\": \"vertex_ai-embedding-models\",\n        \"mode\":
        \"embedding\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"textembedding-gecko-multilingual\": {\n        \"max_tokens\":
        3072,\n        \"max_input_tokens\": 3072,\n        \"output_vector_size\":
        768,\n        \"input_cost_per_character\": 2.5e-08,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 0,\n        \"litellm_provider\":
        \"vertex_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"textembedding-gecko-multilingual@001\": {\n        \"max_tokens\":
        3072,\n        \"max_input_tokens\": 3072,\n        \"output_vector_size\":
        768,\n        \"input_cost_per_character\": 2.5e-08,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 0,\n        \"litellm_provider\":
        \"vertex_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"textembedding-gecko@001\": {\n        \"max_tokens\": 3072,\n
        \       \"max_input_tokens\": 3072,\n        \"output_vector_size\": 768,\n
        \       \"input_cost_per_character\": 2.5e-08,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 0,\n        \"litellm_provider\":
        \"vertex_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"textembedding-gecko@003\": {\n        \"max_tokens\": 3072,\n
        \       \"max_input_tokens\": 3072,\n        \"output_vector_size\": 768,\n
        \       \"input_cost_per_character\": 2.5e-08,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 0,\n        \"litellm_provider\":
        \"vertex_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"text-embedding-preview-0409\": {\n        \"max_tokens\": 3072,\n
        \       \"max_input_tokens\": 3072,\n        \"output_vector_size\": 768,\n
        \       \"input_cost_per_token\": 6.25e-09,\n        \"input_cost_per_token_batch_requests\":
        5e-09,\n        \"output_cost_per_token\": 0,\n        \"litellm_provider\":
        \"vertex_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n    },\n    \"text-multilingual-embedding-preview-0409\":
        {\n        \"max_tokens\": 3072,\n        \"max_input_tokens\": 3072,\n        \"output_vector_size\":
        768,\n        \"input_cost_per_token\": 6.25e-09,\n        \"output_cost_per_token\":
        0,\n        \"litellm_provider\": \"vertex_ai-embedding-models\",\n        \"mode\":
        \"embedding\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"palm/chat-bison\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        1.25e-07,\n        \"output_cost_per_token\": 1.25e-07,\n        \"litellm_provider\":
        \"palm\",\n        \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"palm/chat-bison-001\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        1.25e-07,\n        \"output_cost_per_token\": 1.25e-07,\n        \"litellm_provider\":
        \"palm\",\n        \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"palm/text-bison\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        1.25e-07,\n        \"output_cost_per_token\": 1.25e-07,\n        \"litellm_provider\":
        \"palm\",\n        \"mode\": \"completion\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"palm/text-bison-001\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        1.25e-07,\n        \"output_cost_per_token\": 1.25e-07,\n        \"litellm_provider\":
        \"palm\",\n        \"mode\": \"completion\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"palm/text-bison-safety-off\": {\n        \"max_tokens\": 1024,\n
        \       \"max_input_tokens\": 8192,\n        \"max_output_tokens\": 1024,\n
        \       \"input_cost_per_token\": 1.25e-07,\n        \"output_cost_per_token\":
        1.25e-07,\n        \"litellm_provider\": \"palm\",\n        \"mode\": \"completion\",\n
        \       \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"palm/text-bison-safety-recitation-off\": {\n        \"max_tokens\":
        1024,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        1024,\n        \"input_cost_per_token\": 1.25e-07,\n        \"output_cost_per_token\":
        1.25e-07,\n        \"litellm_provider\": \"palm\",\n        \"mode\": \"completion\",\n
        \       \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini/gemini-1.5-flash-002\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 1048576,\n        \"max_output_tokens\": 8192,\n
        \       \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"cache_read_input_token_cost\": 1.875e-08,\n        \"cache_creation_input_token_cost\":
        1e-06,\n        \"input_cost_per_token\": 7.5e-08,\n        \"input_cost_per_token_above_128k_tokens\":
        1.5e-07,\n        \"output_cost_per_token\": 3e-07,\n        \"output_cost_per_token_above_128k_tokens\":
        6e-07,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_prompt_caching\": true,\n        \"tpm\": 4000000,\n
        \       \"rpm\": 2000,\n        \"source\": \"https://ai.google.dev/pricing\",\n
        \       \"deprecation_date\": \"2025-09-24\",\n        \"supports_tool_choice\":
        true\n    },\n    \"gemini/gemini-1.5-flash-001\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"cache_read_input_token_cost\": 1.875e-08,\n        \"cache_creation_input_token_cost\":
        1e-06,\n        \"input_cost_per_token\": 7.5e-08,\n        \"input_cost_per_token_above_128k_tokens\":
        1.5e-07,\n        \"output_cost_per_token\": 3e-07,\n        \"output_cost_per_token_above_128k_tokens\":
        6e-07,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_prompt_caching\": true,\n        \"tpm\": 4000000,\n
        \       \"rpm\": 2000,\n        \"source\": \"https://ai.google.dev/pricing\",\n
        \       \"deprecation_date\": \"2025-05-24\",\n        \"supports_tool_choice\":
        true\n    },\n    \"gemini/gemini-1.5-flash\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_token\": 7.5e-08,\n        \"input_cost_per_token_above_128k_tokens\":
        1.5e-07,\n        \"output_cost_per_token\": 3e-07,\n        \"output_cost_per_token_above_128k_tokens\":
        6e-07,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"tpm\": 4000000,\n        \"rpm\": 2000,\n        \"source\":
        \"https://ai.google.dev/pricing\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"gemini/gemini-1.5-flash-latest\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_token\": 7.5e-08,\n        \"input_cost_per_token_above_128k_tokens\":
        1.5e-07,\n        \"output_cost_per_token\": 3e-07,\n        \"output_cost_per_token_above_128k_tokens\":
        6e-07,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_prompt_caching\": true,\n        \"tpm\": 4000000,\n
        \       \"rpm\": 2000,\n        \"source\": \"https://ai.google.dev/pricing\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini/gemini-1.5-flash-8b\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_token\": 0,\n
        \       \"input_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_token\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_prompt_caching\":
        true,\n        \"tpm\": 4000000,\n        \"rpm\": 4000,\n        \"source\":
        \"https://ai.google.dev/pricing\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"gemini/gemini-1.5-flash-8b-exp-0924\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_token\": 0,\n        \"input_cost_per_token_above_128k_tokens\":
        0,\n        \"output_cost_per_token\": 0,\n        \"output_cost_per_token_above_128k_tokens\":
        0,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_prompt_caching\": true,\n        \"tpm\": 4000000,\n
        \       \"rpm\": 4000,\n        \"source\": \"https://ai.google.dev/pricing\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini/gemini-exp-1114\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_token\": 0,\n
        \       \"input_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_token\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"tpm\": 4000000,\n        \"rpm\": 1000,\n        \"source\":
        \"https://ai.google.dev/pricing\",\n        \"metadata\": {\n            \"notes\":
        \"Rate limits not documented for gemini-exp-1114. Assuming same as gemini-1.5-pro.\",\n
        \           \"supports_tool_choice\": true\n        }\n    },\n    \"gemini/gemini-exp-1206\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 2097152,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_token\": 0,\n
        \       \"input_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_token\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"tpm\": 4000000,\n        \"rpm\": 1000,\n        \"source\":
        \"https://ai.google.dev/pricing\",\n        \"metadata\": {\n            \"notes\":
        \"Rate limits not documented for gemini-exp-1206. Assuming same as gemini-1.5-pro.\",\n
        \           \"supports_tool_choice\": true\n        }\n    },\n    \"gemini/gemini-1.5-flash-exp-0827\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_token\": 0,\n
        \       \"input_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_token\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"tpm\": 4000000,\n
        \       \"rpm\": 2000,\n        \"source\": \"https://ai.google.dev/pricing\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini/gemini-1.5-flash-8b-exp-0827\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_token\": 0,\n
        \       \"input_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_token\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"tpm\": 4000000,\n
        \       \"rpm\": 4000,\n        \"source\": \"https://ai.google.dev/pricing\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini/gemini-pro\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 32760,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 3.5e-07,\n        \"input_cost_per_token_above_128k_tokens\":
        7e-07,\n        \"output_cost_per_token\": 1.05e-06,\n        \"output_cost_per_token_above_128k_tokens\":
        2.1e-06,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"rpd\": 30000,\n        \"tpm\":
        120000,\n        \"rpm\": 360,\n        \"source\": \"https://ai.google.dev/gemini-api/docs/models/gemini\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini/gemini-1.5-pro\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 2097152,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 3.5e-06,\n
        \       \"input_cost_per_token_above_128k_tokens\": 7e-06,\n        \"output_cost_per_token\":
        1.05e-05,\n        \"output_cost_per_token_above_128k_tokens\": 2.1e-05,\n
        \       \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        true,\n        \"tpm\": 4000000,\n        \"rpm\": 1000,\n        \"source\":
        \"https://ai.google.dev/pricing\"\n    },\n    \"gemini/gemini-1.5-pro-002\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 2097152,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 3.5e-06,\n
        \       \"input_cost_per_token_above_128k_tokens\": 7e-06,\n        \"output_cost_per_token\":
        1.05e-05,\n        \"output_cost_per_token_above_128k_tokens\": 2.1e-05,\n
        \       \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_prompt_caching\": true,\n        \"tpm\": 4000000,\n
        \       \"rpm\": 1000,\n        \"source\": \"https://ai.google.dev/pricing\",\n
        \       \"deprecation_date\": \"2025-09-24\"\n    },\n    \"gemini/gemini-1.5-pro-001\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 2097152,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 3.5e-06,\n
        \       \"input_cost_per_token_above_128k_tokens\": 7e-06,\n        \"output_cost_per_token\":
        1.05e-05,\n        \"output_cost_per_token_above_128k_tokens\": 2.1e-05,\n
        \       \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_prompt_caching\": true,\n        \"tpm\": 4000000,\n
        \       \"rpm\": 1000,\n        \"source\": \"https://ai.google.dev/pricing\",\n
        \       \"deprecation_date\": \"2025-05-24\"\n    },\n    \"gemini/gemini-1.5-pro-exp-0801\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 2097152,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 3.5e-06,\n
        \       \"input_cost_per_token_above_128k_tokens\": 7e-06,\n        \"output_cost_per_token\":
        1.05e-05,\n        \"output_cost_per_token_above_128k_tokens\": 2.1e-05,\n
        \       \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        true,\n        \"tpm\": 4000000,\n        \"rpm\": 1000,\n        \"source\":
        \"https://ai.google.dev/pricing\"\n    },\n    \"gemini/gemini-1.5-pro-exp-0827\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 2097152,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0,\n
        \       \"input_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_token\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        true,\n        \"tpm\": 4000000,\n        \"rpm\": 1000,\n        \"source\":
        \"https://ai.google.dev/pricing\"\n    },\n    \"gemini/gemini-1.5-pro-latest\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 3.5e-06,\n
        \       \"input_cost_per_token_above_128k_tokens\": 7e-06,\n        \"output_cost_per_token\":
        1.05e-06,\n        \"output_cost_per_token_above_128k_tokens\": 2.1e-05,\n
        \       \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        true,\n        \"tpm\": 4000000,\n        \"rpm\": 1000,\n        \"source\":
        \"https://ai.google.dev/pricing\"\n    },\n    \"gemini/gemini-pro-vision\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 30720,\n        \"max_output_tokens\":
        2048,\n        \"input_cost_per_token\": 3.5e-07,\n        \"input_cost_per_token_above_128k_tokens\":
        7e-07,\n        \"output_cost_per_token\": 1.05e-06,\n        \"output_cost_per_token_above_128k_tokens\":
        2.1e-06,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"rpd\": 30000,\n        \"tpm\": 120000,\n        \"rpm\":
        360,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini/gemini-gemma-2-27b-it\":
        {\n        \"max_tokens\": 8192,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        3.5e-07,\n        \"output_cost_per_token\": 1.05e-06,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini/gemini-gemma-2-9b-it\":
        {\n        \"max_tokens\": 8192,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        3.5e-07,\n        \"output_cost_per_token\": 1.05e-06,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini/imagen-4.0-generate-001\":
        {\n        \"output_cost_per_image\": 0.04,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"image_generation\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n    },\n    \"gemini/imagen-4.0-generate-preview-06-06\":
        {\n        \"output_cost_per_image\": 0.04,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"image_generation\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n    },\n    \"gemini/imagen-4.0-ultra-generate-001\":
        {\n        \"output_cost_per_image\": 0.06,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"image_generation\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n    },\n    \"gemini/imagen-4.0-ultra-generate-preview-06-06\":
        {\n        \"output_cost_per_image\": 0.06,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"image_generation\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n    },\n    \"gemini/imagen-4.0-fast-generate-001\":
        {\n        \"output_cost_per_image\": 0.02,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"image_generation\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n    },\n    \"gemini/imagen-4.0-fast-generate-preview-06-06\":
        {\n        \"output_cost_per_image\": 0.02,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"image_generation\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n    },\n    \"gemini/imagen-3.0-generate-002\":
        {\n        \"output_cost_per_image\": 0.04,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"image_generation\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n    },\n    \"gemini/imagen-3.0-generate-001\":
        {\n        \"output_cost_per_image\": 0.04,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"image_generation\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n    },\n    \"gemini/imagen-3.0-fast-generate-001\":
        {\n        \"output_cost_per_image\": 0.02,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"image_generation\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n    },\n    \"command-a-03-2025\":
        {\n        \"max_tokens\": 8000,\n        \"max_input_tokens\": 256000,\n
        \       \"max_output_tokens\": 8000,\n        \"input_cost_per_token\": 2.5e-06,\n
        \       \"output_cost_per_token\": 1e-05,\n        \"litellm_provider\": \"cohere_chat\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_tool_choice\": true\n    },\n    \"command-r\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"litellm_provider\": \"cohere_chat\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"command-r-08-2024\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"litellm_provider\": \"cohere_chat\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"command-r7b-12-2024\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        3.75e-08,\n        \"litellm_provider\": \"cohere_chat\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"source\":
        \"https://docs.cohere.com/v2/docs/command-r7b\",\n        \"supports_tool_choice\":
        true\n    },\n    \"command-light\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        4096,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        3e-07,\n        \"output_cost_per_token\": 6e-07,\n        \"litellm_provider\":
        \"cohere_chat\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"command-r-plus\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        128000,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        2.5e-06,\n        \"output_cost_per_token\": 1e-05,\n        \"litellm_provider\":
        \"cohere_chat\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"command-r-plus-08-2024\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 2.5e-06,\n
        \       \"output_cost_per_token\": 1e-05,\n        \"litellm_provider\": \"cohere_chat\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_tool_choice\": true\n    },\n    \"command-nightly\": {\n
        \       \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1e-06,\n        \"output_cost_per_token\":
        2e-06,\n        \"litellm_provider\": \"cohere\",\n        \"mode\": \"completion\"\n
        \   },\n    \"command\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        4096,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        1e-06,\n        \"output_cost_per_token\": 2e-06,\n        \"litellm_provider\":
        \"cohere\",\n        \"mode\": \"completion\"\n    },\n    \"rerank-v3.5\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"max_query_tokens\": 2048,\n        \"input_cost_per_token\":
        0.0,\n        \"input_cost_per_query\": 0.002,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"cohere\",\n        \"mode\": \"rerank\"\n
        \   },\n    \"rerank-english-v3.0\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        4096,\n        \"max_output_tokens\": 4096,\n        \"max_query_tokens\":
        2048,\n        \"input_cost_per_token\": 0.0,\n        \"input_cost_per_query\":
        0.002,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"cohere\",\n        \"mode\": \"rerank\"\n    },\n    \"rerank-multilingual-v3.0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"max_query_tokens\": 2048,\n        \"input_cost_per_token\":
        0.0,\n        \"input_cost_per_query\": 0.002,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"cohere\",\n        \"mode\": \"rerank\"\n
        \   },\n    \"rerank-english-v2.0\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        4096,\n        \"max_output_tokens\": 4096,\n        \"max_query_tokens\":
        2048,\n        \"input_cost_per_token\": 0.0,\n        \"input_cost_per_query\":
        0.002,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"cohere\",\n        \"mode\": \"rerank\"\n    },\n    \"rerank-multilingual-v2.0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"max_query_tokens\": 2048,\n        \"input_cost_per_token\":
        0.0,\n        \"input_cost_per_query\": 0.002,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"cohere\",\n        \"mode\": \"rerank\"\n
        \   },\n    \"embed-english-light-v3.0\": {\n        \"max_tokens\": 1024,\n
        \       \"max_input_tokens\": 1024,\n        \"input_cost_per_token\": 1e-07,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"cohere\",\n
        \       \"mode\": \"embedding\"\n    },\n    \"embed-multilingual-v3.0\":
        {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\": 1024,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"cohere\",\n        \"supports_embedding_image_input\": true,\n        \"mode\":
        \"embedding\"\n    },\n    \"embed-english-v2.0\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"cohere\",\n        \"mode\": \"embedding\"\n    },\n    \"embed-english-light-v2.0\":
        {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\": 1024,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"cohere\",\n        \"mode\": \"embedding\"\n    },\n    \"embed-multilingual-v2.0\":
        {\n        \"max_tokens\": 768,\n        \"max_input_tokens\": 768,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"cohere\",\n        \"mode\": \"embedding\"\n    },\n    \"embed-english-v3.0\":
        {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\": 1024,\n        \"input_cost_per_token\":
        1e-07,\n        \"input_cost_per_image\": 0.0001,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"cohere\",\n        \"mode\": \"embedding\",\n
        \       \"supports_image_input\": true,\n        \"supports_embedding_image_input\":
        true,\n        \"metadata\": {\n            \"notes\": \"'supports_image_input'
        is a deprecated field. Use 'supports_embedding_image_input' instead.\"\n        }\n
        \   },\n    \"replicate/meta/llama-2-13b\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 4096,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        5e-07,\n        \"litellm_provider\": \"replicate\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"replicate/meta/llama-2-13b-chat\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        5e-07,\n        \"litellm_provider\": \"replicate\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"replicate/meta/llama-2-70b\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 6.5e-07,\n        \"output_cost_per_token\":
        2.75e-06,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/meta/llama-2-70b-chat\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 6.5e-07,\n        \"output_cost_per_token\":
        2.75e-06,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/meta/llama-2-7b\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 5e-08,\n        \"output_cost_per_token\":
        2.5e-07,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/meta/llama-2-7b-chat\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 5e-08,\n        \"output_cost_per_token\":
        2.5e-07,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/meta/llama-3-70b\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 6.5e-07,\n        \"output_cost_per_token\":
        2.75e-06,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/meta/llama-3-70b-instruct\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 6.5e-07,\n        \"output_cost_per_token\":
        2.75e-06,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/meta/llama-3-8b\":
        {\n        \"max_tokens\": 8086,\n        \"max_input_tokens\": 8086,\n        \"max_output_tokens\":
        8086,\n        \"input_cost_per_token\": 5e-08,\n        \"output_cost_per_token\":
        2.5e-07,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/meta/llama-3-8b-instruct\":
        {\n        \"max_tokens\": 8086,\n        \"max_input_tokens\": 8086,\n        \"max_output_tokens\":
        8086,\n        \"input_cost_per_token\": 5e-08,\n        \"output_cost_per_token\":
        2.5e-07,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/mistralai/mistral-7b-v0.1\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 5e-08,\n        \"output_cost_per_token\":
        2.5e-07,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/mistralai/mistral-7b-instruct-v0.2\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 5e-08,\n        \"output_cost_per_token\":
        2.5e-07,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/mistralai/mixtral-8x7b-instruct-v0.1\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        1e-06,\n        \"litellm_provider\": \"replicate\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"openrouter/deepseek/deepseek-r1-0528\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 65336,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 5e-07,\n        \"input_cost_per_token_cache_hit\":
        1.4e-07,\n        \"output_cost_per_token\": 2.15e-06,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_prompt_caching\":
        true\n    },\n    \"openrouter/x-ai/grok-4\": {\n        \"max_tokens\": 256000,\n
        \       \"max_input_tokens\": 256000,\n        \"max_output_tokens\": 256000,\n
        \       \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"source\": \"https://openrouter.ai/x-ai/grok-4\",\n
        \       \"supports_web_search\": true\n    },\n    \"openrouter/bytedance/ui-tars-1.5-7b\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 2048,\n        \"input_cost_per_token\": 1e-07,\n
        \       \"output_cost_per_token\": 2e-07,\n        \"litellm_provider\": \"openrouter\",\n
        \       \"mode\": \"chat\",\n        \"source\": \"https://openrouter.ai/api/v1/models/bytedance/ui-tars-1.5-7b\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"openrouter/deepseek/deepseek-r1\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 65336,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 5.5e-07,\n        \"input_cost_per_token_cache_hit\":
        1.4e-07,\n        \"output_cost_per_token\": 2.19e-06,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_prompt_caching\":
        true\n    },\n    \"openrouter/deepseek/deepseek-chat\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 65536,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 1.4e-07,\n        \"output_cost_per_token\":
        2.8e-07,\n        \"litellm_provider\": \"openrouter\",\n        \"supports_prompt_caching\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"openrouter/deepseek/deepseek-chat-v3-0324\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 65536,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 1.4e-07,\n        \"output_cost_per_token\":
        2.8e-07,\n        \"litellm_provider\": \"openrouter\",\n        \"supports_prompt_caching\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"openrouter/deepseek/deepseek-coder\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 66000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.4e-07,\n        \"output_cost_per_token\":
        2.8e-07,\n        \"litellm_provider\": \"openrouter\",\n        \"supports_prompt_caching\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"openrouter/microsoft/wizardlm-2-8x22b:nitro\": {\n        \"max_tokens\":
        65536,\n        \"input_cost_per_token\": 1e-06,\n        \"output_cost_per_token\":
        1e-06,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"openrouter/google/gemini-2.5-pro\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        7e-07,\n        \"input_cost_per_token\": 1.25e-06,\n        \"output_cost_per_token\":
        1e-05,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/google/gemini-pro-1.5\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1000000,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 2.5e-06,\n        \"output_cost_per_token\":
        7.5e-06,\n        \"input_cost_per_image\": 0.00265,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/google/gemini-2.0-flash-001\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 7e-07,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 4e-07,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/google/gemini-2.5-flash\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        7e-07,\n        \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        2.5e-06,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/mistralai/mixtral-8x22b-instruct\": {\n        \"max_tokens\":
        65536,\n        \"input_cost_per_token\": 6.5e-07,\n        \"output_cost_per_token\":
        6.5e-07,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/cohere/command-r-plus\":
        {\n        \"max_tokens\": 128000,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/databricks/dbrx-instruct\": {\n        \"max_tokens\":
        32768,\n        \"input_cost_per_token\": 6e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"openrouter/anthropic/claude-3-haiku\":
        {\n        \"max_tokens\": 200000,\n        \"input_cost_per_token\": 2.5e-07,\n
        \       \"output_cost_per_token\": 1.25e-06,\n        \"input_cost_per_image\":
        0.0004,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/anthropic/claude-3-5-haiku\":
        {\n        \"max_tokens\": 200000,\n        \"input_cost_per_token\": 1e-06,\n
        \       \"output_cost_per_token\": 5e-06,\n        \"litellm_provider\": \"openrouter\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_tool_choice\": true\n    },\n    \"openrouter/anthropic/claude-3-haiku-20240307\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 2.5e-07,\n
        \       \"output_cost_per_token\": 1.25e-06,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        264,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/anthropic/claude-3-5-haiku-20241022\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 1e-06,\n
        \       \"output_cost_per_token\": 5e-06,\n        \"litellm_provider\": \"openrouter\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"tool_use_system_prompt_tokens\": 264,\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/anthropic/claude-3.5-sonnet\": {\n        \"supports_computer_use\":
        true,\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/anthropic/claude-3.5-sonnet:beta\": {\n        \"supports_computer_use\":
        true,\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/anthropic/claude-3.7-sonnet\":
        {\n        \"supports_computer_use\": true,\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"input_cost_per_image\": 0.0048,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_reasoning\":
        true,\n        \"tool_use_system_prompt_tokens\": 159,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/anthropic/claude-3.7-sonnet:beta\":
        {\n        \"supports_computer_use\": true,\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"input_cost_per_image\": 0.0048,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_reasoning\":
        true,\n        \"tool_use_system_prompt_tokens\": 159,\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/anthropic/claude-3-sonnet\": {\n        \"max_tokens\":
        200000,\n        \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"input_cost_per_image\": 0.0048,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/anthropic/claude-sonnet-4\": {\n        \"supports_computer_use\":
        true,\n        \"max_tokens\": 64000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 64000,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"input_cost_per_image\":
        0.0048,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_reasoning\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/mistralai/mistral-large\": {\n        \"max_tokens\":
        32000,\n        \"input_cost_per_token\": 8e-06,\n        \"output_cost_per_token\":
        2.4e-05,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/mistralai/mistral-small-3.1-24b-instruct\":
        {\n        \"max_tokens\": 32000,\n        \"input_cost_per_token\": 1e-07,\n
        \       \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\": \"openrouter\",\n
        \       \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n    },\n
        \   \"openrouter/mistralai/mistral-small-3.2-24b-instruct\": {\n        \"max_tokens\":
        32000,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        3e-07,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"openrouter/cognitivecomputations/dolphin-mixtral-8x7b\":
        {\n        \"max_tokens\": 32769,\n        \"input_cost_per_token\": 5e-07,\n
        \       \"output_cost_per_token\": 5e-07,\n        \"litellm_provider\": \"openrouter\",\n
        \       \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n    },\n
        \   \"openrouter/google/gemini-pro-vision\": {\n        \"max_tokens\": 45875,\n
        \       \"input_cost_per_token\": 1.25e-07,\n        \"output_cost_per_token\":
        3.75e-07,\n        \"input_cost_per_image\": 0.0025,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/fireworks/firellava-13b\": {\n        \"max_tokens\":
        4096,\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        2e-07,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"openrouter/meta-llama/llama-3-8b-instruct:free\":
        {\n        \"max_tokens\": 8192,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"openrouter\",\n
        \       \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n    },\n
        \   \"openrouter/meta-llama/llama-3-8b-instruct:extended\": {\n        \"max_tokens\":
        16384,\n        \"input_cost_per_token\": 2.25e-07,\n        \"output_cost_per_token\":
        2.25e-06,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/meta-llama/llama-3-70b-instruct:nitro\":
        {\n        \"max_tokens\": 8192,\n        \"input_cost_per_token\": 9e-07,\n
        \       \"output_cost_per_token\": 9e-07,\n        \"litellm_provider\": \"openrouter\",\n
        \       \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n    },\n
        \   \"openrouter/meta-llama/llama-3-70b-instruct\": {\n        \"max_tokens\":
        8192,\n        \"input_cost_per_token\": 5.9e-07,\n        \"output_cost_per_token\":
        7.9e-07,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/o1\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        1.5e-05,\n        \"output_cost_per_token\": 6e-05,\n        \"cache_read_input_token_cost\":
        7.5e-06,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/o1-mini\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 65536,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.2e-05,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        false,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/o1-mini-2024-09-12\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 65536,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.2e-05,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        false,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/o1-preview\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 1.5e-05,\n
        \       \"output_cost_per_token\": 6e-05,\n        \"litellm_provider\": \"openrouter\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        false,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/o1-preview-2024-09-12\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 1.5e-05,\n
        \       \"output_cost_per_token\": 6e-05,\n        \"litellm_provider\": \"openrouter\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        false,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/o3-mini\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 65536,\n        \"input_cost_per_token\": 1.1e-06,\n
        \       \"output_cost_per_token\": 4.4e-06,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": false,\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/openai/o3-mini-high\": {\n        \"max_tokens\":
        65536,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        65536,\n        \"input_cost_per_token\": 1.1e-06,\n        \"output_cost_per_token\":
        4.4e-06,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        false,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/gpt-4o\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 2.5e-06,\n
        \       \"output_cost_per_token\": 1e-05,\n        \"litellm_provider\": \"openrouter\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/gpt-4o-2024-05-13\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 5e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/gpt-4-vision-preview\":
        {\n        \"max_tokens\": 130000,\n        \"input_cost_per_token\": 1e-05,\n
        \       \"output_cost_per_token\": 3e-05,\n        \"input_cost_per_image\":
        0.01445,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/gpt-3.5-turbo\":
        {\n        \"max_tokens\": 4095,\n        \"input_cost_per_token\": 1.5e-06,\n
        \       \"output_cost_per_token\": 2e-06,\n        \"litellm_provider\": \"openrouter\",\n
        \       \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n    },\n
        \   \"openrouter/openai/gpt-3.5-turbo-16k\": {\n        \"max_tokens\": 16383,\n
        \       \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        4e-06,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/gpt-4\":
        {\n        \"max_tokens\": 8192,\n        \"input_cost_per_token\": 3e-05,\n
        \       \"output_cost_per_token\": 6e-05,\n        \"litellm_provider\": \"openrouter\",\n
        \       \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n    },\n
        \   \"openrouter/openai/gpt-oss-20b\": {\n        \"max_tokens\": 32768,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 32768,\n
        \       \"input_cost_per_token\": 1.8e-07,\n        \"output_cost_per_token\":
        8e-07,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true,\n        \"source\": \"https://openrouter.ai/openai/gpt-oss-20b\"\n
        \   },\n    \"openrouter/openai/gpt-oss-120b\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 1.8e-07,\n        \"output_cost_per_token\":
        8e-07,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true,\n        \"source\": \"https://openrouter.ai/openai/gpt-oss-120b\"\n
        \   },\n    \"openrouter/anthropic/claude-instant-v1\": {\n        \"max_tokens\":
        100000,\n        \"max_output_tokens\": 8191,\n        \"input_cost_per_token\":
        1.63e-06,\n        \"output_cost_per_token\": 5.51e-06,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/anthropic/claude-2\": {\n        \"max_tokens\":
        100000,\n        \"max_output_tokens\": 8191,\n        \"input_cost_per_token\":
        1.102e-05,\n        \"output_cost_per_token\": 3.268e-05,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/anthropic/claude-3-opus\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.5e-05,\n        \"output_cost_per_token\":
        7.5e-05,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"tool_use_system_prompt_tokens\": 395,\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/google/palm-2-chat-bison\": {\n        \"max_tokens\":
        25804,\n        \"input_cost_per_token\": 5e-07,\n        \"output_cost_per_token\":
        5e-07,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"openrouter/google/palm-2-codechat-bison\":
        {\n        \"max_tokens\": 20070,\n        \"input_cost_per_token\": 5e-07,\n
        \       \"output_cost_per_token\": 5e-07,\n        \"litellm_provider\": \"openrouter\",\n
        \       \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n    },\n
        \   \"openrouter/meta-llama/llama-2-13b-chat\": {\n        \"max_tokens\":
        4096,\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        2e-07,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"openrouter/meta-llama/llama-2-70b-chat\":
        {\n        \"max_tokens\": 4096,\n        \"input_cost_per_token\": 1.5e-06,\n
        \       \"output_cost_per_token\": 1.5e-06,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/meta-llama/codellama-34b-instruct\": {\n        \"max_tokens\":
        8192,\n        \"input_cost_per_token\": 5e-07,\n        \"output_cost_per_token\":
        5e-07,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"openrouter/nousresearch/nous-hermes-llama2-13b\":
        {\n        \"max_tokens\": 4096,\n        \"input_cost_per_token\": 2e-07,\n
        \       \"output_cost_per_token\": 2e-07,\n        \"litellm_provider\": \"openrouter\",\n
        \       \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n    },\n
        \   \"openrouter/mancer/weaver\": {\n        \"max_tokens\": 8000,\n        \"input_cost_per_token\":
        5.625e-06,\n        \"output_cost_per_token\": 5.625e-06,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/gryphe/mythomax-l2-13b\": {\n        \"max_tokens\":
        8192,\n        \"input_cost_per_token\": 1.875e-06,\n        \"output_cost_per_token\":
        1.875e-06,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/jondurbin/airoboros-l2-70b-2.1\":
        {\n        \"max_tokens\": 4096,\n        \"input_cost_per_token\": 1.3875e-05,\n
        \       \"output_cost_per_token\": 1.3875e-05,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/undi95/remm-slerp-l2-13b\": {\n        \"max_tokens\":
        6144,\n        \"input_cost_per_token\": 1.875e-06,\n        \"output_cost_per_token\":
        1.875e-06,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/pygmalionai/mythalion-13b\":
        {\n        \"max_tokens\": 4096,\n        \"input_cost_per_token\": 1.875e-06,\n
        \       \"output_cost_per_token\": 1.875e-06,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/mistralai/mistral-7b-instruct\": {\n        \"max_tokens\":
        8192,\n        \"input_cost_per_token\": 1.3e-07,\n        \"output_cost_per_token\":
        1.3e-07,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/mistralai/mistral-7b-instruct:free\":
        {\n        \"max_tokens\": 8192,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"openrouter\",\n
        \       \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n    },\n
        \   \"openrouter/qwen/qwen-2.5-coder-32b-instruct\": {\n        \"max_tokens\":
        33792,\n        \"max_input_tokens\": 33792,\n        \"max_output_tokens\":
        33792,\n        \"input_cost_per_token\": 1.8e-07,\n        \"output_cost_per_token\":
        1.8e-07,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/qwen/qwen-vl-plus\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        2048,\n        \"input_cost_per_token\": 2.1e-07,\n        \"output_cost_per_token\":
        6.3e-07,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/qwen/qwen3-coder\":
        {\n        \"max_tokens\": 1000000,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 1000000,\n        \"input_cost_per_token\":
        1e-06,\n        \"output_cost_per_token\": 5e-06,\n        \"litellm_provider\":
        \"openrouter\",\n        \"source\": \"https://openrouter.ai/qwen/qwen3-coder\",\n
        \       \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n    },\n
        \   \"openrouter/switchpoint/router\": {\n        \"max_tokens\": 131072,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 131072,\n
        \       \"input_cost_per_token\": 8.5e-07,\n        \"output_cost_per_token\":
        3.4e-06,\n        \"litellm_provider\": \"openrouter\",\n        \"source\":
        \"https://openrouter.ai/switchpoint/router\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"j2-ultra\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 1.5e-05,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"litellm_provider\": \"ai21\",\n        \"mode\": \"completion\"\n
        \   },\n    \"jamba-1.5-mini@001\": {\n        \"max_tokens\": 256000,\n        \"max_input_tokens\":
        256000,\n        \"max_output_tokens\": 256000,\n        \"input_cost_per_token\":
        2e-07,\n        \"output_cost_per_token\": 4e-07,\n        \"litellm_provider\":
        \"ai21\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"jamba-1.5-large@001\": {\n        \"max_tokens\": 256000,\n
        \       \"max_input_tokens\": 256000,\n        \"max_output_tokens\": 256000,\n
        \       \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        8e-06,\n        \"litellm_provider\": \"ai21\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"jamba-1.5\": {\n        \"max_tokens\":
        256000,\n        \"max_input_tokens\": 256000,\n        \"max_output_tokens\":
        256000,\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        4e-07,\n        \"litellm_provider\": \"ai21\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"jamba-1.5-mini\": {\n
        \       \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n        \"max_output_tokens\":
        256000,\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        4e-07,\n        \"litellm_provider\": \"ai21\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"jamba-1.5-large\": {\n
        \       \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n        \"max_output_tokens\":
        256000,\n        \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        8e-06,\n        \"litellm_provider\": \"ai21\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"jamba-large-1.6\": {\n
        \       \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n        \"max_output_tokens\":
        256000,\n        \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        8e-06,\n        \"litellm_provider\": \"ai21\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"jamba-large-1.7\": {\n
        \       \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n        \"max_output_tokens\":
        256000,\n        \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        8e-06,\n        \"litellm_provider\": \"ai21\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"jamba-mini-1.6\": {\n
        \       \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n        \"max_output_tokens\":
        256000,\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        4e-07,\n        \"litellm_provider\": \"ai21\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"jamba-mini-1.7\": {\n
        \       \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n        \"max_output_tokens\":
        256000,\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        4e-07,\n        \"litellm_provider\": \"ai21\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"j2-mid\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 1e-05,\n        \"output_cost_per_token\":
        1e-05,\n        \"litellm_provider\": \"ai21\",\n        \"mode\": \"completion\"\n
        \   },\n    \"j2-light\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        3e-06,\n        \"output_cost_per_token\": 3e-06,\n        \"litellm_provider\":
        \"ai21\",\n        \"mode\": \"completion\"\n    },\n    \"dolphin\": {\n
        \       \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 5e-07,\n        \"output_cost_per_token\":
        5e-07,\n        \"litellm_provider\": \"nlp_cloud\",\n        \"mode\": \"completion\"\n
        \   },\n    \"chatdolphin\": {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\":
        16384,\n        \"max_output_tokens\": 16384,\n        \"input_cost_per_token\":
        5e-07,\n        \"output_cost_per_token\": 5e-07,\n        \"litellm_provider\":
        \"nlp_cloud\",\n        \"mode\": \"chat\"\n    },\n    \"luminous-base\":
        {\n        \"max_tokens\": 2048,\n        \"input_cost_per_token\": 3e-05,\n
        \       \"output_cost_per_token\": 3.3e-05,\n        \"litellm_provider\":
        \"aleph_alpha\",\n        \"mode\": \"completion\"\n    },\n    \"luminous-base-control\":
        {\n        \"max_tokens\": 2048,\n        \"input_cost_per_token\": 3.75e-05,\n
        \       \"output_cost_per_token\": 4.125e-05,\n        \"litellm_provider\":
        \"aleph_alpha\",\n        \"mode\": \"chat\"\n    },\n    \"luminous-extended\":
        {\n        \"max_tokens\": 2048,\n        \"input_cost_per_token\": 4.5e-05,\n
        \       \"output_cost_per_token\": 4.95e-05,\n        \"litellm_provider\":
        \"aleph_alpha\",\n        \"mode\": \"completion\"\n    },\n    \"luminous-extended-control\":
        {\n        \"max_tokens\": 2048,\n        \"input_cost_per_token\": 5.625e-05,\n
        \       \"output_cost_per_token\": 6.1875e-05,\n        \"litellm_provider\":
        \"aleph_alpha\",\n        \"mode\": \"chat\"\n    },\n    \"luminous-supreme\":
        {\n        \"max_tokens\": 2048,\n        \"input_cost_per_token\": 0.000175,\n
        \       \"output_cost_per_token\": 0.0001925,\n        \"litellm_provider\":
        \"aleph_alpha\",\n        \"mode\": \"completion\"\n    },\n    \"luminous-supreme-control\":
        {\n        \"max_tokens\": 2048,\n        \"input_cost_per_token\": 0.00021875,\n
        \       \"output_cost_per_token\": 0.000240625,\n        \"litellm_provider\":
        \"aleph_alpha\",\n        \"mode\": \"chat\"\n    },\n    \"ai21.j2-mid-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 8191,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 1.25e-05,\n        \"output_cost_per_token\":
        1.25e-05,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"ai21.j2-ultra-v1\": {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\":
        8191,\n        \"max_output_tokens\": 8191,\n        \"input_cost_per_token\":
        1.88e-05,\n        \"output_cost_per_token\": 1.88e-05,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"ai21.jamba-instruct-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 70000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 5e-07,\n        \"output_cost_per_token\":
        7e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true\n    },\n    \"ai21.jamba-1-5-large-v1:0\":
        {\n        \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n
        \       \"max_output_tokens\": 256000,\n        \"input_cost_per_token\":
        2e-06,\n        \"output_cost_per_token\": 8e-06,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"ai21.jamba-1-5-mini-v1:0\":
        {\n        \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n
        \       \"max_output_tokens\": 256000,\n        \"input_cost_per_token\":
        2e-07,\n        \"output_cost_per_token\": 4e-07,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"amazon.rerank-v1:0\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 32000,\n
        \       \"max_output_tokens\": 32000,\n        \"max_query_tokens\": 32000,\n
        \       \"max_document_chunks_per_query\": 100,\n        \"max_tokens_per_document_chunk\":
        512,\n        \"input_cost_per_token\": 0.0,\n        \"input_cost_per_query\":
        0.001,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"rerank\"\n    },\n    \"amazon.titan-text-lite-v1\":
        {\n        \"max_tokens\": 4000,\n        \"max_input_tokens\": 42000,\n        \"max_output_tokens\":
        4000,\n        \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        4e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"amazon.titan-text-express-v1\": {\n        \"max_tokens\": 8000,\n
        \       \"max_input_tokens\": 42000,\n        \"max_output_tokens\": 8000,\n
        \       \"input_cost_per_token\": 1.3e-06,\n        \"output_cost_per_token\":
        1.7e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"amazon.titan-text-premier-v1:0\": {\n        \"max_tokens\":
        32000,\n        \"max_input_tokens\": 42000,\n        \"max_output_tokens\":
        32000,\n        \"input_cost_per_token\": 5e-07,\n        \"output_cost_per_token\":
        1.5e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"amazon.titan-embed-text-v1\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 8192,\n        \"output_vector_size\": 1536,\n
        \       \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"amazon.titan-embed-text-v2:0\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 8192,\n        \"output_vector_size\": 1024,\n
        \       \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"amazon.titan-embed-image-v1\": {\n        \"max_tokens\": 128,\n
        \       \"max_input_tokens\": 128,\n        \"output_vector_size\": 1024,\n
        \       \"input_cost_per_token\": 8e-07,\n        \"input_cost_per_image\":
        6e-05,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"bedrock\",\n        \"supports_image_input\": true,\n        \"supports_embedding_image_input\":
        true,\n        \"mode\": \"embedding\",\n        \"source\": \"https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/providers?model=amazon.titan-image-generator-v1\",\n
        \       \"metadata\": {\n            \"notes\": \"'supports_image_input' is
        a deprecated field. Use 'supports_embedding_image_input' instead.\"\n        }\n
        \   },\n    \"mistral.mistral-7b-instruct-v0:2\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        2e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"mistral.mixtral-8x7b-instruct-v0:1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 4.5e-07,\n        \"output_cost_per_token\":
        7e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"mistral.mistral-large-2402-v1:0\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 8e-06,\n        \"output_cost_per_token\":
        2.4e-05,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"mistral.mistral-large-2407-v1:0\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 9e-06,\n        \"litellm_provider\": \"bedrock\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_tool_choice\": true\n    },\n    \"mistral.mistral-small-2402-v1:0\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 1e-06,\n        \"output_cost_per_token\":
        3e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"eu.mistral.pixtral-large-2502-v1:0\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 2e-06,\n
        \       \"output_cost_per_token\": 6e-06,\n        \"litellm_provider\": \"bedrock_converse\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_tool_choice\": false\n    },\n    \"us.mistral.pixtral-large-2502-v1:0\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 2e-06,\n
        \       \"output_cost_per_token\": 6e-06,\n        \"litellm_provider\": \"bedrock_converse\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_tool_choice\": false\n    },\n    \"bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 4.5e-07,\n        \"output_cost_per_token\":
        7e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 4.5e-07,\n        \"output_cost_per_token\":
        7e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 5.9e-07,\n        \"output_cost_per_token\":
        9.1e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        2e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        2e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        2.6e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/us-east-1/mistral.mistral-large-2402-v1:0\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 8e-06,\n        \"output_cost_per_token\":
        2.4e-05,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"bedrock/us-west-2/mistral.mistral-large-2402-v1:0\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 8e-06,\n        \"output_cost_per_token\":
        2.4e-05,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"bedrock/eu-west-3/mistral.mistral-large-2402-v1:0\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 1.04e-05,\n        \"output_cost_per_token\":
        3.12e-05,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"amazon.nova-micro-v1:0\":
        {\n        \"max_tokens\": 10000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 10000,\n        \"input_cost_per_token\": 3.5e-08,\n
        \       \"output_cost_per_token\": 1.4e-07,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"us.amazon.nova-micro-v1:0\": {\n        \"max_tokens\":
        10000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        10000,\n        \"input_cost_per_token\": 3.5e-08,\n        \"output_cost_per_token\":
        1.4e-07,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"eu.amazon.nova-micro-v1:0\":
        {\n        \"max_tokens\": 10000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 10000,\n        \"input_cost_per_token\": 4.6e-08,\n
        \       \"output_cost_per_token\": 1.84e-07,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"amazon.nova-lite-v1:0\": {\n        \"max_tokens\": 10000,\n
        \       \"max_input_tokens\": 300000,\n        \"max_output_tokens\": 10000,\n
        \       \"input_cost_per_token\": 6e-08,\n        \"output_cost_per_token\":
        2.4e-07,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"us.amazon.nova-lite-v1:0\":
        {\n        \"max_tokens\": 10000,\n        \"max_input_tokens\": 300000,\n
        \       \"max_output_tokens\": 10000,\n        \"input_cost_per_token\": 6e-08,\n
        \       \"output_cost_per_token\": 2.4e-07,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"eu.amazon.nova-lite-v1:0\": {\n        \"max_tokens\":
        10000,\n        \"max_input_tokens\": 300000,\n        \"max_output_tokens\":
        10000,\n        \"input_cost_per_token\": 7.8e-08,\n        \"output_cost_per_token\":
        3.12e-07,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"amazon.nova-pro-v1:0\":
        {\n        \"max_tokens\": 10000,\n        \"max_input_tokens\": 300000,\n
        \       \"max_output_tokens\": 10000,\n        \"input_cost_per_token\": 8e-07,\n
        \       \"output_cost_per_token\": 3.2e-06,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"us.amazon.nova-pro-v1:0\": {\n        \"max_tokens\":
        10000,\n        \"max_input_tokens\": 300000,\n        \"max_output_tokens\":
        10000,\n        \"input_cost_per_token\": 8e-07,\n        \"output_cost_per_token\":
        3.2e-06,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"1024-x-1024/50-steps/bedrock/amazon.nova-canvas-v1:0\":
        {\n        \"max_input_tokens\": 2600,\n        \"output_cost_per_image\":
        0.06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"eu.amazon.nova-pro-v1:0\": {\n        \"max_tokens\": 10000,\n
        \       \"max_input_tokens\": 300000,\n        \"max_output_tokens\": 10000,\n
        \       \"input_cost_per_token\": 1.05e-06,\n        \"output_cost_per_token\":
        4.2e-06,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://aws.amazon.com/bedrock/pricing/\"\n
        \   },\n    \"apac.amazon.nova-micro-v1:0\": {\n        \"max_tokens\": 10000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 10000,\n
        \       \"input_cost_per_token\": 3.7e-08,\n        \"output_cost_per_token\":
        1.48e-07,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"apac.amazon.nova-lite-v1:0\":
        {\n        \"max_tokens\": 10000,\n        \"max_input_tokens\": 300000,\n
        \       \"max_output_tokens\": 10000,\n        \"input_cost_per_token\": 6.3e-08,\n
        \       \"output_cost_per_token\": 2.52e-07,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"apac.amazon.nova-pro-v1:0\": {\n        \"max_tokens\":
        10000,\n        \"max_input_tokens\": 300000,\n        \"max_output_tokens\":
        10000,\n        \"input_cost_per_token\": 8.4e-07,\n        \"output_cost_per_token\":
        3.36e-06,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"us.amazon.nova-premier-v1:0\":
        {\n        \"max_tokens\": 10000,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 10000,\n        \"input_cost_per_token\": 2.5e-06,\n
        \       \"output_cost_per_token\": 1.25e-05,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": false,\n        \"supports_response_schema\":
        true\n    },\n    \"anthropic.claude-3-sonnet-20240229-v1:0\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"bedrock/invoke/anthropic.claude-3-5-sonnet-20240620-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true,\n        \"metadata\": {\n
        \           \"notes\": \"Anthropic via Invoke route does not currently support
        pdf input.\"\n        }\n    },\n    \"anthropic.claude-3-5-sonnet-20240620-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"openai.gpt-oss-20b-1:0\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 128000,\n
        \       \"input_cost_per_token\": 7e-08,\n        \"output_cost_per_token\":
        3e-07,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"openai.gpt-oss-120b-1:0\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        1.5e-07,\n        \"output_cost_per_token\": 6e-07,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true\n    },\n    \"anthropic.claude-opus-4-1-20250805-v1:0\": {\n        \"max_tokens\":
        32000,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        32000,\n        \"input_cost_per_token\": 1.5e-05,\n        \"output_cost_per_token\":
        7.5e-05,\n        \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        0.01,\n            \"search_context_size_medium\": 0.01,\n            \"search_context_size_high\":
        0.01\n        },\n        \"cache_creation_input_token_cost\": 1.875e-05,\n
        \       \"cache_read_input_token_cost\": 1.5e-06,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"anthropic.claude-opus-4-20250514-v1:0\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 32000,\n        \"input_cost_per_token\": 1.5e-05,\n
        \       \"output_cost_per_token\": 7.5e-05,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.01,\n            \"search_context_size_medium\":
        0.01,\n            \"search_context_size_high\": 0.01\n        },\n        \"cache_creation_input_token_cost\":
        1.875e-05,\n        \"cache_read_input_token_cost\": 1.5e-06,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"anthropic.claude-sonnet-4-20250514-v1:0\":
        {\n        \"max_tokens\": 64000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 64000,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.01,\n            \"search_context_size_medium\":
        0.01,\n            \"search_context_size_high\": 0.01\n        },\n        \"cache_creation_input_token_cost\":
        3.75e-06,\n        \"cache_read_input_token_cost\": 3e-07,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"anthropic.claude-3-7-sonnet-20250219-v1:0\":
        {\n        \"supports_computer_use\": true,\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"cache_creation_input_token_cost\": 3.75e-06,\n        \"cache_read_input_token_cost\":
        3e-07,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"anthropic.claude-3-5-sonnet-20241022-v2:0\": {\n        \"supports_computer_use\":
        true,\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"cache_creation_input_token_cost\":
        3.75e-06,\n        \"cache_read_input_token_cost\": 3e-07,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"anthropic.claude-3-haiku-20240307-v1:0\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 2.5e-07,\n        \"output_cost_per_token\":
        1.25e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"anthropic.claude-3-5-haiku-20241022-v1:0\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 8e-07,\n
        \       \"output_cost_per_token\": 4e-06,\n        \"cache_creation_input_token_cost\":
        1e-06,\n        \"cache_read_input_token_cost\": 8e-08,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_assistant_prefill\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"anthropic.claude-3-opus-20240229-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 1.5e-05,\n
        \       \"output_cost_per_token\": 7.5e-05,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"us.anthropic.claude-3-sonnet-20240229-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"us.anthropic.claude-3-5-sonnet-20240620-v1:0\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"us.anthropic.claude-3-5-sonnet-20241022-v2:0\":
        {\n        \"supports_computer_use\": true,\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"cache_creation_input_token_cost\": 3.75e-06,\n        \"cache_read_input_token_cost\":
        3e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\":
        {\n        \"supports_computer_use\": true,\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"cache_creation_input_token_cost\": 3.75e-06,\n        \"cache_read_input_token_cost\":
        3e-07,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true\n    },\n    \"us.anthropic.claude-opus-4-1-20250805-v1:0\": {\n        \"max_tokens\":
        32000,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        32000,\n        \"input_cost_per_token\": 1.5e-05,\n        \"output_cost_per_token\":
        7.5e-05,\n        \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        0.01,\n            \"search_context_size_medium\": 0.01,\n            \"search_context_size_high\":
        0.01\n        },\n        \"cache_creation_input_token_cost\": 1.875e-05,\n
        \       \"cache_read_input_token_cost\": 1.5e-06,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"us.anthropic.claude-opus-4-20250514-v1:0\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 32000,\n        \"input_cost_per_token\": 1.5e-05,\n
        \       \"output_cost_per_token\": 7.5e-05,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.01,\n            \"search_context_size_medium\":
        0.01,\n            \"search_context_size_high\": 0.01\n        },\n        \"cache_creation_input_token_cost\":
        1.875e-05,\n        \"cache_read_input_token_cost\": 1.5e-06,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"us.anthropic.claude-sonnet-4-20250514-v1:0\":
        {\n        \"max_tokens\": 64000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 64000,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.01,\n            \"search_context_size_medium\":
        0.01,\n            \"search_context_size_high\": 0.01\n        },\n        \"cache_creation_input_token_cost\":
        3.75e-06,\n        \"cache_read_input_token_cost\": 3e-07,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"us.anthropic.claude-3-haiku-20240307-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 2.5e-07,\n
        \       \"output_cost_per_token\": 1.25e-06,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"us.anthropic.claude-3-5-haiku-20241022-v1:0\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 8e-07,\n        \"output_cost_per_token\":
        4e-06,\n        \"cache_creation_input_token_cost\": 1e-06,\n        \"cache_read_input_token_cost\":
        8e-08,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"us.anthropic.claude-3-opus-20240229-v1:0\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.5e-05,\n        \"output_cost_per_token\":
        7.5e-05,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"eu.anthropic.claude-3-sonnet-20240229-v1:0\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"eu.anthropic.claude-3-5-sonnet-20240620-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"eu.anthropic.claude-3-5-sonnet-20241022-v2:0\": {\n        \"supports_computer_use\":
        true,\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"eu.anthropic.claude-3-7-sonnet-20250219-v1:0\": {\n        \"supports_computer_use\":
        true,\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"eu.anthropic.claude-3-haiku-20240307-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 2.5e-07,\n
        \       \"output_cost_per_token\": 1.25e-06,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"eu.anthropic.claude-opus-4-1-20250805-v1:0\": {\n        \"max_tokens\":
        32000,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        32000,\n        \"input_cost_per_token\": 1.5e-05,\n        \"output_cost_per_token\":
        7.5e-05,\n        \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        0.01,\n            \"search_context_size_medium\": 0.01,\n            \"search_context_size_high\":
        0.01\n        },\n        \"cache_creation_input_token_cost\": 1.875e-05,\n
        \       \"cache_read_input_token_cost\": 1.5e-06,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"eu.anthropic.claude-opus-4-20250514-v1:0\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 32000,\n        \"input_cost_per_token\": 1.5e-05,\n
        \       \"output_cost_per_token\": 7.5e-05,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.01,\n            \"search_context_size_medium\":
        0.01,\n            \"search_context_size_high\": 0.01\n        },\n        \"cache_creation_input_token_cost\":
        1.875e-05,\n        \"cache_read_input_token_cost\": 1.5e-06,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"eu.anthropic.claude-sonnet-4-20250514-v1:0\":
        {\n        \"max_tokens\": 64000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 64000,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.01,\n            \"search_context_size_medium\":
        0.01,\n            \"search_context_size_high\": 0.01\n        },\n        \"cache_creation_input_token_cost\":
        3.75e-06,\n        \"cache_read_input_token_cost\": 3e-07,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"apac.anthropic.claude-3-haiku-20240307-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 2.5e-07,\n
        \       \"output_cost_per_token\": 1.25e-06,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"apac.anthropic.claude-3-sonnet-20240229-v1:0\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"apac.anthropic.claude-3-5-sonnet-20240620-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"apac.anthropic.claude-3-5-sonnet-20241022-v2:0\": {\n
        \       \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"cache_creation_input_token_cost\": 3.75e-06,\n        \"cache_read_input_token_cost\":
        3e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_computer_use\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"apac.anthropic.claude-sonnet-4-20250514-v1:0\": {\n        \"max_tokens\":
        64000,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        64000,\n        \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        0.01,\n            \"search_context_size_medium\": 0.01,\n            \"search_context_size_high\":
        0.01\n        },\n        \"cache_creation_input_token_cost\": 3.75e-06,\n
        \       \"cache_read_input_token_cost\": 3e-07,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"eu.anthropic.claude-3-5-haiku-20241022-v1:0\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 2.5e-07,\n
        \       \"output_cost_per_token\": 1.25e-06,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"eu.anthropic.claude-3-opus-20240229-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 1.5e-05,\n
        \       \"output_cost_per_token\": 7.5e-05,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 8e-06,\n
        \       \"output_cost_per_token\": 2.4e-05,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-east-1/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 8e-06,\n
        \       \"output_cost_per_token\": 2.4e-05,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-west-2/anthropic.claude-v1\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 100000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 8e-06,\n        \"output_cost_per_token\":
        2.4e-05,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/ap-northeast-1/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 8e-06,\n
        \       \"output_cost_per_token\": 2.4e-05,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0455,\n
        \       \"output_cost_per_second\": 0.0455,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.02527,\n
        \       \"output_cost_per_second\": 0.02527,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-central-1/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 8e-06,\n
        \       \"output_cost_per_token\": 2.4e-05,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-central-1/1-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0415,\n
        \       \"output_cost_per_second\": 0.0415,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-central-1/6-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.02305,\n
        \       \"output_cost_per_second\": 0.02305,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-east-1/1-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0175,\n
        \       \"output_cost_per_second\": 0.0175,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-east-1/6-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.00972,\n
        \       \"output_cost_per_second\": 0.00972,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-west-2/1-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0175,\n
        \       \"output_cost_per_second\": 0.0175,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-west-2/6-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.00972,\n
        \       \"output_cost_per_second\": 0.00972,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 8e-06,\n
        \       \"output_cost_per_token\": 2.4e-05,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-east-1/anthropic.claude-v2\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 100000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 8e-06,\n        \"output_cost_per_token\":
        2.4e-05,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/us-west-2/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 8e-06,\n
        \       \"output_cost_per_token\": 2.4e-05,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/ap-northeast-1/anthropic.claude-v2\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 100000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 8e-06,\n        \"output_cost_per_token\":
        2.4e-05,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0455,\n
        \       \"output_cost_per_second\": 0.0455,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.02527,\n
        \       \"output_cost_per_second\": 0.02527,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/eu-central-1/anthropic.claude-v2\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 100000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 8e-06,\n        \"output_cost_per_token\":
        2.4e-05,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0415,\n
        \       \"output_cost_per_second\": 0.0415,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.02305,\n
        \       \"output_cost_per_second\": 0.02305,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-east-1/1-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0175,\n
        \       \"output_cost_per_second\": 0.0175,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-east-1/6-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.00972,\n
        \       \"output_cost_per_second\": 0.00972,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-west-2/1-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0175,\n
        \       \"output_cost_per_second\": 0.0175,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-west-2/6-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.00972,\n
        \       \"output_cost_per_second\": 0.00972,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"anthropic.claude-v2:1\": {\n        \"max_tokens\": 8191,\n
        \       \"max_input_tokens\": 100000,\n        \"max_output_tokens\": 8191,\n
        \       \"input_cost_per_token\": 8e-06,\n        \"output_cost_per_token\":
        2.4e-05,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/us-east-1/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 8e-06,\n
        \       \"output_cost_per_token\": 2.4e-05,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-west-2/anthropic.claude-v2:1\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 100000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 8e-06,\n        \"output_cost_per_token\":
        2.4e-05,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/ap-northeast-1/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 8e-06,\n
        \       \"output_cost_per_token\": 2.4e-05,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0455,\n
        \       \"output_cost_per_second\": 0.0455,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.02527,\n
        \       \"output_cost_per_second\": 0.02527,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/eu-central-1/anthropic.claude-v2:1\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 100000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 8e-06,\n        \"output_cost_per_token\":
        2.4e-05,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0415,\n
        \       \"output_cost_per_second\": 0.0415,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.02305,\n
        \       \"output_cost_per_second\": 0.02305,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0175,\n
        \       \"output_cost_per_second\": 0.0175,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.00972,\n
        \       \"output_cost_per_second\": 0.00972,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0175,\n
        \       \"output_cost_per_second\": 0.0175,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.00972,\n
        \       \"output_cost_per_second\": 0.00972,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"anthropic.claude-instant-v1\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 100000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 8e-07,\n        \"output_cost_per_token\":
        2.4e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/us-east-1/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 8e-07,\n
        \       \"output_cost_per_token\": 2.4e-06,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.011,\n
        \       \"output_cost_per_second\": 0.011,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.00611,\n
        \       \"output_cost_per_second\": 0.00611,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.011,\n
        \       \"output_cost_per_second\": 0.011,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.00611,\n
        \       \"output_cost_per_second\": 0.00611,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-west-2/anthropic.claude-instant-v1\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 100000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 8e-07,\n        \"output_cost_per_token\":
        2.4e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/ap-northeast-1/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 2.23e-06,\n
        \       \"output_cost_per_token\": 7.55e-06,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.01475,\n
        \       \"output_cost_per_second\": 0.01475,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.008194,\n
        \       \"output_cost_per_second\": 0.008194,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/eu-central-1/anthropic.claude-instant-v1\": {\n
        \       \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 2.48e-06,\n        \"output_cost_per_token\":
        8.38e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.01635,\n
        \       \"output_cost_per_second\": 0.01635,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.009083,\n
        \       \"output_cost_per_second\": 0.009083,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"cohere.rerank-v3-5:0\": {\n        \"max_tokens\": 32000,\n
        \       \"max_input_tokens\": 32000,\n        \"max_output_tokens\": 32000,\n
        \       \"max_query_tokens\": 32000,\n        \"max_document_chunks_per_query\":
        100,\n        \"max_tokens_per_document_chunk\": 512,\n        \"input_cost_per_token\":
        0.0,\n        \"input_cost_per_query\": 0.002,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"rerank\"\n
        \   },\n    \"cohere.command-text-v14\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 4096,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 1.5e-06,\n        \"output_cost_per_token\":
        2e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/*/1-month-commitment/cohere.command-text-v14\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_second\": 0.011,\n        \"output_cost_per_second\":
        0.011,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/*/6-month-commitment/cohere.command-text-v14\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_second\": 0.0066027,\n        \"output_cost_per_second\":
        0.0066027,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"cohere.command-light-text-v14\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/*/1-month-commitment/cohere.command-light-text-v14\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_second\": 0.001902,\n        \"output_cost_per_second\":
        0.001902,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/*/6-month-commitment/cohere.command-light-text-v14\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_second\": 0.0011416,\n        \"output_cost_per_second\":
        0.0011416,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"cohere.command-r-plus-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"cohere.command-r-v1:0\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 5e-07,\n        \"output_cost_per_token\":
        1.5e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"cohere.embed-english-v3\":
        {\n        \"max_tokens\": 512,\n        \"max_input_tokens\": 512,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"embedding\",\n        \"supports_embedding_image_input\":
        true\n    },\n    \"cohere.embed-multilingual-v3\": {\n        \"max_tokens\":
        512,\n        \"max_input_tokens\": 512,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"embedding\",\n        \"supports_embedding_image_input\":
        true\n    },\n    \"us.deepseek.r1-v1:0\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 1.35e-06,\n        \"output_cost_per_token\":
        5.4e-06,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_reasoning\": true,\n        \"supports_function_calling\":
        false,\n        \"supports_tool_choice\": false\n    },\n    \"meta.llama3-3-70b-instruct-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 7.2e-07,\n
        \       \"output_cost_per_token\": 7.2e-07,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": false\n    },\n    \"meta.llama2-13b-chat-v1\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 7.5e-07,\n        \"output_cost_per_token\":
        1e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"meta.llama2-70b-chat-v1\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 4096,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 1.95e-06,\n        \"output_cost_per_token\":
        2.56e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"meta.llama3-8b-instruct-v1:0\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 8192,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/us-east-1/meta.llama3-8b-instruct-v1:0\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/us-west-1/meta.llama3-8b-instruct-v1:0\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/ap-south-1/meta.llama3-8b-instruct-v1:0\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 3.6e-07,\n        \"output_cost_per_token\":
        7.2e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/ca-central-1/meta.llama3-8b-instruct-v1:0\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 3.5e-07,\n        \"output_cost_per_token\":
        6.9e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/eu-west-1/meta.llama3-8b-instruct-v1:0\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 3.2e-07,\n        \"output_cost_per_token\":
        6.5e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/eu-west-2/meta.llama3-8b-instruct-v1:0\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 3.9e-07,\n        \"output_cost_per_token\":
        7.8e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/sa-east-1/meta.llama3-8b-instruct-v1:0\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 5e-07,\n        \"output_cost_per_token\":
        1.01e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"meta.llama3-70b-instruct-v1:0\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 2.65e-06,\n        \"output_cost_per_token\":
        3.5e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/us-east-1/meta.llama3-70b-instruct-v1:0\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 2.65e-06,\n        \"output_cost_per_token\":
        3.5e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/us-west-1/meta.llama3-70b-instruct-v1:0\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 2.65e-06,\n        \"output_cost_per_token\":
        3.5e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/ap-south-1/meta.llama3-70b-instruct-v1:0\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 3.18e-06,\n        \"output_cost_per_token\":
        4.2e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/ca-central-1/meta.llama3-70b-instruct-v1:0\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 3.05e-06,\n        \"output_cost_per_token\":
        4.03e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/eu-west-1/meta.llama3-70b-instruct-v1:0\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 2.86e-06,\n        \"output_cost_per_token\":
        3.78e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/eu-west-2/meta.llama3-70b-instruct-v1:0\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 3.45e-06,\n        \"output_cost_per_token\":
        4.55e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/sa-east-1/meta.llama3-70b-instruct-v1:0\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 4.45e-06,\n        \"output_cost_per_token\":
        5.88e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"meta.llama3-1-8b-instruct-v1:0\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        2048,\n        \"input_cost_per_token\": 2.2e-07,\n        \"output_cost_per_token\":
        2.2e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        false\n    },\n    \"us.meta.llama3-1-8b-instruct-v1:0\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        2048,\n        \"input_cost_per_token\": 2.2e-07,\n        \"output_cost_per_token\":
        2.2e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        false\n    },\n    \"meta.llama3-1-70b-instruct-v1:0\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        2048,\n        \"input_cost_per_token\": 9.9e-07,\n        \"output_cost_per_token\":
        9.9e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        false\n    },\n    \"us.meta.llama3-1-70b-instruct-v1:0\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        2048,\n        \"input_cost_per_token\": 9.9e-07,\n        \"output_cost_per_token\":
        9.9e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        false\n    },\n    \"meta.llama3-1-405b-instruct-v1:0\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 5.32e-06,\n        \"output_cost_per_token\":
        1.6e-05,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        false\n    },\n    \"us.meta.llama3-1-405b-instruct-v1:0\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 5.32e-06,\n        \"output_cost_per_token\":
        1.6e-05,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        false\n    },\n    \"meta.llama3-2-1b-instruct-v1:0\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        1e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        false\n    },\n    \"us.meta.llama3-2-1b-instruct-v1:0\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        1e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        false\n    },\n    \"eu.meta.llama3-2-1b-instruct-v1:0\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.3e-07,\n        \"output_cost_per_token\":
        1.3e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        false\n    },\n    \"meta.llama3-2-3b-instruct-v1:0\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        1.5e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        false\n    },\n    \"us.meta.llama3-2-3b-instruct-v1:0\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        1.5e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        false\n    },\n    \"eu.meta.llama3-2-3b-instruct-v1:0\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.9e-07,\n        \"output_cost_per_token\":
        1.9e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        false\n    },\n    \"meta.llama3-2-11b-instruct-v1:0\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 3.5e-07,\n        \"output_cost_per_token\":
        3.5e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        false,\n        \"supports_vision\": true\n    },\n    \"us.meta.llama3-2-11b-instruct-v1:0\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 3.5e-07,\n
        \       \"output_cost_per_token\": 3.5e-07,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": false,\n        \"supports_vision\":
        true\n    },\n    \"meta.llama3-2-90b-instruct-v1:0\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        2e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        false,\n        \"supports_vision\": true\n    },\n    \"us.meta.llama3-2-90b-instruct-v1:0\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 2e-06,\n
        \       \"output_cost_per_token\": 2e-06,\n        \"litellm_provider\": \"bedrock\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_tool_choice\": false,\n        \"supports_vision\": true\n
        \   },\n    \"us.meta.llama3-3-70b-instruct-v1:0\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 7.2e-07,\n        \"output_cost_per_token\":
        7.2e-07,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        false\n    },\n    \"meta.llama4-maverick-17b-instruct-v1:0\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 2.4e-07,\n        \"input_cost_per_token_batches\":
        1.2e-07,\n        \"output_cost_per_token\": 9.7e-07,\n        \"output_cost_per_token_batches\":
        4.85e-07,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        false,\n        \"supported_modalities\": [\n            \"text\",\n            \"image\"\n
        \       ],\n        \"supported_output_modalities\": [\n            \"text\",\n
        \           \"code\"\n        ]\n    },\n    \"us.meta.llama4-maverick-17b-instruct-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 2.4e-07,\n
        \       \"input_cost_per_token_batches\": 1.2e-07,\n        \"output_cost_per_token\":
        9.7e-07,\n        \"output_cost_per_token_batches\": 4.85e-07,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": false,\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\",\n            \"code\"\n        ]\n    },\n    \"meta.llama4-scout-17b-instruct-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 1.7e-07,\n
        \       \"input_cost_per_token_batches\": 8.5e-08,\n        \"output_cost_per_token\":
        6.6e-07,\n        \"output_cost_per_token_batches\": 3.3e-07,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": false,\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\",\n            \"code\"\n        ]\n    },\n    \"us.meta.llama4-scout-17b-instruct-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 1.7e-07,\n
        \       \"input_cost_per_token_batches\": 8.5e-08,\n        \"output_cost_per_token\":
        6.6e-07,\n        \"output_cost_per_token_batches\": 3.3e-07,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": false,\n        \"supported_modalities\":
        [\n            \"text\",\n            \"image\"\n        ],\n        \"supported_output_modalities\":
        [\n            \"text\",\n            \"code\"\n        ]\n    },\n    \"512-x-512/50-steps/stability.stable-diffusion-xl-v0\":
        {\n        \"max_tokens\": 77,\n        \"max_input_tokens\": 77,\n        \"output_cost_per_image\":
        0.018,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"512-x-512/max-steps/stability.stable-diffusion-xl-v0\": {\n
        \       \"max_tokens\": 77,\n        \"max_input_tokens\": 77,\n        \"output_cost_per_image\":
        0.036,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"max-x-max/50-steps/stability.stable-diffusion-xl-v0\": {\n        \"max_tokens\":
        77,\n        \"max_input_tokens\": 77,\n        \"output_cost_per_image\":
        0.036,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"max-x-max/max-steps/stability.stable-diffusion-xl-v0\": {\n
        \       \"max_tokens\": 77,\n        \"max_input_tokens\": 77,\n        \"output_cost_per_image\":
        0.072,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"1024-x-1024/50-steps/stability.stable-diffusion-xl-v1\": {\n
        \       \"max_tokens\": 77,\n        \"max_input_tokens\": 77,\n        \"output_cost_per_image\":
        0.04,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"1024-x-1024/max-steps/stability.stable-diffusion-xl-v1\": {\n
        \       \"max_tokens\": 77,\n        \"max_input_tokens\": 77,\n        \"output_cost_per_image\":
        0.08,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"stability.sd3-large-v1:0\": {\n        \"max_tokens\": 77,\n
        \       \"max_input_tokens\": 77,\n        \"output_cost_per_image\": 0.08,\n
        \       \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"stability.sd3-5-large-v1:0\": {\n        \"max_tokens\": 77,\n
        \       \"max_input_tokens\": 77,\n        \"output_cost_per_image\": 0.08,\n
        \       \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"stability.stable-image-core-v1:0\": {\n        \"max_tokens\":
        77,\n        \"max_input_tokens\": 77,\n        \"output_cost_per_image\":
        0.04,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"stability.stable-image-core-v1:1\": {\n        \"max_tokens\":
        77,\n        \"max_input_tokens\": 77,\n        \"output_cost_per_image\":
        0.04,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"stability.stable-image-ultra-v1:0\": {\n        \"max_tokens\":
        77,\n        \"max_input_tokens\": 77,\n        \"output_cost_per_image\":
        0.14,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"stability.stable-image-ultra-v1:1\": {\n        \"max_tokens\":
        77,\n        \"max_input_tokens\": 77,\n        \"output_cost_per_image\":
        0.14,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"sagemaker/meta-textgeneration-llama-2-7b\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"sagemaker\",\n        \"mode\": \"completion\"\n
        \   },\n    \"sagemaker/meta-textgeneration-llama-2-7b-f\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"sagemaker\",\n        \"mode\": \"chat\"\n
        \   },\n    \"sagemaker/meta-textgeneration-llama-2-13b\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"sagemaker\",\n        \"mode\": \"completion\"\n
        \   },\n    \"sagemaker/meta-textgeneration-llama-2-13b-f\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"sagemaker\",\n        \"mode\": \"chat\"\n
        \   },\n    \"sagemaker/meta-textgeneration-llama-2-70b\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"sagemaker\",\n        \"mode\": \"completion\"\n
        \   },\n    \"sagemaker/meta-textgeneration-llama-2-70b-b-f\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"sagemaker\",\n        \"mode\": \"chat\"\n
        \   },\n    \"together-ai-up-to-4b\": {\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 1e-07,\n        \"litellm_provider\":
        \"together_ai\",\n        \"mode\": \"chat\"\n    },\n    \"together-ai-4.1b-8b\":
        {\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        2e-07,\n        \"litellm_provider\": \"together_ai\",\n        \"mode\":
        \"chat\"\n    },\n    \"together-ai-8.1b-21b\": {\n        \"max_tokens\":
        1000,\n        \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        3e-07,\n        \"litellm_provider\": \"together_ai\",\n        \"mode\":
        \"chat\"\n    },\n    \"together-ai-21.1b-41b\": {\n        \"input_cost_per_token\":
        8e-07,\n        \"output_cost_per_token\": 8e-07,\n        \"litellm_provider\":
        \"together_ai\",\n        \"mode\": \"chat\"\n    },\n    \"together-ai-41.1b-80b\":
        {\n        \"input_cost_per_token\": 9e-07,\n        \"output_cost_per_token\":
        9e-07,\n        \"litellm_provider\": \"together_ai\",\n        \"mode\":
        \"chat\"\n    },\n    \"together-ai-81.1b-110b\": {\n        \"input_cost_per_token\":
        1.8e-06,\n        \"output_cost_per_token\": 1.8e-06,\n        \"litellm_provider\":
        \"together_ai\",\n        \"mode\": \"chat\"\n    },\n    \"together-ai-embedding-up-to-150m\":
        {\n        \"input_cost_per_token\": 8e-09,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"together_ai\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"together-ai-embedding-151m-to-350m\": {\n        \"input_cost_per_token\":
        1.6e-08,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"together_ai\",\n        \"mode\": \"embedding\"\n    },\n    \"together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\":
        {\n        \"input_cost_per_token\": 1.8e-07,\n        \"output_cost_per_token\":
        1.8e-07,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\":
        {\n        \"input_cost_per_token\": 8.8e-07,\n        \"output_cost_per_token\":
        8.8e-07,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\":
        {\n        \"input_cost_per_token\": 3.5e-06,\n        \"output_cost_per_token\":
        3.5e-06,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo\":
        {\n        \"input_cost_per_token\": 8.8e-07,\n        \"output_cost_per_token\":
        8.8e-07,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\":
        {\n        \"input_cost_per_token\": 0,\n        \"output_cost_per_token\":
        0,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1\": {\n        \"input_cost_per_token\":
        6e-07,\n        \"output_cost_per_token\": 6e-07,\n        \"litellm_provider\":
        \"together_ai\",\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"together_ai/mistralai/Mistral-7B-Instruct-v0.1\":
        {\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"together_ai/togethercomputer/CodeLlama-34b-Instruct\": {\n        \"litellm_provider\":
        \"together_ai\",\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"together_ai/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\":
        {\n        \"input_cost_per_token\": 2.7e-07,\n        \"output_cost_per_token\":
        8.5e-07,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"together_ai/meta-llama/Llama-4-Scout-17B-16E-Instruct\":
        {\n        \"input_cost_per_token\": 1.8e-07,\n        \"output_cost_per_token\":
        5.9e-07,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"together_ai/meta-llama/Llama-3.2-3B-Instruct-Turbo\":
        {\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"together_ai/Qwen/Qwen2.5-7B-Instruct-Turbo\":
        {\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"together_ai/Qwen/Qwen2.5-72B-Instruct-Turbo\":
        {\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"together_ai/Qwen/Qwen3-235B-A22B-Instruct-2507-tput\":
        {\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        6e-06,\n        \"max_input_tokens\": 262000,\n        \"litellm_provider\":
        \"together_ai\",\n        \"supports_function_calling\": false,\n        \"supports_parallel_function_calling\":
        false,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": false,\n
        \       \"source\": \"https://www.together.ai/models/qwen3-235b-a22b-instruct-2507-fp8\"\n
        \   },\n    \"together_ai/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8\": {\n        \"input_cost_per_token\":
        2e-06,\n        \"output_cost_per_token\": 2e-06,\n        \"max_input_tokens\":
        256000,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        false,\n        \"supports_parallel_function_calling\": false,\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": false,\n        \"source\": \"https://www.together.ai/models/qwen3-coder-480b-a35b-instruct\"\n
        \   },\n    \"together_ai/Qwen/Qwen3-235B-A22B-Thinking-2507\": {\n        \"input_cost_per_token\":
        6.5e-07,\n        \"output_cost_per_token\": 3e-06,\n        \"max_input_tokens\":
        256000,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        false,\n        \"supports_parallel_function_calling\": false,\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": false,\n        \"source\": \"https://www.together.ai/models/qwen3-235b-a22b-thinking-2507\"\n
        \   },\n    \"together_ai/Qwen/Qwen3-235B-A22B-fp8-tput\": {\n        \"input_cost_per_token\":
        2e-07,\n        \"output_cost_per_token\": 6e-07,\n        \"max_input_tokens\":
        40000,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        false,\n        \"supports_parallel_function_calling\": false,\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": false,\n        \"source\": \"https://www.together.ai/models/qwen3-235b-a22b-fp8-tput\"\n
        \   },\n    \"together_ai/deepseek-ai/DeepSeek-V3\": {\n        \"input_cost_per_token\":
        1.25e-06,\n        \"output_cost_per_token\": 1.25e-06,\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 65536,\n        \"max_output_tokens\":
        8192,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"together_ai/deepseek-ai/DeepSeek-R1\":
        {\n        \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        7e-06,\n        \"max_tokens\": 20480,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 20480,\n        \"litellm_provider\": \"together_ai\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"together_ai/deepseek-ai/DeepSeek-R1-0528-tput\": {\n        \"input_cost_per_token\":
        5.5e-07,\n        \"output_cost_per_token\": 2.19e-06,\n        \"max_input_tokens\":
        128000,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        false,\n        \"supports_parallel_function_calling\": false,\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": false,\n        \"source\": \"https://www.together.ai/models/deepseek-r1-0528-throughput\"\n
        \   },\n    \"together_ai/mistralai/Mistral-Small-24B-Instruct-2501\": {\n
        \       \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"together_ai/moonshotai/Kimi-K2-Instruct\":
        {\n        \"input_cost_per_token\": 1e-06,\n        \"output_cost_per_token\":
        3e-06,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"mode\": \"chat\",\n        \"source\": \"https://www.together.ai/models/kimi-k2-instruct\"\n
        \   },\n    \"together_ai/openai/gpt-oss-120b\": {\n        \"input_cost_per_token\":
        1.5e-07,\n        \"output_cost_per_token\": 6e-07,\n        \"max_input_tokens\":
        128000,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        false,\n        \"supports_tool_choice\": false,\n        \"supports_parallel_function_calling\":
        false,\n        \"mode\": \"chat\",\n        \"source\": \"https://www.together.ai/models/gpt-oss-120b\"\n
        \   },\n    \"together_ai/OpenAI/gpt-oss-20B\": {\n        \"input_cost_per_token\":
        5e-08,\n        \"output_cost_per_token\": 2e-07,\n        \"max_input_tokens\":
        128000,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        false,\n        \"supports_tool_choice\": false,\n        \"supports_parallel_function_calling\":
        false,\n        \"mode\": \"chat\",\n        \"source\": \"https://www.together.ai/models/gpt-oss-20b\"\n
        \   },\n    \"together_ai/zai-org/GLM-4.5-Air-FP8\": {\n        \"input_cost_per_token\":
        2e-07,\n        \"output_cost_per_token\": 1.1e-06,\n        \"max_input_tokens\":
        128000,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        false,\n        \"supports_tool_choice\": false,\n        \"supports_parallel_function_calling\":
        false,\n        \"mode\": \"chat\",\n        \"source\": \"https://www.together.ai/models/glm-4-5-air\"\n
        \   },\n    \"ollama/codegemma\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        0.0,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"ollama\",\n        \"mode\": \"completion\"\n    },\n    \"ollama/codegeex4\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"ollama\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": false\n
        \   },\n    \"ollama/deepseek-coder-v2-instruct\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"ollama/deepseek-coder-v2-base\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"completion\",\n
        \       \"supports_function_calling\": true\n    },\n    \"ollama/deepseek-coder-v2-lite-instruct\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"ollama\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true\n
        \   },\n    \"ollama/deepseek-coder-v2-lite-base\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"completion\",\n
        \       \"supports_function_calling\": true\n    },\n    \"ollama/internlm2_5-20b-chat\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"ollama\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true\n
        \   },\n    \"ollama/llama2\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        4096,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.0,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"ollama\",\n        \"mode\": \"chat\"\n    },\n    \"ollama/llama2:7b\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"chat\"\n
        \   },\n    \"ollama/llama2:13b\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        4096,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.0,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"ollama\",\n        \"mode\": \"chat\"\n    },\n    \"ollama/llama2:70b\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"chat\"\n
        \   },\n    \"ollama/llama2-uncensored\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 4096,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"completion\"\n
        \   },\n    \"ollama/llama3\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        0.0,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"ollama\",\n        \"mode\": \"chat\"\n    },\n    \"ollama/llama3:8b\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"chat\"\n
        \   },\n    \"ollama/llama3:70b\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        0.0,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"ollama\",\n        \"mode\": \"chat\"\n    },\n    \"ollama/llama3.1\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"ollama/mistral-large-instruct-2407\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 65536,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"ollama\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true\n
        \   },\n    \"ollama/mistral\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        0.0,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"ollama\",\n        \"mode\": \"completion\",\n        \"supports_function_calling\":
        true\n    },\n    \"ollama/mistral-7B-Instruct-v0.1\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"ollama/mistral-7B-Instruct-v0.2\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"ollama\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true\n
        \   },\n    \"ollama/mixtral-8x7B-Instruct-v0.1\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"ollama/mixtral-8x22B-Instruct-v0.1\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 65536,\n
        \       \"max_output_tokens\": 65536,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"ollama\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true\n
        \   },\n    \"ollama/codellama\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        4096,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.0,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"ollama\",\n        \"mode\": \"completion\"\n    },\n    \"ollama/orca-mini\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"completion\"\n
        \   },\n    \"ollama/vicuna\": {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\":
        2048,\n        \"max_output_tokens\": 2048,\n        \"input_cost_per_token\":
        0.0,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"ollama\",\n        \"mode\": \"completion\"\n    },\n    \"deepinfra/deepseek-ai/DeepSeek-V3\":
        {\n        \"max_tokens\": 163840,\n        \"max_input_tokens\": 163840,\n
        \       \"max_output_tokens\": 163840,\n        \"input_cost_per_token\":
        3.8e-07,\n        \"output_cost_per_token\": 8.9e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/Phind/Phind-CodeLlama-34B-v2\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 6e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        1.5e-08,\n        \"output_cost_per_token\": 2e-08,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/google/gemma-2-9b-it\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 3e-08,\n        \"output_cost_per_token\":
        6e-08,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": false\n    },\n    \"deepinfra/deepseek-ai/DeepSeek-R1-0528-Turbo\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 1e-06,\n
        \       \"output_cost_per_token\": 3e-06,\n        \"litellm_provider\": \"deepinfra\",\n
        \       \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n    },\n
        \   \"deepinfra/Qwen/Qwen2-7B-Instruct\": {\n        \"max_tokens\": 32768,\n
        \       \"max_input_tokens\": 32768,\n        \"max_output_tokens\": 32768,\n
        \       \"input_cost_per_token\": 5.5e-08,\n        \"output_cost_per_token\":
        5.5e-08,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/Qwen/QVQ-72B-Preview\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 32000,\n
        \       \"max_output_tokens\": 32000,\n        \"input_cost_per_token\": 2.5e-07,\n
        \       \"output_cost_per_token\": 5e-07,\n        \"litellm_provider\": \"deepinfra\",\n
        \       \"mode\": \"chat\",\n        \"supports_tool_choice\": false\n    },\n
        \   \"deepinfra/meta-llama/Llama-3.3-70B-Instruct\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 2.3e-07,\n        \"output_cost_per_token\":
        4e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/microsoft/Phi-4-multimodal-instruct\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        5e-08,\n        \"output_cost_per_token\": 1e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        false\n    },\n    \"deepinfra/mistralai/Devstral-Small-2507\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 7e-08,\n        \"output_cost_per_token\":
        2.8e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/microsoft/WizardLM-2-7B\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 5.5e-08,\n
        \       \"output_cost_per_token\": 5.5e-08,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        false\n    },\n    \"deepinfra/meta-llama/Llama-3.2-90B-Vision-Instruct\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 3.5e-07,\n
        \       \"output_cost_per_token\": 4e-07,\n        \"litellm_provider\": \"deepinfra\",\n
        \       \"mode\": \"chat\",\n        \"supports_tool_choice\": false\n    },\n
        \   \"deepinfra/mistralai/Mistral-Small-3.2-24B-Instruct-2506\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 5e-08,\n        \"output_cost_per_token\":
        1e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/deepseek-ai/DeepSeek-V3-0324\":
        {\n        \"max_tokens\": 163840,\n        \"max_input_tokens\": 163840,\n
        \       \"max_output_tokens\": 163840,\n        \"input_cost_per_token\":
        2.8e-07,\n        \"output_cost_per_token\": 8.8e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1\": {\n
        \       \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 8e-08,\n        \"output_cost_per_token\":
        2.4e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/anthropic/claude-3-7-sonnet-latest\":
        {\n        \"max_tokens\": 200000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 200000,\n        \"input_cost_per_token\":
        3.3e-06,\n        \"output_cost_per_token\": 1.65e-05,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/cognitivecomputations/dolphin-2.9.1-llama-3-70b\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 3.5e-07,\n        \"output_cost_per_token\":
        4e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": false\n    },\n    \"deepinfra/Qwen/Qwen2.5-Coder-32B-Instruct\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 6e-08,\n
        \       \"output_cost_per_token\": 1.5e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        false\n    },\n    \"deepinfra/Qwen/Qwen3-235B-A22B\": {\n        \"max_tokens\":
        40960,\n        \"max_input_tokens\": 40960,\n        \"max_output_tokens\":
        40960,\n        \"input_cost_per_token\": 1.3e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/deepseek-ai/DeepSeek-V3-0324-Turbo\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 1e-06,\n
        \       \"output_cost_per_token\": 3e-06,\n        \"litellm_provider\": \"deepinfra\",\n
        \       \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n    },\n
        \   \"deepinfra/microsoft/WizardLM-2-8x22B\": {\n        \"max_tokens\": 65536,\n
        \       \"max_input_tokens\": 65536,\n        \"max_output_tokens\": 65536,\n
        \       \"input_cost_per_token\": 4.8e-07,\n        \"output_cost_per_token\":
        4.8e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": false\n    },\n    \"deepinfra/Sao10K/L3-8B-Lunaris-v1-Turbo\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 2e-08,\n        \"output_cost_per_token\":
        5e-08,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": false\n    },\n    \"deepinfra/meta-llama/Llama-Guard-4-12B\":
        {\n        \"max_tokens\": 163840,\n        \"max_input_tokens\": 163840,\n
        \       \"max_output_tokens\": 163840,\n        \"input_cost_per_token\":
        1.8e-07,\n        \"output_cost_per_token\": 1.8e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        false\n    },\n    \"deepinfra/Gryphe/MythoMax-L2-13b\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 7.2e-08,\n        \"output_cost_per_token\":
        7.2e-08,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/meta-llama/Llama-3.2-1B-Instruct\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        5e-09,\n        \"output_cost_per_token\": 1e-08,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/google/gemma-2-27b-it\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 2.7e-07,\n        \"output_cost_per_token\":
        2.7e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": false\n    },\n    \"deepinfra/Qwen/Qwen2.5-VL-32B-Instruct\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        2e-07,\n        \"output_cost_per_token\": 6e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/nvidia/Llama-3.1-Nemotron-70B-Instruct\": {\n
        \       \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 1.2e-07,\n        \"output_cost_per_token\":
        3e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/mistralai/Mixtral-8x22B-Instruct-v0.1\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 65536,\n
        \       \"max_output_tokens\": 65536,\n        \"input_cost_per_token\": 6.5e-07,\n
        \       \"output_cost_per_token\": 6.5e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/Qwen/Qwen2.5-7B-Instruct\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 4e-08,\n        \"output_cost_per_token\":
        1e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": false\n    },\n    \"deepinfra/google/gemini-1.5-flash-8b\":
        {\n        \"max_tokens\": 1000000,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 1000000,\n        \"input_cost_per_token\":
        3.75e-08,\n        \"output_cost_per_token\": 1.5e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/NousResearch/Hermes-3-Llama-3.1-70B\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        2.8e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/deepseek-ai/DeepSeek-R1-Distill-Llama-70B\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 4e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        false\n    },\n    \"deepinfra/meta-llama/Llama-Guard-3-8B\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 5.5e-08,\n        \"output_cost_per_token\":
        5.5e-08,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": false\n    },\n    \"deepinfra/mistralai/Mistral-Small-24B-Instruct-2501\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 5e-08,\n
        \       \"output_cost_per_token\": 8e-08,\n        \"litellm_provider\": \"deepinfra\",\n
        \       \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n    },\n
        \   \"deepinfra/lizpreciatior/lzlv_70b_fp16_hf\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 3.5e-07,\n        \"output_cost_per_token\":
        4e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": false\n    },\n    \"deepinfra/meta-llama/Llama-2-13b-chat-hf\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.3e-07,\n        \"output_cost_per_token\":
        1.3e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/anthropic/claude-4-opus\":
        {\n        \"max_tokens\": 200000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 200000,\n        \"input_cost_per_token\":
        1.65e-05,\n        \"output_cost_per_token\": 8.25e-05,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/openchat/openchat-3.6-8b\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 5.5e-08,\n        \"output_cost_per_token\":
        5.5e-08,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": false\n    },\n    \"deepinfra/google/gemma-3-27b-it\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        9e-08,\n        \"output_cost_per_token\": 1.7e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/Austism/chronos-hermes-13b-v2\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.3e-07,\n        \"output_cost_per_token\":
        1.3e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/Sao10K/L3.1-70B-Euryale-v2.2\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        6.5e-07,\n        \"output_cost_per_token\": 7.5e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        false\n    },\n    \"deepinfra/Qwen/QwQ-32B-Preview\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 1.2e-07,\n        \"output_cost_per_token\":
        1.8e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": false\n    },\n    \"deepinfra/anthropic/claude-4-sonnet\":
        {\n        \"max_tokens\": 200000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 200000,\n        \"input_cost_per_token\":
        3.3e-06,\n        \"output_cost_per_token\": 1.65e-05,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/microsoft/Phi-3-medium-4k-instruct\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.4e-07,\n        \"output_cost_per_token\":
        1.4e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": false\n    },\n    \"deepinfra/mattshumer/Reflection-Llama-3.1-70B\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 3.5e-07,\n        \"output_cost_per_token\":
        4e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": false\n    },\n    \"deepinfra/openchat/openchat_3.5\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 5.5e-08,\n        \"output_cost_per_token\":
        5.5e-08,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/Sao10K/L3.3-70B-Euryale-v2.3\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        6.5e-07,\n        \"output_cost_per_token\": 7.5e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        false\n    },\n    \"deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct\": {\n
        \       \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 2.3e-07,\n        \"output_cost_per_token\":
        4e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/deepseek-ai/DeepSeek-V3.1\":
        {\n        \"max_tokens\": 163840,\n        \"max_input_tokens\": 163840,\n
        \       \"max_output_tokens\": 163840,\n        \"input_cost_per_token\":
        3.2e-07,\n        \"output_cost_per_token\": 1.15e-06,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        false\n    },\n    \"deepinfra/Qwen/Qwen2.5-Coder-7B\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 2.5e-08,\n        \"output_cost_per_token\":
        5e-08,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": false\n    },\n    \"deepinfra/cognitivecomputations/dolphin-2.6-mixtral-8x7b\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 2.4e-07,\n
        \       \"output_cost_per_token\": 2.4e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/meta-llama/Meta-Llama-3.1-405B-Instruct\": {\n
        \       \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 8e-07,\n        \"output_cost_per_token\":
        8e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/deepseek-ai/DeepSeek-Prover-V2-671B\":
        {\n        \"max_tokens\": 163840,\n        \"max_input_tokens\": 163840,\n
        \       \"max_output_tokens\": 163840,\n        \"input_cost_per_token\":
        5e-07,\n        \"output_cost_per_token\": 2.18e-06,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        false\n    },\n    \"deepinfra/zai-org/GLM-4.5\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 5.5e-07,\n        \"output_cost_per_token\":
        2e-06,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/meta-llama/Llama-3.2-3B-Instruct\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        1.2e-08,\n        \"output_cost_per_token\": 2.4e-08,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/meta-llama/Meta-Llama-3-70B-Instruct\": {\n
        \       \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        4e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/google/gemini-1.5-flash\":
        {\n        \"max_tokens\": 1000000,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 1000000,\n        \"input_cost_per_token\":
        7.5e-08,\n        \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/KoboldAI/LLaMA2-13B-Tiefighter\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        1e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/google/gemini-2.5-pro\":
        {\n        \"max_tokens\": 1000000,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 1000000,\n        \"input_cost_per_token\":
        8.75e-07,\n        \"output_cost_per_token\": 7e-06,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/Qwen/Qwen3-30B-A3B\": {\n        \"max_tokens\":
        40960,\n        \"max_input_tokens\": 40960,\n        \"max_output_tokens\":
        40960,\n        \"input_cost_per_token\": 8e-08,\n        \"output_cost_per_token\":
        2.9e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/Qwen/QwQ-32B\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        7.5e-08,\n        \"output_cost_per_token\": 1.5e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/moonshotai/Kimi-K2-Instruct\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 5e-07,\n        \"output_cost_per_token\":
        2e-06,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/Sao10K/L3-70B-Euryale-v2.1\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 7e-07,\n        \"output_cost_per_token\":
        8e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": false\n    },\n    \"deepinfra/microsoft/phi-4-reasoning-plus\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 7e-08,\n
        \       \"output_cost_per_token\": 3.5e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        false\n    },\n    \"deepinfra/google/gemma-3-12b-it\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 5e-08,\n        \"output_cost_per_token\":
        1e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/google/gemini-2.5-flash\":
        {\n        \"max_tokens\": 1000000,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 1000000,\n        \"input_cost_per_token\":
        2.1e-07,\n        \"output_cost_per_token\": 1.75e-06,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/deepseek-ai/DeepSeek-R1\": {\n        \"max_tokens\":
        163840,\n        \"max_input_tokens\": 163840,\n        \"max_output_tokens\":
        163840,\n        \"input_cost_per_token\": 4.5e-07,\n        \"output_cost_per_token\":
        2.15e-06,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/mistralai/Mistral-7B-Instruct-v0.3\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 2.8e-08,\n
        \       \"output_cost_per_token\": 5.4e-08,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/Qwen/Qwen2.5-72B-Instruct\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 1.2e-07,\n        \"output_cost_per_token\":
        3.9e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/Qwen/Qwen3-14B\":
        {\n        \"max_tokens\": 40960,\n        \"max_input_tokens\": 40960,\n
        \       \"max_output_tokens\": 40960,\n        \"input_cost_per_token\": 6e-08,\n
        \       \"output_cost_per_token\": 2.4e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/allenai/olmOCR-7B-0725-FP8\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 2.7e-07,\n        \"output_cost_per_token\":
        1.5e-06,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": false\n    },\n    \"deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct\":
        {\n        \"max_tokens\": 262144,\n        \"max_input_tokens\": 262144,\n
        \       \"max_output_tokens\": 262144,\n        \"input_cost_per_token\":
        4e-07,\n        \"output_cost_per_token\": 1.6e-06,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/microsoft/phi-4\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 7e-08,\n        \"output_cost_per_token\":
        1.4e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/NousResearch/Hermes-3-Llama-3.1-405B\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        7e-07,\n        \"output_cost_per_token\": 8e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/zai-org/GLM-4.5-Air\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        1.1e-06,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        7.5e-08,\n        \"output_cost_per_token\": 1.5e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/openai/gpt-oss-120b\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 9e-08,\n        \"output_cost_per_token\":
        4.5e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/google/codegemma-7b-it\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 7e-08,\n        \"output_cost_per_token\":
        7e-08,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": false\n    },\n    \"deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo\":
        {\n        \"max_tokens\": 262144,\n        \"max_input_tokens\": 262144,\n
        \       \"max_output_tokens\": 262144,\n        \"input_cost_per_token\":
        3e-07,\n        \"output_cost_per_token\": 1.2e-06,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/mistralai/Mistral-Nemo-Instruct-2407\": {\n
        \       \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 2e-08,\n        \"output_cost_per_token\":
        4e-08,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/openbmb/MiniCPM-Llama3-V-2_5\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 3.4e-07,\n        \"output_cost_per_token\":
        3.4e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": false\n    },\n    \"deepinfra/bigcode/starcoder2-15b-instruct-v0.1\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        1.5e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": false\n    },\n    \"deepinfra/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\":
        {\n        \"max_tokens\": 1048576,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 1048576,\n        \"input_cost_per_token\":
        1.5e-07,\n        \"output_cost_per_token\": 6e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/meta-llama/Llama-4-Scout-17B-16E-Instruct\":
        {\n        \"max_tokens\": 327680,\n        \"max_input_tokens\": 327680,\n
        \       \"max_output_tokens\": 327680,\n        \"input_cost_per_token\":
        8e-08,\n        \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/google/gemini-2.0-flash-001\": {\n        \"max_tokens\":
        1000000,\n        \"max_input_tokens\": 1000000,\n        \"max_output_tokens\":
        1000000,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        4e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/Gryphe/MythoMax-L2-13b-turbo\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.3e-07,\n        \"output_cost_per_token\":
        1.3e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": false\n    },\n    \"deepinfra/google/gemma-1.1-7b-it\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 7e-08,\n        \"output_cost_per_token\":
        7e-08,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 2.8e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct\": {\n
        \       \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 3e-08,\n        \"output_cost_per_token\":
        5e-08,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/Qwen/Qwen3-32B\":
        {\n        \"max_tokens\": 40960,\n        \"max_input_tokens\": 40960,\n
        \       \"max_output_tokens\": 40960,\n        \"input_cost_per_token\": 1e-07,\n
        \       \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\": \"deepinfra\",\n
        \       \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n    },\n
        \   \"deepinfra/Qwen/Qwen3-235B-A22B-Thinking-2507\": {\n        \"max_tokens\":
        262144,\n        \"max_input_tokens\": 262144,\n        \"max_output_tokens\":
        262144,\n        \"input_cost_per_token\": 1.3e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/meta-llama/Llama-2-70b-chat-hf\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 6.4e-07,\n        \"output_cost_per_token\":
        8e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/nvidia/Nemotron-4-340B-Instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 4.2e-06,\n        \"output_cost_per_token\":
        4.2e-06,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/deepseek-ai/DeepSeek-R1-0528\":
        {\n        \"max_tokens\": 163840,\n        \"max_input_tokens\": 163840,\n
        \       \"max_output_tokens\": 163840,\n        \"input_cost_per_token\":
        5e-07,\n        \"output_cost_per_token\": 2.15e-06,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/deepseek-ai/DeepSeek-R1-Turbo\": {\n        \"max_tokens\":
        163840,\n        \"max_input_tokens\": 163840,\n        \"max_output_tokens\":
        163840,\n        \"input_cost_per_token\": 1e-06,\n        \"output_cost_per_token\":
        3e-06,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/NovaSky-AI/Sky-T1-32B-Preview\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 1.2e-07,\n
        \       \"output_cost_per_token\": 1.8e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        false\n    },\n    \"deepinfra/Qwen/Qwen3-235B-A22B-Instruct-2507\": {\n        \"max_tokens\":
        262144,\n        \"max_input_tokens\": 262144,\n        \"max_output_tokens\":
        262144,\n        \"input_cost_per_token\": 1.3e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/mistralai/Mistral-Small-3.1-24B-Instruct-2503\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        5e-08,\n        \"output_cost_per_token\": 1e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        false\n    },\n    \"deepinfra/mistralai/Mistral-7B-Instruct-v0.1\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 5.5e-08,\n        \"output_cost_per_token\":
        5.5e-08,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/Qwen/Qwen2-72B-Instruct\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 3.5e-07,\n
        \       \"output_cost_per_token\": 4e-07,\n        \"litellm_provider\": \"deepinfra\",\n
        \       \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n    },\n
        \   \"deepinfra/meta-llama/Llama-4-Maverick-17B-128E-Instruct-Turbo\": {\n
        \       \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 5e-07,\n        \"output_cost_per_token\":
        5e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": false\n    },\n    \"deepinfra/Sao10K/L3-8B-Lunaris-v1\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 3e-08,\n        \"output_cost_per_token\":
        6e-08,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": false\n    },\n    \"deepinfra/deepinfra/airoboros-70b\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 7e-07,\n        \"output_cost_per_token\":
        9e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/google/gemma-3-4b-it\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        2e-08,\n        \"output_cost_per_token\": 4e-08,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/meta-llama/Meta-Llama-3-8B-Instruct\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 3e-08,\n        \"output_cost_per_token\":
        6e-08,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"deepinfra/mistralai/Mistral-7B-Instruct-v0.2\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 5.5e-08,\n
        \       \"output_cost_per_token\": 5.5e-08,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        false\n    },\n    \"deepinfra/meta-llama/Llama-3.3-70B-Instruct-Turbo\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        3.8e-08,\n        \"output_cost_per_token\": 1.2e-07,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/mistralai/Devstral-Small-2505\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 6e-08,\n        \"output_cost_per_token\":
        1.2e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/meta-llama/Llama-3.2-11B-Vision-Instruct\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        4.9e-08,\n        \"output_cost_per_token\": 4.9e-08,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        false\n    },\n    \"deepinfra/openai/gpt-oss-20b\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 4e-08,\n        \"output_cost_per_token\":
        1.6e-07,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"perplexity/codellama-34b-instruct\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 3.5e-07,\n
        \       \"output_cost_per_token\": 1.4e-06,\n        \"litellm_provider\":
        \"perplexity\",\n        \"mode\": \"chat\"\n    },\n    \"perplexity/codellama-70b-instruct\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 7e-07,\n
        \       \"output_cost_per_token\": 2.8e-06,\n        \"litellm_provider\":
        \"perplexity\",\n        \"mode\": \"chat\"\n    },\n    \"perplexity/llama-3.1-70b-instruct\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        1e-06,\n        \"output_cost_per_token\": 1e-06,\n        \"litellm_provider\":
        \"perplexity\",\n        \"mode\": \"chat\"\n    },\n    \"perplexity/llama-3.1-8b-instruct\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        2e-07,\n        \"output_cost_per_token\": 2e-07,\n        \"litellm_provider\":
        \"perplexity\",\n        \"mode\": \"chat\"\n    },\n    \"perplexity/llama-3.1-sonar-huge-128k-online\":
        {\n        \"max_tokens\": 127072,\n        \"max_input_tokens\": 127072,\n
        \       \"max_output_tokens\": 127072,\n        \"input_cost_per_token\":
        5e-06,\n        \"output_cost_per_token\": 5e-06,\n        \"litellm_provider\":
        \"perplexity\",\n        \"mode\": \"chat\",\n        \"deprecation_date\":
        \"2025-02-22\"\n    },\n    \"perplexity/llama-3.1-sonar-large-128k-online\":
        {\n        \"max_tokens\": 127072,\n        \"max_input_tokens\": 127072,\n
        \       \"max_output_tokens\": 127072,\n        \"input_cost_per_token\":
        1e-06,\n        \"output_cost_per_token\": 1e-06,\n        \"litellm_provider\":
        \"perplexity\",\n        \"mode\": \"chat\",\n        \"deprecation_date\":
        \"2025-02-22\"\n    },\n    \"perplexity/llama-3.1-sonar-large-128k-chat\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        1e-06,\n        \"output_cost_per_token\": 1e-06,\n        \"litellm_provider\":
        \"perplexity\",\n        \"mode\": \"chat\",\n        \"deprecation_date\":
        \"2025-02-22\"\n    },\n    \"perplexity/llama-3.1-sonar-small-128k-chat\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        2e-07,\n        \"output_cost_per_token\": 2e-07,\n        \"litellm_provider\":
        \"perplexity\",\n        \"mode\": \"chat\",\n        \"deprecation_date\":
        \"2025-02-22\"\n    },\n    \"perplexity/llama-3.1-sonar-small-128k-online\":
        {\n        \"max_tokens\": 127072,\n        \"max_input_tokens\": 127072,\n
        \       \"max_output_tokens\": 127072,\n        \"input_cost_per_token\":
        2e-07,\n        \"output_cost_per_token\": 2e-07,\n        \"litellm_provider\":
        \"perplexity\",\n        \"mode\": \"chat\",\n        \"deprecation_date\":
        \"2025-02-22\"\n    },\n    \"perplexity/pplx-7b-chat\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 7e-08,\n        \"output_cost_per_token\":
        2.8e-07,\n        \"litellm_provider\": \"perplexity\",\n        \"mode\":
        \"chat\"\n    },\n    \"perplexity/pplx-70b-chat\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 7e-07,\n        \"output_cost_per_token\":
        2.8e-06,\n        \"litellm_provider\": \"perplexity\",\n        \"mode\":
        \"chat\"\n    },\n    \"perplexity/pplx-7b-online\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        2.8e-07,\n        \"input_cost_per_request\": 0.005,\n        \"litellm_provider\":
        \"perplexity\",\n        \"mode\": \"chat\"\n    },\n    \"perplexity/pplx-70b-online\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        2.8e-06,\n        \"input_cost_per_request\": 0.005,\n        \"litellm_provider\":
        \"perplexity\",\n        \"mode\": \"chat\"\n    },\n    \"perplexity/llama-2-70b-chat\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 7e-07,\n        \"output_cost_per_token\":
        2.8e-06,\n        \"litellm_provider\": \"perplexity\",\n        \"mode\":
        \"chat\"\n    },\n    \"perplexity/mistral-7b-instruct\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 7e-08,\n        \"output_cost_per_token\":
        2.8e-07,\n        \"litellm_provider\": \"perplexity\",\n        \"mode\":
        \"chat\"\n    },\n    \"perplexity/mixtral-8x7b-instruct\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 7e-08,\n        \"output_cost_per_token\":
        2.8e-07,\n        \"litellm_provider\": \"perplexity\",\n        \"mode\":
        \"chat\"\n    },\n    \"perplexity/sonar-small-chat\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 7e-08,\n        \"output_cost_per_token\":
        2.8e-07,\n        \"litellm_provider\": \"perplexity\",\n        \"mode\":
        \"chat\"\n    },\n    \"perplexity/sonar-small-online\": {\n        \"max_tokens\":
        12000,\n        \"max_input_tokens\": 12000,\n        \"max_output_tokens\":
        12000,\n        \"input_cost_per_token\": 0,\n        \"output_cost_per_token\":
        2.8e-07,\n        \"input_cost_per_request\": 0.005,\n        \"litellm_provider\":
        \"perplexity\",\n        \"mode\": \"chat\"\n    },\n    \"perplexity/sonar-medium-chat\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 6e-07,\n
        \       \"output_cost_per_token\": 1.8e-06,\n        \"litellm_provider\":
        \"perplexity\",\n        \"mode\": \"chat\"\n    },\n    \"perplexity/sonar-medium-online\":
        {\n        \"max_tokens\": 12000,\n        \"max_input_tokens\": 12000,\n
        \       \"max_output_tokens\": 12000,\n        \"input_cost_per_token\": 0,\n
        \       \"output_cost_per_token\": 1.8e-06,\n        \"input_cost_per_request\":
        0.005,\n        \"litellm_provider\": \"perplexity\",\n        \"mode\": \"chat\"\n
        \   },\n    \"perplexity/sonar\": {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\":
        128000,\n        \"input_cost_per_token\": 1e-06,\n        \"output_cost_per_token\":
        1e-06,\n        \"litellm_provider\": \"perplexity\",\n        \"mode\": \"chat\",\n
        \       \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        0.005,\n            \"search_context_size_medium\": 0.008,\n            \"search_context_size_high\":
        0.012\n        },\n        \"supports_web_search\": true\n    },\n    \"perplexity/sonar-pro\":
        {\n        \"max_tokens\": 8000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8000,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"perplexity\",\n        \"mode\": \"chat\",\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.006,\n            \"search_context_size_medium\":
        0.01,\n            \"search_context_size_high\": 0.014\n        },\n        \"supports_web_search\":
        true\n    },\n    \"perplexity/sonar-reasoning\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"input_cost_per_token\":
        1e-06,\n        \"output_cost_per_token\": 5e-06,\n        \"litellm_provider\":
        \"perplexity\",\n        \"mode\": \"chat\",\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.005,\n            \"search_context_size_medium\":
        0.008,\n            \"search_context_size_high\": 0.014\n        },\n        \"supports_web_search\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"perplexity/sonar-reasoning-pro\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        8e-06,\n        \"litellm_provider\": \"perplexity\",\n        \"mode\": \"chat\",\n
        \       \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        0.006,\n            \"search_context_size_medium\": 0.01,\n            \"search_context_size_high\":
        0.014\n        },\n        \"supports_web_search\": true,\n        \"supports_reasoning\":
        true\n    },\n    \"perplexity/sonar-deep-research\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"input_cost_per_token\":
        2e-06,\n        \"output_cost_per_token\": 8e-06,\n        \"output_cost_per_reasoning_token\":
        3e-06,\n        \"citation_cost_per_token\": 2e-06,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.005,\n            \"search_context_size_medium\":
        0.005,\n            \"search_context_size_high\": 0.005\n        },\n        \"litellm_provider\":
        \"perplexity\",\n        \"mode\": \"chat\",\n        \"supports_reasoning\":
        true,\n        \"supports_web_search\": true\n    },\n    \"fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 1e-07,\n
        \       \"output_cost_per_token\": 1e-07,\n        \"litellm_provider\": \"fireworks_ai\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": false,\n
        \       \"supports_response_schema\": true,\n        \"source\": \"https://fireworks.ai/pricing\",\n
        \       \"supports_tool_choice\": false\n    },\n    \"fireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 1e-07,\n
        \       \"output_cost_per_token\": 1e-07,\n        \"litellm_provider\": \"fireworks_ai\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": false,\n
        \       \"supports_response_schema\": true,\n        \"source\": \"https://fireworks.ai/pricing\",\n
        \       \"supports_tool_choice\": false\n    },\n    \"fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 1e-07,\n
        \       \"output_cost_per_token\": 1e-07,\n        \"litellm_provider\": \"fireworks_ai\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": false,\n
        \       \"supports_response_schema\": true,\n        \"source\": \"https://fireworks.ai/pricing\",\n
        \       \"supports_tool_choice\": false\n    },\n    \"fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 2e-07,\n
        \       \"output_cost_per_token\": 2e-07,\n        \"litellm_provider\": \"fireworks_ai\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": false,\n
        \       \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://fireworks.ai/pricing\",\n        \"supports_tool_choice\":
        false\n    },\n    \"fireworks_ai/accounts/fireworks/models/llama-v3p2-90b-vision-instruct\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 9e-07,\n
        \       \"output_cost_per_token\": 9e-07,\n        \"litellm_provider\": \"fireworks_ai\",\n
        \       \"mode\": \"chat\",\n        \"supports_tool_choice\": false,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://fireworks.ai/pricing\"\n
        \   },\n    \"fireworks_ai/accounts/fireworks/models/firefunction-v2\": {\n
        \       \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 9e-07,\n        \"output_cost_per_token\":
        9e-07,\n        \"litellm_provider\": \"fireworks_ai\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://fireworks.ai/pricing\",\n        \"supports_tool_choice\":
        true\n    },\n    \"fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 65536,\n
        \       \"max_output_tokens\": 65536,\n        \"input_cost_per_token\": 1.2e-06,\n
        \       \"output_cost_per_token\": 1.2e-06,\n        \"litellm_provider\":
        \"fireworks_ai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://fireworks.ai/pricing\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 9e-07,\n
        \       \"output_cost_per_token\": 9e-07,\n        \"litellm_provider\": \"fireworks_ai\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": false,\n
        \       \"supports_response_schema\": true,\n        \"source\": \"https://fireworks.ai/pricing\",\n
        \       \"supports_tool_choice\": false\n    },\n    \"fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 9e-07,\n        \"output_cost_per_token\":
        9e-07,\n        \"litellm_provider\": \"fireworks_ai\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": false,\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://fireworks.ai/pricing\",\n        \"supports_tool_choice\":
        false\n    },\n    \"fireworks_ai/accounts/fireworks/models/yi-large\": {\n
        \       \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        3e-06,\n        \"litellm_provider\": \"fireworks_ai\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": false,\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://fireworks.ai/pricing\",\n        \"supports_tool_choice\":
        false\n    },\n    \"fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 65536,\n
        \       \"max_output_tokens\": 65536,\n        \"input_cost_per_token\": 1.2e-06,\n
        \       \"output_cost_per_token\": 1.2e-06,\n        \"litellm_provider\":
        \"fireworks_ai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        false,\n        \"supports_response_schema\": true,\n        \"source\": \"https://fireworks.ai/pricing\",\n
        \       \"supports_tool_choice\": false\n    },\n    \"fireworks_ai/accounts/fireworks/models/deepseek-v3\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 9e-07,\n
        \       \"output_cost_per_token\": 9e-07,\n        \"litellm_provider\": \"fireworks_ai\",\n
        \       \"mode\": \"chat\",\n        \"supports_response_schema\": true,\n
        \       \"source\": \"https://fireworks.ai/pricing\",\n        \"supports_tool_choice\":
        false\n    },\n    \"fireworks_ai/accounts/fireworks/models/deepseek-v3-0324\":
        {\n        \"max_tokens\": 163840,\n        \"max_input_tokens\": 163840,\n
        \       \"max_output_tokens\": 163840,\n        \"input_cost_per_token\":
        9e-07,\n        \"output_cost_per_token\": 9e-07,\n        \"litellm_provider\":
        \"fireworks_ai\",\n        \"mode\": \"chat\",\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://fireworks.ai/models/fireworks/deepseek-v3-0324\",\n
        \       \"supports_tool_choice\": false\n    },\n    \"fireworks_ai/accounts/fireworks/models/deepseek-r1\":
        {\n        \"max_tokens\": 20480,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 20480,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 8e-06,\n        \"litellm_provider\": \"fireworks_ai\",\n
        \       \"mode\": \"chat\",\n        \"supports_response_schema\": true,\n
        \       \"source\": \"https://fireworks.ai/pricing\",\n        \"supports_tool_choice\":
        false\n    },\n    \"fireworks_ai/accounts/fireworks/models/deepseek-r1-basic\":
        {\n        \"max_tokens\": 20480,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 20480,\n        \"input_cost_per_token\": 5.5e-07,\n
        \       \"output_cost_per_token\": 2.19e-06,\n        \"litellm_provider\":
        \"fireworks_ai\",\n        \"mode\": \"chat\",\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://fireworks.ai/pricing\",\n        \"supports_tool_choice\":
        false\n    },\n    \"fireworks_ai/accounts/fireworks/models/deepseek-r1-0528\":
        {\n        \"max_tokens\": 160000,\n        \"max_input_tokens\": 160000,\n
        \       \"max_output_tokens\": 160000,\n        \"input_cost_per_token\":
        3e-06,\n        \"output_cost_per_token\": 8e-06,\n        \"litellm_provider\":
        \"fireworks_ai\",\n        \"mode\": \"chat\",\n        \"source\": \"https://fireworks.ai/pricing\",\n
        \       \"supports_tool_choice\": false,\n        \"supports_response_schema\":
        true\n    },\n    \"fireworks_ai/accounts/fireworks/models/kimi-k2-instruct\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 6e-07,\n
        \       \"output_cost_per_token\": 2.5e-06,\n        \"litellm_provider\":
        \"fireworks_ai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true,\n        \"source\": \"https://fireworks.ai/models/fireworks/kimi-k2-instruct\"\n
        \   },\n    \"fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 3e-06,\n
        \       \"output_cost_per_token\": 3e-06,\n        \"litellm_provider\": \"fireworks_ai\",\n
        \       \"mode\": \"chat\",\n        \"supports_response_schema\": true,\n
        \       \"source\": \"https://fireworks.ai/pricing\",\n        \"supports_tool_choice\":
        true,\n        \"supports_function_calling\": true\n    },\n    \"fireworks_ai/accounts/fireworks/models/llama4-maverick-instruct-basic\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        2.2e-07,\n        \"output_cost_per_token\": 8.8e-07,\n        \"litellm_provider\":
        \"fireworks_ai\",\n        \"mode\": \"chat\",\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://fireworks.ai/pricing\",\n        \"supports_tool_choice\":
        false\n    },\n    \"fireworks_ai/accounts/fireworks/models/llama4-scout-instruct-basic\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        1.5e-07,\n        \"output_cost_per_token\": 6e-07,\n        \"litellm_provider\":
        \"fireworks_ai\",\n        \"mode\": \"chat\",\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://fireworks.ai/pricing\",\n        \"supports_tool_choice\":
        false\n    },\n    \"fireworks_ai/accounts/fireworks/models/glm-4p5\": {\n
        \       \"max_tokens\": 96000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        96000,\n        \"input_cost_per_token\": 5.5e-07,\n        \"output_cost_per_token\":
        2.19e-06,\n        \"litellm_provider\": \"fireworks_ai\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"source\": \"https://fireworks.ai/models/fireworks/glm-4p5\"\n
        \   },\n    \"fireworks_ai/accounts/fireworks/models/glm-4p5-air\": {\n        \"max_tokens\":
        96000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        96000,\n        \"input_cost_per_token\": 2.2e-07,\n        \"output_cost_per_token\":
        8.8e-07,\n        \"litellm_provider\": \"fireworks_ai\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"source\": \"https://artificialanalysis.ai/models/glm-4-5-air\"\n
        \   },\n    \"fireworks_ai/accounts/fireworks/models/gpt-oss-120b\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"litellm_provider\": \"fireworks_ai\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"source\": \"https://fireworks.ai/pricing\"\n
        \   },\n    \"fireworks_ai/accounts/fireworks/models/gpt-oss-20b\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 5e-08,\n        \"output_cost_per_token\":
        2e-07,\n        \"litellm_provider\": \"fireworks_ai\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"source\": \"https://fireworks.ai/pricing\"\n
        \   },\n    \"fireworks_ai/nomic-ai/nomic-embed-text-v1.5\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"input_cost_per_token\":
        8e-09,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"fireworks_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://fireworks.ai/pricing\"\n    },\n    \"fireworks_ai/nomic-ai/nomic-embed-text-v1\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"input_cost_per_token\":
        8e-09,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"fireworks_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://fireworks.ai/pricing\"\n    },\n    \"fireworks_ai/WhereIsAI/UAE-Large-V1\":
        {\n        \"max_tokens\": 512,\n        \"max_input_tokens\": 512,\n        \"input_cost_per_token\":
        1.6e-08,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"fireworks_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://fireworks.ai/pricing\"\n    },\n    \"fireworks_ai/thenlper/gte-large\":
        {\n        \"max_tokens\": 512,\n        \"max_input_tokens\": 512,\n        \"input_cost_per_token\":
        1.6e-08,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"fireworks_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://fireworks.ai/pricing\"\n    },\n    \"fireworks_ai/thenlper/gte-base\":
        {\n        \"max_tokens\": 512,\n        \"max_input_tokens\": 512,\n        \"input_cost_per_token\":
        8e-09,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"fireworks_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://fireworks.ai/pricing\"\n    },\n    \"fireworks-ai-up-to-4b\": {\n
        \       \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        2e-07,\n        \"litellm_provider\": \"fireworks_ai\"\n    },\n    \"fireworks-ai-4.1b-to-16b\":
        {\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        2e-07,\n        \"litellm_provider\": \"fireworks_ai\"\n    },\n    \"fireworks-ai-above-16b\":
        {\n        \"input_cost_per_token\": 9e-07,\n        \"output_cost_per_token\":
        9e-07,\n        \"litellm_provider\": \"fireworks_ai\"\n    },\n    \"fireworks-ai-moe-up-to-56b\":
        {\n        \"input_cost_per_token\": 5e-07,\n        \"output_cost_per_token\":
        5e-07,\n        \"litellm_provider\": \"fireworks_ai\"\n    },\n    \"fireworks-ai-56b-to-176b\":
        {\n        \"input_cost_per_token\": 1.2e-06,\n        \"output_cost_per_token\":
        1.2e-06,\n        \"litellm_provider\": \"fireworks_ai\"\n    },\n    \"fireworks-ai-default\":
        {\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"fireworks_ai\"\n    },\n    \"fireworks-ai-embedding-up-to-150m\":
        {\n        \"input_cost_per_token\": 8e-09,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"fireworks_ai-embedding-models\"\n    },\n
        \   \"fireworks-ai-embedding-150m-to-350m\": {\n        \"input_cost_per_token\":
        1.6e-08,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"fireworks_ai-embedding-models\"\n    },\n    \"anyscale/mistralai/Mistral-7B-Instruct-v0.1\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 1.5e-07,\n
        \       \"output_cost_per_token\": 1.5e-07,\n        \"litellm_provider\":
        \"anyscale\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"source\": \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mistral-7B-Instruct-v0.1\"\n
        \   },\n    \"anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        1.5e-07,\n        \"litellm_provider\": \"anyscale\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"source\": \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x7B-Instruct-v0.1\"\n
        \   },\n    \"anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1\": {\n        \"max_tokens\":
        65536,\n        \"max_input_tokens\": 65536,\n        \"max_output_tokens\":
        65536,\n        \"input_cost_per_token\": 9e-07,\n        \"output_cost_per_token\":
        9e-07,\n        \"litellm_provider\": \"anyscale\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"source\": \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x22B-Instruct-v0.1\"\n
        \   },\n    \"anyscale/HuggingFaceH4/zephyr-7b-beta\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        1.5e-07,\n        \"litellm_provider\": \"anyscale\",\n        \"mode\": \"chat\"\n
        \   },\n    \"anyscale/google/gemma-7b-it\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 8192,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        1.5e-07,\n        \"litellm_provider\": \"anyscale\",\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/google-gemma-7b-it\"\n
        \   },\n    \"anyscale/meta-llama/Llama-2-7b-chat-hf\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        1.5e-07,\n        \"litellm_provider\": \"anyscale\",\n        \"mode\": \"chat\"\n
        \   },\n    \"anyscale/meta-llama/Llama-2-13b-chat-hf\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 2.5e-07,\n        \"output_cost_per_token\":
        2.5e-07,\n        \"litellm_provider\": \"anyscale\",\n        \"mode\": \"chat\"\n
        \   },\n    \"anyscale/meta-llama/Llama-2-70b-chat-hf\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1e-06,\n        \"output_cost_per_token\":
        1e-06,\n        \"litellm_provider\": \"anyscale\",\n        \"mode\": \"chat\"\n
        \   },\n    \"anyscale/codellama/CodeLlama-34b-Instruct-hf\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1e-06,\n        \"output_cost_per_token\":
        1e-06,\n        \"litellm_provider\": \"anyscale\",\n        \"mode\": \"chat\"\n
        \   },\n    \"anyscale/codellama/CodeLlama-70b-Instruct-hf\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1e-06,\n        \"output_cost_per_token\":
        1e-06,\n        \"litellm_provider\": \"anyscale\",\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/codellama-CodeLlama-70b-Instruct-hf\"\n
        \   },\n    \"anyscale/meta-llama/Meta-Llama-3-8B-Instruct\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 1.5e-07,\n        \"output_cost_per_token\":
        1.5e-07,\n        \"litellm_provider\": \"anyscale\",\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-8B-Instruct\"\n
        \   },\n    \"anyscale/meta-llama/Meta-Llama-3-70B-Instruct\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 1e-06,\n        \"output_cost_per_token\":
        1e-06,\n        \"litellm_provider\": \"anyscale\",\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-70B-Instruct\"\n
        \   },\n    \"cloudflare/@cf/meta/llama-2-7b-chat-fp16\": {\n        \"max_tokens\":
        3072,\n        \"max_input_tokens\": 3072,\n        \"max_output_tokens\":
        3072,\n        \"input_cost_per_token\": 1.923e-06,\n        \"output_cost_per_token\":
        1.923e-06,\n        \"litellm_provider\": \"cloudflare\",\n        \"mode\":
        \"chat\"\n    },\n    \"cloudflare/@cf/meta/llama-2-7b-chat-int8\": {\n        \"max_tokens\":
        2048,\n        \"max_input_tokens\": 2048,\n        \"max_output_tokens\":
        2048,\n        \"input_cost_per_token\": 1.923e-06,\n        \"output_cost_per_token\":
        1.923e-06,\n        \"litellm_provider\": \"cloudflare\",\n        \"mode\":
        \"chat\"\n    },\n    \"cloudflare/@cf/mistral/mistral-7b-instruct-v0.1\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 1.923e-06,\n        \"output_cost_per_token\":
        1.923e-06,\n        \"litellm_provider\": \"cloudflare\",\n        \"mode\":
        \"chat\"\n    },\n    \"cloudflare/@hf/thebloke/codellama-7b-instruct-awq\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 1.923e-06,\n        \"output_cost_per_token\":
        1.923e-06,\n        \"litellm_provider\": \"cloudflare\",\n        \"mode\":
        \"chat\"\n    },\n    \"v0/v0-1.0-md\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 128000,\n
        \       \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"litellm_provider\": \"v0\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"v0/v0-1.5-md\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        3e-06,\n        \"output_cost_per_token\": 1.5e-05,\n        \"litellm_provider\":
        \"v0\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"v0/v0-1.5-lg\": {\n        \"max_tokens\": 512000,\n        \"max_input_tokens\":
        512000,\n        \"max_output_tokens\": 512000,\n        \"input_cost_per_token\":
        1.5e-05,\n        \"output_cost_per_token\": 7.5e-05,\n        \"litellm_provider\":
        \"v0\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"lambda_ai/deepseek-llama3.3-70b\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        6e-07,\n        \"litellm_provider\": \"lambda_ai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"lambda_ai/deepseek-r1-0528\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        2e-07,\n        \"output_cost_per_token\": 6e-07,\n        \"litellm_provider\":
        \"lambda_ai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true\n    },\n    \"lambda_ai/deepseek-r1-671b\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 8e-07,\n        \"output_cost_per_token\":
        8e-07,\n        \"litellm_provider\": \"lambda_ai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"lambda_ai/deepseek-v3-0324\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        2e-07,\n        \"output_cost_per_token\": 6e-07,\n        \"litellm_provider\":
        \"lambda_ai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"lambda_ai/hermes3-405b\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        8e-07,\n        \"output_cost_per_token\": 8e-07,\n        \"litellm_provider\":
        \"lambda_ai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"lambda_ai/hermes3-70b\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        1.2e-07,\n        \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\":
        \"lambda_ai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"lambda_ai/hermes3-8b\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        2.5e-08,\n        \"output_cost_per_token\": 4e-08,\n        \"litellm_provider\":
        \"lambda_ai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"lambda_ai/lfm-40b\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 2e-07,\n        \"litellm_provider\":
        \"lambda_ai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"lambda_ai/lfm-7b\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        2.5e-08,\n        \"output_cost_per_token\": 4e-08,\n        \"litellm_provider\":
        \"lambda_ai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"lambda_ai/llama-4-maverick-17b-128e-instruct-fp8\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 5e-08,\n
        \       \"output_cost_per_token\": 1e-07,\n        \"litellm_provider\": \"lambda_ai\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"lambda_ai/llama-4-scout-17b-16e-instruct\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 5e-08,\n
        \       \"output_cost_per_token\": 1e-07,\n        \"litellm_provider\": \"lambda_ai\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"lambda_ai/llama3.1-405b-instruct-fp8\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        8e-07,\n        \"output_cost_per_token\": 8e-07,\n        \"litellm_provider\":
        \"lambda_ai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"lambda_ai/llama3.1-70b-instruct-fp8\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        1.2e-07,\n        \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\":
        \"lambda_ai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"lambda_ai/llama3.1-8b-instruct\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        2.5e-08,\n        \"output_cost_per_token\": 4e-08,\n        \"litellm_provider\":
        \"lambda_ai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"lambda_ai/llama3.1-nemotron-70b-instruct-fp8\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        1.2e-07,\n        \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\":
        \"lambda_ai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"lambda_ai/llama3.2-11b-vision-instruct\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        1.5e-08,\n        \"output_cost_per_token\": 2.5e-08,\n        \"litellm_provider\":
        \"lambda_ai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"lambda_ai/llama3.2-3b-instruct\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 1.5e-08,\n        \"output_cost_per_token\":
        2.5e-08,\n        \"litellm_provider\": \"lambda_ai\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"lambda_ai/llama3.3-70b-instruct-fp8\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 1.2e-07,\n        \"output_cost_per_token\":
        3e-07,\n        \"litellm_provider\": \"lambda_ai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"lambda_ai/qwen25-coder-32b-instruct\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 5e-08,\n        \"output_cost_per_token\":
        1e-07,\n        \"litellm_provider\": \"lambda_ai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"lambda_ai/qwen3-32b-fp8\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 5e-08,\n        \"output_cost_per_token\":
        1e-07,\n        \"litellm_provider\": \"lambda_ai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"hyperbolic/moonshotai/Kimi-K2-Instruct\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        2e-06,\n        \"output_cost_per_token\": 2e-06,\n        \"litellm_provider\":
        \"hyperbolic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"hyperbolic/deepseek-ai/DeepSeek-R1-0528\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        2.5e-07,\n        \"output_cost_per_token\": 2.5e-07,\n        \"litellm_provider\":
        \"hyperbolic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"hyperbolic/Qwen/Qwen3-235B-A22B\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        2e-06,\n        \"output_cost_per_token\": 2e-06,\n        \"litellm_provider\":
        \"hyperbolic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"hyperbolic/deepseek-ai/DeepSeek-V3-0324\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 4e-07,\n
        \       \"output_cost_per_token\": 4e-07,\n        \"litellm_provider\": \"hyperbolic\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"hyperbolic/Qwen/QwQ-32B\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        2e-07,\n        \"output_cost_per_token\": 2e-07,\n        \"litellm_provider\":
        \"hyperbolic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"hyperbolic/deepseek-ai/DeepSeek-R1\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 4e-07,\n
        \       \"output_cost_per_token\": 4e-07,\n        \"litellm_provider\": \"hyperbolic\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"hyperbolic/deepseek-ai/DeepSeek-V3\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 2e-07,\n
        \       \"output_cost_per_token\": 2e-07,\n        \"litellm_provider\": \"hyperbolic\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"hyperbolic/meta-llama/Llama-3.3-70B-Instruct\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        1.2e-07,\n        \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\":
        \"hyperbolic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"hyperbolic/Qwen/Qwen2.5-Coder-32B-Instruct\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 1.2e-07,\n
        \       \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\": \"hyperbolic\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"hyperbolic/meta-llama/Llama-3.2-3B-Instruct\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 1.2e-07,\n
        \       \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\": \"hyperbolic\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"hyperbolic/Qwen/Qwen2.5-72B-Instruct\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        1.2e-07,\n        \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\":
        \"hyperbolic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"hyperbolic/meta-llama/Meta-Llama-3-70B-Instruct\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        1.2e-07,\n        \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\":
        \"hyperbolic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"hyperbolic/NousResearch/Hermes-3-Llama-3.1-70B\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 1.2e-07,\n
        \       \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\": \"hyperbolic\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"hyperbolic/meta-llama/Meta-Llama-3.1-405B-Instruct\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 1.2e-07,\n
        \       \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\": \"hyperbolic\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"hyperbolic/meta-llama/Meta-Llama-3.1-8B-Instruct\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 1.2e-07,\n
        \       \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\": \"hyperbolic\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"hyperbolic/meta-llama/Meta-Llama-3.1-70B-Instruct\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 1.2e-07,\n
        \       \"output_cost_per_token\": 3e-07,\n        \"litellm_provider\": \"hyperbolic\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_parallel_function_calling\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"voyage/voyage-lite-01\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"voyage\",\n        \"mode\": \"embedding\"\n    },\n    \"voyage/voyage-large-2\":
        {\n        \"max_tokens\": 16000,\n        \"max_input_tokens\": 16000,\n
        \       \"input_cost_per_token\": 1.2e-07,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"voyage\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"voyage/voyage-finance-2\": {\n        \"max_tokens\": 32000,\n
        \       \"max_input_tokens\": 32000,\n        \"input_cost_per_token\": 1.2e-07,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"voyage\",\n
        \       \"mode\": \"embedding\"\n    },\n    \"voyage/voyage-lite-02-instruct\":
        {\n        \"max_tokens\": 4000,\n        \"max_input_tokens\": 4000,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"voyage\",\n        \"mode\": \"embedding\"\n    },\n    \"voyage/voyage-law-2\":
        {\n        \"max_tokens\": 16000,\n        \"max_input_tokens\": 16000,\n
        \       \"input_cost_per_token\": 1.2e-07,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"voyage\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"voyage/voyage-code-2\": {\n        \"max_tokens\": 16000,\n
        \       \"max_input_tokens\": 16000,\n        \"input_cost_per_token\": 1.2e-07,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"voyage\",\n
        \       \"mode\": \"embedding\"\n    },\n    \"voyage/voyage-2\": {\n        \"max_tokens\":
        4000,\n        \"max_input_tokens\": 4000,\n        \"input_cost_per_token\":
        1e-07,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"voyage\",\n        \"mode\": \"embedding\"\n    },\n    \"voyage/voyage-3-large\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 32000,\n
        \       \"input_cost_per_token\": 1.8e-07,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"voyage\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"voyage/voyage-3\": {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\":
        32000,\n        \"input_cost_per_token\": 6e-08,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"voyage\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"voyage/voyage-3-lite\": {\n        \"max_tokens\": 32000,\n
        \       \"max_input_tokens\": 32000,\n        \"input_cost_per_token\": 2e-08,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"voyage\",\n
        \       \"mode\": \"embedding\"\n    },\n    \"voyage/voyage-code-3\": {\n
        \       \"max_tokens\": 32000,\n        \"max_input_tokens\": 32000,\n        \"input_cost_per_token\":
        1.8e-07,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"voyage\",\n        \"mode\": \"embedding\"\n    },\n    \"voyage/voyage-multimodal-3\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 32000,\n
        \       \"input_cost_per_token\": 1.2e-07,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"voyage\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"voyage/voyage-context-3\": {\n        \"max_tokens\": 120000,\n
        \       \"max_input_tokens\": 120000,\n        \"input_cost_per_token\": 1.8e-07,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"voyage\",\n
        \       \"mode\": \"embedding\"\n    },\n    \"voyage/rerank-2\": {\n        \"max_tokens\":
        16000,\n        \"max_input_tokens\": 16000,\n        \"max_output_tokens\":
        16000,\n        \"max_query_tokens\": 16000,\n        \"input_cost_per_token\":
        5e-08,\n        \"input_cost_per_query\": 5e-08,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"voyage\",\n        \"mode\": \"rerank\"\n
        \   },\n    \"voyage/rerank-2-lite\": {\n        \"max_tokens\": 8000,\n        \"max_input_tokens\":
        8000,\n        \"max_output_tokens\": 8000,\n        \"max_query_tokens\":
        8000,\n        \"input_cost_per_token\": 2e-08,\n        \"input_cost_per_query\":
        2e-08,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"voyage\",\n        \"mode\": \"rerank\"\n    },\n    \"databricks/databricks-claude-3-7-sonnet\":
        {\n        \"max_tokens\": 200000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        2.5e-06,\n        \"input_dbu_cost_per_token\": 3.571e-05,\n        \"output_cost_per_token\":
        1.7857e-05,\n        \"output_db_cost_per_token\": 0.000214286,\n        \"litellm_provider\":
        \"databricks\",\n        \"mode\": \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\n            \"notes\": \"Input/output cost per token
        is dbu cost * $0.070, based on databricks Claude 3.7 conversion. Number provided
        for reference, '*_dbu_cost_per_token' used in actual calculation.\"\n        },\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true\n    },\n    \"databricks/databricks-meta-llama-3-1-405b-instruct\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        5e-06,\n        \"input_dbu_cost_per_token\": 7.1429e-05,\n        \"output_cost_per_token\":
        1.500002e-05,\n        \"output_db_cost_per_token\": 0.000214286,\n        \"litellm_provider\":
        \"databricks\",\n        \"mode\": \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\n            \"notes\": \"Input/output cost per token
        is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number
        provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"\n
        \       },\n        \"supports_tool_choice\": true\n    },\n    \"databricks/databricks-meta-llama-3-1-70b-instruct\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        1.00002e-06,\n        \"input_dbu_cost_per_token\": 1.4286e-05,\n        \"output_cost_per_token\":
        2.99999e-06,\n        \"output_dbu_cost_per_token\": 4.2857e-05,\n        \"litellm_provider\":
        \"databricks\",\n        \"mode\": \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\n            \"notes\": \"Input/output cost per token
        is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number
        provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"\n
        \       },\n        \"supports_tool_choice\": true\n    },\n    \"databricks/databricks-meta-llama-3-3-70b-instruct\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        1.00002e-06,\n        \"input_dbu_cost_per_token\": 1.4286e-05,\n        \"output_cost_per_token\":
        2.99999e-06,\n        \"output_dbu_cost_per_token\": 4.2857e-05,\n        \"litellm_provider\":
        \"databricks\",\n        \"mode\": \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\n            \"notes\": \"Input/output cost per token
        is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number
        provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"\n
        \       },\n        \"supports_tool_choice\": true\n    },\n    \"databricks/databricks-llama-4-maverick\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        5e-06,\n        \"input_dbu_cost_per_token\": 7.143e-05,\n        \"output_cost_per_token\":
        1.5e-05,\n        \"output_dbu_cost_per_token\": 0.00021429,\n        \"litellm_provider\":
        \"databricks\",\n        \"mode\": \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\n            \"notes\": \"Databricks documentation
        now provides both DBU costs (_dbu_cost_per_token) and dollar costs(_cost_per_token).\"\n
        \       },\n        \"supports_tool_choice\": true\n    },\n    \"databricks/databricks-dbrx-instruct\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 7.4998e-07,\n
        \       \"input_dbu_cost_per_token\": 1.0714e-05,\n        \"output_cost_per_token\":
        2.24901e-06,\n        \"output_dbu_cost_per_token\": 3.2143e-05,\n        \"litellm_provider\":
        \"databricks\",\n        \"mode\": \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\n            \"notes\": \"Input/output cost per token
        is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number
        provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"\n
        \       },\n        \"supports_tool_choice\": true\n    },\n    \"databricks/databricks-meta-llama-3-70b-instruct\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        1.00002e-06,\n        \"input_dbu_cost_per_token\": 1.4286e-05,\n        \"output_cost_per_token\":
        2.99999e-06,\n        \"output_dbu_cost_per_token\": 4.2857e-05,\n        \"litellm_provider\":
        \"databricks\",\n        \"mode\": \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\n            \"notes\": \"Input/output cost per token
        is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number
        provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"\n
        \       },\n        \"supports_tool_choice\": true\n    },\n    \"databricks/databricks-llama-2-70b-chat\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 5.0001e-07,\n        \"input_dbu_cost_per_token\":
        7.143e-06,\n        \"output_cost_per_token\": 1.5e-06,\n        \"output_dbu_cost_per_token\":
        2.1429e-05,\n        \"litellm_provider\": \"databricks\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\n            \"notes\": \"Input/output cost per token
        is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number
        provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"\n
        \       },\n        \"supports_tool_choice\": true\n    },\n    \"databricks/databricks-mixtral-8x7b-instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 5.0001e-07,\n        \"input_dbu_cost_per_token\":
        7.143e-06,\n        \"output_cost_per_token\": 9.9902e-07,\n        \"output_dbu_cost_per_token\":
        1.4286e-05,\n        \"litellm_provider\": \"databricks\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\n            \"notes\": \"Input/output cost per token
        is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number
        provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"\n
        \       },\n        \"supports_tool_choice\": true\n    },\n    \"databricks/databricks-mpt-30b-instruct\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 9.9902e-07,\n        \"input_dbu_cost_per_token\":
        1.4286e-05,\n        \"output_cost_per_token\": 9.9902e-07,\n        \"output_dbu_cost_per_token\":
        1.4286e-05,\n        \"litellm_provider\": \"databricks\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\n            \"notes\": \"Input/output cost per token
        is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number
        provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"\n
        \       },\n        \"supports_tool_choice\": true\n    },\n    \"databricks/databricks-mpt-7b-instruct\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 5.0001e-07,\n        \"input_dbu_cost_per_token\":
        7.143e-06,\n        \"output_cost_per_token\": 0.0,\n        \"output_dbu_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"databricks\",\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\n            \"notes\": \"Input/output cost per token
        is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number
        provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"\n
        \       },\n        \"supports_tool_choice\": true\n    },\n    \"databricks/databricks-bge-large-en\":
        {\n        \"max_tokens\": 512,\n        \"max_input_tokens\": 512,\n        \"output_vector_size\":
        1024,\n        \"input_cost_per_token\": 1.0003e-07,\n        \"input_dbu_cost_per_token\":
        1.429e-06,\n        \"output_cost_per_token\": 0.0,\n        \"output_dbu_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"databricks\",\n        \"mode\": \"embedding\",\n
        \       \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\n            \"notes\": \"Input/output cost per token
        is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number
        provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"\n
        \       }\n    },\n    \"databricks/databricks-gte-large-en\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"output_vector_size\":
        1024,\n        \"input_cost_per_token\": 1.2999e-07,\n        \"input_dbu_cost_per_token\":
        1.857e-06,\n        \"output_cost_per_token\": 0.0,\n        \"output_dbu_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"databricks\",\n        \"mode\": \"embedding\",\n
        \       \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\n            \"notes\": \"Input/output cost per token
        is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number
        provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"\n
        \       }\n    },\n    \"sambanova/Meta-Llama-3.1-8B-Instruct\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        2e-07,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n
        \   },\n    \"sambanova/Meta-Llama-3.1-405B-Instruct\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 5e-06,\n        \"output_cost_per_token\":
        1e-05,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n
        \   },\n    \"sambanova/Meta-Llama-3.2-1B-Instruct\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 4e-08,\n        \"output_cost_per_token\":
        8e-08,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n    },\n
        \   \"sambanova/Meta-Llama-3.2-3B-Instruct\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 4096,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 8e-08,\n        \"output_cost_per_token\":
        1.6e-07,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n
        \   },\n    \"sambanova/Llama-4-Maverick-17B-128E-Instruct\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 6.3e-07,\n        \"output_cost_per_token\":
        1.8e-06,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\",\n
        \       \"metadata\": {\n            \"notes\": \"For vision models, images
        are converted to 6432 input tokens and are billed at that amount\"\n        }\n
        \   },\n    \"sambanova/Llama-4-Scout-17B-16E-Instruct\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 4e-07,\n        \"output_cost_per_token\":
        7e-07,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\",\n
        \       \"metadata\": {\n            \"notes\": \"For vision models, images
        are converted to 6432 input tokens and are billed at that amount\"\n        }\n
        \   },\n    \"sambanova/Meta-Llama-3.3-70B-Instruct\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 6e-07,\n        \"output_cost_per_token\":
        1.2e-06,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n
        \   },\n    \"sambanova/Meta-Llama-Guard-3-8B\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        3e-07,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n    },\n
        \   \"sambanova/Qwen3-32B\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        4e-07,\n        \"output_cost_per_token\": 8e-07,\n        \"litellm_provider\":
        \"sambanova\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n    },\n
        \   \"sambanova/QwQ-32B\": {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\":
        16384,\n        \"max_output_tokens\": 16384,\n        \"input_cost_per_token\":
        5e-07,\n        \"output_cost_per_token\": 1e-06,\n        \"litellm_provider\":
        \"sambanova\",\n        \"mode\": \"chat\",\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n
        \   },\n    \"sambanova/Qwen2-Audio-7B-Instruct\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 5e-07,\n        \"output_cost_per_token\":
        0.0001,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\": \"chat\",\n
        \       \"supports_audio_input\": true,\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n
        \   },\n    \"sambanova/DeepSeek-R1-Distill-Llama-70B\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 7e-07,\n        \"output_cost_per_token\":
        1.4e-06,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n
        \   },\n    \"sambanova/DeepSeek-R1\": {\n        \"max_tokens\": 32768,\n
        \       \"max_input_tokens\": 32768,\n        \"max_output_tokens\": 32768,\n
        \       \"input_cost_per_token\": 5e-06,\n        \"output_cost_per_token\":
        7e-06,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n    },\n
        \   \"sambanova/DeepSeek-V3-0324\": {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\":
        32768,\n        \"max_output_tokens\": 32768,\n        \"input_cost_per_token\":
        3e-06,\n        \"output_cost_per_token\": 4.5e-06,\n        \"litellm_provider\":
        \"sambanova\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n
        \   },\n    \"assemblyai/nano\": {\n        \"mode\": \"audio_transcription\",\n
        \       \"input_cost_per_second\": 0.00010278,\n        \"output_cost_per_second\":
        0.0,\n        \"litellm_provider\": \"assemblyai\"\n    },\n    \"assemblyai/best\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        3.333e-05,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"assemblyai\"\n    },\n    \"jina-reranker-v2-base-multilingual\": {\n        \"max_tokens\":
        1024,\n        \"max_input_tokens\": 1024,\n        \"max_output_tokens\":
        1024,\n        \"max_document_chunks_per_query\": 2048,\n        \"input_cost_per_token\":
        1.8e-08,\n        \"output_cost_per_token\": 1.8e-08,\n        \"litellm_provider\":
        \"jina_ai\",\n        \"mode\": \"rerank\"\n    },\n    \"snowflake/deepseek-r1\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 8192,\n        \"litellm_provider\": \"snowflake\",\n
        \       \"supports_reasoning\": true,\n        \"mode\": \"chat\"\n    },\n
        \   \"snowflake/snowflake-arctic\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        4096,\n        \"max_output_tokens\": 8192,\n        \"litellm_provider\":
        \"snowflake\",\n        \"mode\": \"chat\"\n    },\n    \"snowflake/claude-3-5-sonnet\":
        {\n        \"supports_computer_use\": true,\n        \"max_tokens\": 18000,\n
        \       \"max_input_tokens\": 18000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/mistral-large\": {\n        \"max_tokens\": 32000,\n
        \       \"max_input_tokens\": 32000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/mistral-large2\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/reka-flash\": {\n        \"max_tokens\": 100000,\n
        \       \"max_input_tokens\": 100000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/reka-core\": {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\":
        32000,\n        \"max_output_tokens\": 8192,\n        \"litellm_provider\":
        \"snowflake\",\n        \"mode\": \"chat\"\n    },\n    \"snowflake/jamba-instruct\":
        {\n        \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n
        \       \"max_output_tokens\": 8192,\n        \"litellm_provider\": \"snowflake\",\n
        \       \"mode\": \"chat\"\n    },\n    \"snowflake/jamba-1.5-mini\": {\n
        \       \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n        \"max_output_tokens\":
        8192,\n        \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/jamba-1.5-large\": {\n        \"max_tokens\": 256000,\n
        \       \"max_input_tokens\": 256000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/mixtral-8x7b\": {\n        \"max_tokens\": 32000,\n
        \       \"max_input_tokens\": 32000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/llama2-70b-chat\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 4096,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/llama3-8b\": {\n        \"max_tokens\": 8000,\n        \"max_input_tokens\":
        8000,\n        \"max_output_tokens\": 8192,\n        \"litellm_provider\":
        \"snowflake\",\n        \"mode\": \"chat\"\n    },\n    \"snowflake/llama3-70b\":
        {\n        \"max_tokens\": 8000,\n        \"max_input_tokens\": 8000,\n        \"max_output_tokens\":
        8192,\n        \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/llama3.1-8b\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/llama3.1-70b\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/llama3.3-70b\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/snowflake-llama-3.3-70b\": {\n        \"max_tokens\":
        8000,\n        \"max_input_tokens\": 8000,\n        \"max_output_tokens\":
        8192,\n        \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/llama3.1-405b\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/snowflake-llama-3.1-405b\": {\n        \"max_tokens\":
        8000,\n        \"max_input_tokens\": 8000,\n        \"max_output_tokens\":
        8192,\n        \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/llama3.2-1b\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/llama3.2-3b\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/mistral-7b\": {\n        \"max_tokens\": 32000,\n
        \       \"max_input_tokens\": 32000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/gemma-7b\": {\n        \"max_tokens\": 8000,\n        \"max_input_tokens\":
        8000,\n        \"max_output_tokens\": 8192,\n        \"litellm_provider\":
        \"snowflake\",\n        \"mode\": \"chat\"\n    },\n    \"gradient_ai/anthropic-claude-3.7-sonnet\":
        {\n        \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        15e-06,\n        \"litellm_provider\": \"gradient_ai\",\n        \"mode\":
        \"chat\",\n        \"max_tokens\": 1024,\n        \"supported_endpoints\":
        [\"/v1/chat/completions\"],\n        \"supported_modalities\": [\"text\"],\n
        \       \"supports_tool_choice\": false\n    },\n    \"gradient_ai/anthropic-claude-3.5-sonnet\":
        {\n        \"input_cost_per_token\": 3e-06,\n        \"output_cost_per_token\":
        15e-06,\n        \"litellm_provider\": \"gradient_ai\",\n        \"mode\":
        \"chat\",\n        \"max_tokens\": 1024,\n        \"supported_endpoints\":
        [\"/v1/chat/completions\"],\n        \"supported_modalities\": [\"text\"],\n
        \       \"supports_tool_choice\": false\n    },\n    \"gradient_ai/anthropic-claude-3.5-haiku\":
        {\n        \"input_cost_per_token\": 8e-07,\n        \"output_cost_per_token\":
        4e-06,\n        \"litellm_provider\": \"gradient_ai\",\n        \"mode\":
        \"chat\",\n        \"max_tokens\": 1024,\n        \"supported_endpoints\":
        [\"/v1/chat/completions\"],\n        \"supported_modalities\": [\"text\"],\n
        \       \"supports_tool_choice\": false\n    },\n    \"gradient_ai/anthropic-claude-3-opus\":
        {\n        \"input_cost_per_token\": 15e-06,\n        \"output_cost_per_token\":
        75e-06,\n        \"litellm_provider\": \"gradient_ai\",\n        \"mode\":
        \"chat\",\n        \"max_tokens\": 1024,\n        \"supported_endpoints\":
        [\"/v1/chat/completions\"],\n        \"supported_modalities\": [\"text\"],\n
        \       \"supports_tool_choice\": false\n    },\n    \"gradient_ai/deepseek-r1-distill-llama-70b\":
        {\n        \"input_cost_per_token\": 99e-08,\n        \"output_cost_per_token\":
        99e-08,\n        \"litellm_provider\": \"gradient_ai\",\n        \"mode\":
        \"chat\",\n        \"max_tokens\": 8000,\n        \"supported_endpoints\":
        [\"/v1/chat/completions\"],\n        \"supported_modalities\": [\"text\"],\n
        \       \"supports_tool_choice\": false\n    },\n    \"gradient_ai/llama3.3-70b-instruct\":
        {\n        \"input_cost_per_token\": 65e-08,\n        \"output_cost_per_token\":
        65e-08,\n        \"litellm_provider\": \"gradient_ai\",\n        \"mode\":
        \"chat\",\n        \"max_tokens\": 2048,\n        \"supported_endpoints\":
        [\"/v1/chat/completions\"],\n        \"supported_modalities\": [\"text\"],\n
        \       \"supports_tool_choice\": false\n    },\n    \"gradient_ai/llama3-8b-instruct\":
        {\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        2e-07,\n        \"litellm_provider\": \"gradient_ai\",\n        \"mode\":
        \"chat\",\n        \"max_tokens\": 512,\n        \"supported_endpoints\":
        [\"/v1/chat/completions\"],\n        \"supported_modalities\": [\"text\"],\n
        \       \"supports_tool_choice\": false\n    },\n    \"gradient_ai/mistral-nemo-instruct-2407\":
        {\n        \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        3e-07,\n        \"litellm_provider\": \"gradient_ai\",\n        \"mode\":
        \"chat\",\n        \"max_tokens\": 512,\n        \"supported_endpoints\":
        [\"/v1/chat/completions\"],\n        \"supported_modalities\": [\"text\"],\n
        \       \"supports_tool_choice\": false\n    },\n    \"gradient_ai/openai-o3\":
        {\n        \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        8e-06,\n        \"litellm_provider\": \"gradient_ai\",\n        \"mode\":
        \"chat\",\n        \"max_tokens\": 100000,\n        \"supported_endpoints\":
        [\"/v1/chat/completions\"],\n        \"supported_modalities\": [\"text\"],\n
        \       \"supports_tool_choice\": false\n    },\n    \"gradient_ai/openai-o3-mini\":
        {\n        \"input_cost_per_token\": 11e-07,\n        \"output_cost_per_token\":
        44e-07,\n        \"litellm_provider\": \"gradient_ai\",\n        \"mode\":
        \"chat\",\n        \"max_tokens\": 100000,\n        \"supported_endpoints\":
        [\"/v1/chat/completions\"],\n        \"supported_modalities\": [\"text\"],\n
        \       \"supports_tool_choice\": false\n    },\n    \"gradient_ai/openai-gpt-4o\":
        {\n        \"litellm_provider\": \"gradient_ai\",\n        \"mode\": \"chat\",\n
        \       \"max_tokens\": 16384,\n        \"supported_endpoints\": [\"/v1/chat/completions\"],\n
        \       \"supported_modalities\": [\"text\"],\n        \"supports_tool_choice\":
        false\n    },\n    \"gradient_ai/openai-gpt-4o-mini\": {\n        \"litellm_provider\":
        \"gradient_ai\",\n        \"mode\": \"chat\",\n        \"max_tokens\": 16384,\n
        \       \"supported_endpoints\": [\"/v1/chat/completions\"],\n        \"supported_modalities\":
        [\"text\"],\n        \"supports_tool_choice\": false\n    },\n    \"gradient_ai/alibaba-qwen3-32b\":
        {\n        \"litellm_provider\": \"gradient_ai\",\n        \"mode\": \"chat\",\n
        \       \"max_tokens\": 2048,\n        \"supported_endpoints\": [\"/v1/chat/completions\"],\n
        \       \"supported_modalities\": [\"text\"],\n        \"supports_tool_choice\":
        false\n    },\n    \"nscale/meta-llama/Llama-4-Scout-17B-16E-Instruct\": {\n
        \       \"input_cost_per_token\": 9e-08,\n        \"output_cost_per_token\":
        2.9e-07,\n        \"litellm_provider\": \"nscale\",\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\"\n
        \   },\n    \"nscale/Qwen/Qwen2.5-Coder-3B-Instruct\": {\n        \"input_cost_per_token\":
        1e-08,\n        \"output_cost_per_token\": 3e-08,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\"\n
        \   },\n    \"nscale/Qwen/Qwen2.5-Coder-7B-Instruct\": {\n        \"input_cost_per_token\":
        1e-08,\n        \"output_cost_per_token\": 3e-08,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\"\n
        \   },\n    \"nscale/Qwen/Qwen2.5-Coder-32B-Instruct\": {\n        \"input_cost_per_token\":
        6e-08,\n        \"output_cost_per_token\": 2e-07,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\"\n
        \   },\n    \"nscale/Qwen/QwQ-32B\": {\n        \"input_cost_per_token\":
        1.8e-07,\n        \"output_cost_per_token\": 2e-07,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\"\n
        \   },\n    \"nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-70B\": {\n        \"input_cost_per_token\":
        3.75e-07,\n        \"output_cost_per_token\": 3.75e-07,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\",\n
        \       \"metadata\": {\n            \"notes\": \"Pricing listed as $0.75/1M
        tokens total. Assumed 50/50 split for input/output.\"\n        }\n    },\n
        \   \"nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-8B\": {\n        \"input_cost_per_token\":
        2.5e-08,\n        \"output_cost_per_token\": 2.5e-08,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\",\n
        \       \"metadata\": {\n            \"notes\": \"Pricing listed as $0.05/1M
        tokens total. Assumed 50/50 split for input/output.\"\n        }\n    },\n
        \   \"nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\": {\n        \"input_cost_per_token\":
        9e-08,\n        \"output_cost_per_token\": 9e-08,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\",\n
        \       \"metadata\": {\n            \"notes\": \"Pricing listed as $0.18/1M
        tokens total. Assumed 50/50 split for input/output.\"\n        }\n    },\n
        \   \"nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\": {\n        \"input_cost_per_token\":
        2e-07,\n        \"output_cost_per_token\": 2e-07,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\",\n
        \       \"metadata\": {\n            \"notes\": \"Pricing listed as $0.40/1M
        tokens total. Assumed 50/50 split for input/output.\"\n        }\n    },\n
        \   \"nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\": {\n        \"input_cost_per_token\":
        7e-08,\n        \"output_cost_per_token\": 7e-08,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\",\n
        \       \"metadata\": {\n            \"notes\": \"Pricing listed as $0.14/1M
        tokens total. Assumed 50/50 split for input/output.\"\n        }\n    },\n
        \   \"nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\": {\n        \"input_cost_per_token\":
        1.5e-07,\n        \"output_cost_per_token\": 1.5e-07,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\",\n
        \       \"metadata\": {\n            \"notes\": \"Pricing listed as $0.30/1M
        tokens total. Assumed 50/50 split for input/output.\"\n        }\n    },\n
        \   \"nscale/mistralai/mixtral-8x22b-instruct-v0.1\": {\n        \"input_cost_per_token\":
        6e-07,\n        \"output_cost_per_token\": 6e-07,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\",\n
        \       \"metadata\": {\n            \"notes\": \"Pricing listed as $1.20/1M
        tokens total. Assumed 50/50 split for input/output.\"\n        }\n    },\n
        \   \"nscale/meta-llama/Llama-3.1-8B-Instruct\": {\n        \"input_cost_per_token\":
        3e-08,\n        \"output_cost_per_token\": 3e-08,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\",\n
        \       \"metadata\": {\n            \"notes\": \"Pricing listed as $0.06/1M
        tokens total. Assumed 50/50 split for input/output.\"\n        }\n    },\n
        \   \"nscale/meta-llama/Llama-3.3-70B-Instruct\": {\n        \"input_cost_per_token\":
        2e-07,\n        \"output_cost_per_token\": 2e-07,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\",\n
        \       \"metadata\": {\n            \"notes\": \"Pricing listed as $0.40/1M
        tokens total. Assumed 50/50 split for input/output.\"\n        }\n    },\n
        \   \"nscale/black-forest-labs/FLUX.1-schnell\": {\n        \"mode\": \"image_generation\",\n
        \       \"input_cost_per_pixel\": 1.3e-09,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"nscale\",\n        \"supported_endpoints\":
        [\n            \"/v1/images/generations\"\n        ],\n        \"source\":
        \"https://docs.nscale.com/docs/inference/serverless-models/current#image-models\"\n
        \   },\n    \"nscale/stabilityai/stable-diffusion-xl-base-1.0\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 3e-09,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"nscale\",\n        \"supported_endpoints\":
        [\n            \"/v1/images/generations\"\n        ],\n        \"source\":
        \"https://docs.nscale.com/docs/inference/serverless-models/current#image-models\"\n
        \   },\n    \"featherless_ai/featherless-ai/Qwerky-72B\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        4096,\n        \"litellm_provider\": \"featherless_ai\",\n        \"mode\":
        \"chat\"\n    },\n    \"featherless_ai/featherless-ai/Qwerky-QwQ-32B\": {\n
        \       \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        4096,\n        \"litellm_provider\": \"featherless_ai\",\n        \"mode\":
        \"chat\"\n    },\n    \"deepgram/nova-3\": {\n        \"mode\": \"audio_transcription\",\n
        \       \"input_cost_per_second\": 7.167e-05,\n        \"output_cost_per_second\":
        0.0,\n        \"litellm_provider\": \"deepgram\",\n        \"supported_endpoints\":
        [\n            \"/v1/audio/transcriptions\"\n        ],\n        \"source\":
        \"https://deepgram.com/pricing\",\n        \"metadata\": {\n            \"original_pricing_per_minute\":
        0.0043,\n            \"calculation\": \"$0.0043/60 seconds = $0.00007167 per
        second\"\n        }\n    },\n    \"deepgram/nova-3-general\": {\n        \"mode\":
        \"audio_transcription\",\n        \"input_cost_per_second\": 7.167e-05,\n
        \       \"output_cost_per_second\": 0.0,\n        \"litellm_provider\": \"deepgram\",\n
        \       \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0043,\n            \"calculation\":
        \"$0.0043/60 seconds = $0.00007167 per second\"\n        }\n    },\n    \"deepgram/nova-3-medical\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        8.667e-05,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0052,\n            \"calculation\":
        \"$0.0052/60 seconds = $0.00008667 per second (multilingual)\"\n        }\n
        \   },\n    \"deepgram/nova-2\": {\n        \"mode\": \"audio_transcription\",\n
        \       \"input_cost_per_second\": 7.167e-05,\n        \"output_cost_per_second\":
        0.0,\n        \"litellm_provider\": \"deepgram\",\n        \"supported_endpoints\":
        [\n            \"/v1/audio/transcriptions\"\n        ],\n        \"source\":
        \"https://deepgram.com/pricing\",\n        \"metadata\": {\n            \"original_pricing_per_minute\":
        0.0043,\n            \"calculation\": \"$0.0043/60 seconds = $0.00007167 per
        second\"\n        }\n    },\n    \"deepgram/nova-2-general\": {\n        \"mode\":
        \"audio_transcription\",\n        \"input_cost_per_second\": 7.167e-05,\n
        \       \"output_cost_per_second\": 0.0,\n        \"litellm_provider\": \"deepgram\",\n
        \       \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0043,\n            \"calculation\":
        \"$0.0043/60 seconds = $0.00007167 per second\"\n        }\n    },\n    \"deepgram/nova-2-meeting\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        7.167e-05,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0043,\n            \"calculation\":
        \"$0.0043/60 seconds = $0.00007167 per second\"\n        }\n    },\n    \"deepgram/nova-2-phonecall\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        7.167e-05,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0043,\n            \"calculation\":
        \"$0.0043/60 seconds = $0.00007167 per second\"\n        }\n    },\n    \"deepgram/nova-2-voicemail\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        7.167e-05,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0043,\n            \"calculation\":
        \"$0.0043/60 seconds = $0.00007167 per second\"\n        }\n    },\n    \"deepgram/nova-2-finance\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        7.167e-05,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0043,\n            \"calculation\":
        \"$0.0043/60 seconds = $0.00007167 per second\"\n        }\n    },\n    \"deepgram/nova-2-conversationalai\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        7.167e-05,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0043,\n            \"calculation\":
        \"$0.0043/60 seconds = $0.00007167 per second\"\n        }\n    },\n    \"deepgram/nova-2-video\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        7.167e-05,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0043,\n            \"calculation\":
        \"$0.0043/60 seconds = $0.00007167 per second\"\n        }\n    },\n    \"deepgram/nova-2-drivethru\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        7.167e-05,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0043,\n            \"calculation\":
        \"$0.0043/60 seconds = $0.00007167 per second\"\n        }\n    },\n    \"deepgram/nova-2-automotive\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        7.167e-05,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0043,\n            \"calculation\":
        \"$0.0043/60 seconds = $0.00007167 per second\"\n        }\n    },\n    \"deepgram/nova-2-atc\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        7.167e-05,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0043,\n            \"calculation\":
        \"$0.0043/60 seconds = $0.00007167 per second\"\n        }\n    },\n    \"deepgram/nova\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        7.167e-05,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0043,\n            \"calculation\":
        \"$0.0043/60 seconds = $0.00007167 per second\"\n        }\n    },\n    \"deepgram/nova-general\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        7.167e-05,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0043,\n            \"calculation\":
        \"$0.0043/60 seconds = $0.00007167 per second\"\n        }\n    },\n    \"deepgram/nova-phonecall\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        7.167e-05,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0043,\n            \"calculation\":
        \"$0.0043/60 seconds = $0.00007167 per second\"\n        }\n    },\n    \"deepgram/enhanced\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0.00024167,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0145,\n            \"calculation\":
        \"$0.0145/60 seconds = $0.00024167 per second\"\n        }\n    },\n    \"deepgram/enhanced-general\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0.00024167,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0145,\n            \"calculation\":
        \"$0.0145/60 seconds = $0.00024167 per second\"\n        }\n    },\n    \"deepgram/enhanced-meeting\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0.00024167,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0145,\n            \"calculation\":
        \"$0.0145/60 seconds = $0.00024167 per second\"\n        }\n    },\n    \"deepgram/enhanced-phonecall\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0.00024167,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0145,\n            \"calculation\":
        \"$0.0145/60 seconds = $0.00024167 per second\"\n        }\n    },\n    \"deepgram/enhanced-finance\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0.00024167,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0145,\n            \"calculation\":
        \"$0.0145/60 seconds = $0.00024167 per second\"\n        }\n    },\n    \"deepgram/base\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0.00020833,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0125,\n            \"calculation\":
        \"$0.0125/60 seconds = $0.00020833 per second\"\n        }\n    },\n    \"deepgram/base-general\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0.00020833,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0125,\n            \"calculation\":
        \"$0.0125/60 seconds = $0.00020833 per second\"\n        }\n    },\n    \"deepgram/base-meeting\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0.00020833,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0125,\n            \"calculation\":
        \"$0.0125/60 seconds = $0.00020833 per second\"\n        }\n    },\n    \"deepgram/base-phonecall\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0.00020833,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0125,\n            \"calculation\":
        \"$0.0125/60 seconds = $0.00020833 per second\"\n        }\n    },\n    \"deepgram/base-voicemail\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0.00020833,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0125,\n            \"calculation\":
        \"$0.0125/60 seconds = $0.00020833 per second\"\n        }\n    },\n    \"deepgram/base-finance\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0.00020833,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0125,\n            \"calculation\":
        \"$0.0125/60 seconds = $0.00020833 per second\"\n        }\n    },\n    \"deepgram/base-conversationalai\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0.00020833,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0125,\n            \"calculation\":
        \"$0.0125/60 seconds = $0.00020833 per second\"\n        }\n    },\n    \"deepgram/base-video\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0.00020833,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_minute\": 0.0125,\n            \"calculation\":
        \"$0.0125/60 seconds = $0.00020833 per second\"\n        }\n    },\n    \"deepgram/whisper\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0.0001,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"notes\": \"Deepgram's hosted OpenAI Whisper models - pricing
        may differ from native Deepgram models\"\n        }\n    },\n    \"deepgram/whisper-tiny\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0.0001,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"notes\": \"Deepgram's hosted OpenAI Whisper models - pricing
        may differ from native Deepgram models\"\n        }\n    },\n    \"deepgram/whisper-base\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0.0001,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"notes\": \"Deepgram's hosted OpenAI Whisper models - pricing
        may differ from native Deepgram models\"\n        }\n    },\n    \"deepgram/whisper-small\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0.0001,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"notes\": \"Deepgram's hosted OpenAI Whisper models - pricing
        may differ from native Deepgram models\"\n        }\n    },\n    \"deepgram/whisper-medium\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0.0001,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"notes\": \"Deepgram's hosted OpenAI Whisper models - pricing
        may differ from native Deepgram models\"\n        }\n    },\n    \"deepgram/whisper-large\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0.0001,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"deepgram\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://deepgram.com/pricing\",\n        \"metadata\":
        {\n            \"notes\": \"Deepgram's hosted OpenAI Whisper models - pricing
        may differ from native Deepgram models\"\n        }\n    },\n    \"elevenlabs/scribe_v1\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        6.11e-05,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"elevenlabs\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://elevenlabs.io/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_hour\": 0.22,\n            \"calculation\":
        \"$0.22/hour = $0.00366/minute = $0.0000611 per second (enterprise pricing)\",\n
        \           \"notes\": \"ElevenLabs Scribe v1 - state-of-the-art speech recognition
        model with 99 language support\"\n        }\n    },\n    \"elevenlabs/scribe_v1_experimental\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        6.11e-05,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"elevenlabs\",\n        \"supported_endpoints\": [\n            \"/v1/audio/transcriptions\"\n
        \       ],\n        \"source\": \"https://elevenlabs.io/pricing\",\n        \"metadata\":
        {\n            \"original_pricing_per_hour\": 0.22,\n            \"calculation\":
        \"$0.22/hour = $0.00366/minute = $0.0000611 per second (enterprise pricing)\",\n
        \           \"notes\": \"ElevenLabs Scribe v1 experimental - enhanced version
        of the main Scribe model\"\n        }\n    },\n    \"bedrock/us-gov-east-1/amazon.titan-embed-text-v1\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"output_vector_size\":
        1536,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"bedrock/us-gov-east-1/amazon.titan-embed-text-v2:0\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"output_vector_size\":
        1024,\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"bedrock/us-gov-east-1/amazon.titan-text-express-v1\": {\n        \"max_tokens\":
        8000,\n        \"max_input_tokens\": 42000,\n        \"max_output_tokens\":
        8000,\n        \"input_cost_per_token\": 1.3e-06,\n        \"output_cost_per_token\":
        1.7e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/us-gov-east-1/amazon.titan-text-lite-v1\": {\n        \"max_tokens\":
        4000,\n        \"max_input_tokens\": 42000,\n        \"max_output_tokens\":
        4000,\n        \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        4e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/us-gov-east-1/amazon.titan-text-premier-v1:0\": {\n
        \       \"max_tokens\": 32000,\n        \"max_input_tokens\": 42000,\n        \"max_output_tokens\":
        32000,\n        \"input_cost_per_token\": 5e-07,\n        \"output_cost_per_token\":
        1.5e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/us-gov-east-1/anthropic.claude-3-5-sonnet-20240620-v1:0\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 3.6e-06,\n
        \       \"output_cost_per_token\": 1.8e-05,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-gov-east-1/anthropic.claude-3-haiku-20240307-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 3e-07,\n
        \       \"output_cost_per_token\": 1.5e-06,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-gov-east-1/meta.llama3-70b-instruct-v1:0\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 8000,\n        \"max_output_tokens\":
        2048,\n        \"input_cost_per_token\": 2.65e-06,\n        \"output_cost_per_token\":
        3.5e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true\n    },\n    \"bedrock/us-gov-east-1/meta.llama3-8b-instruct-v1:0\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 8000,\n        \"max_output_tokens\":
        2048,\n        \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        2.65e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true\n    },\n    \"bedrock/us-gov-west-1/amazon.titan-embed-text-v1\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"output_vector_size\":
        1536,\n        \"input_cost_per_token\": 1e-07,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"bedrock/us-gov-west-1/amazon.titan-embed-text-v2:0\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"output_vector_size\":
        1024,\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"bedrock/us-gov-west-1/amazon.titan-text-express-v1\": {\n        \"max_tokens\":
        8000,\n        \"max_input_tokens\": 42000,\n        \"max_output_tokens\":
        8000,\n        \"input_cost_per_token\": 1.3e-06,\n        \"output_cost_per_token\":
        1.7e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/us-gov-west-1/amazon.titan-text-lite-v1\": {\n        \"max_tokens\":
        4000,\n        \"max_input_tokens\": 42000,\n        \"max_output_tokens\":
        4000,\n        \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        4e-07,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/us-gov-west-1/amazon.titan-text-premier-v1:0\": {\n
        \       \"max_tokens\": 32000,\n        \"max_input_tokens\": 42000,\n        \"max_output_tokens\":
        32000,\n        \"input_cost_per_token\": 5e-07,\n        \"output_cost_per_token\":
        1.5e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\"\n
        \   },\n    \"bedrock/us-gov-west-1/anthropic.claude-3-5-sonnet-20240620-v1:0\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 3.6e-06,\n
        \       \"output_cost_per_token\": 1.8e-05,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-gov-west-1/anthropic.claude-3-haiku-20240307-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 3e-07,\n
        \       \"output_cost_per_token\": 1.5e-06,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-gov-west-1/meta.llama3-70b-instruct-v1:0\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 8000,\n        \"max_output_tokens\":
        2048,\n        \"input_cost_per_token\": 2.65e-06,\n        \"output_cost_per_token\":
        3.5e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true\n    },\n    \"bedrock/us-gov-west-1/meta.llama3-8b-instruct-v1:0\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 8000,\n        \"max_output_tokens\":
        2048,\n        \"input_cost_per_token\": 3e-07,\n        \"output_cost_per_token\":
        2.65e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true\n    },\n    \"bedrock/us-gov-east-1/amazon.nova-pro-v1:0\":
        {\n        \"max_tokens\": 10000,\n        \"max_input_tokens\": 300000,\n
        \       \"max_output_tokens\": 10000,\n        \"input_cost_per_token\": 9.6e-07,\n
        \       \"output_cost_per_token\": 3.84e-06,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"bedrock/us-gov-west-1/amazon.nova-pro-v1:0\": {\n        \"max_tokens\":
        10000,\n        \"max_input_tokens\": 300000,\n        \"max_output_tokens\":
        10000,\n        \"input_cost_per_token\": 9.6e-07,\n        \"output_cost_per_token\":
        3.84e-06,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"dashscope/qwen-max\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 30720,\n
        \       \"max_output_tokens\": 8192,\n        \"litellm_provider\": \"dashscope\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://bailian.console.alibabacloud.com/?spm=a2c63.p38356.0.0.4a615d7bjSUCb4&tab=doc#/doc/?type=model&url=https%3A%2F%2Fwww.alibabacloud.com%2Fhelp%2Fen%2Fdoc-detail%2F2840914.html\"\n
        \   },\n    \"dashscope/qwen-plus-latest\": {\n        \"max_tokens\": 131072,\n
        \       \"max_input_tokens\": 129024,\n        \"max_output_tokens\": 16384,\n
        \       \"litellm_provider\": \"dashscope\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"mode\": \"chat\",\n        \"source\": \"https://bailian.console.alibabacloud.com/?spm=a2c63.p38356.0.0.4a615d7bjSUCb4&tab=doc#/doc/?type=model&url=https%3A%2F%2Fwww.alibabacloud.com%2Fhelp%2Fen%2Fdoc-detail%2F2840914.html\"\n
        \   },\n    \"dashscope/qwen-turbo-latest\": {\n        \"max_tokens\": 131072,\n
        \       \"max_input_tokens\": 129024,\n        \"max_output_tokens\": 16384,\n
        \       \"litellm_provider\": \"dashscope\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"mode\": \"chat\",\n        \"source\": \"https://bailian.console.alibabacloud.com/?spm=a2c63.p38356.0.0.4a615d7bjSUCb4&tab=doc#/doc/?type=model&url=https%3A%2F%2Fwww.alibabacloud.com%2Fhelp%2Fen%2Fdoc-detail%2F2840914.html\"\n
        \   },\n    \"dashscope/qwen3-30b-a3b\": {\n        \"max_tokens\": 131072,\n
        \       \"max_input_tokens\": 129024,\n        \"max_output_tokens\": 16384,\n
        \       \"litellm_provider\": \"dashscope\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"mode\": \"chat\",\n        \"source\": \"https://bailian.console.alibabacloud.com/?spm=a2c63.p38356.0.0.4a615d7bjSUCb4&tab=doc#/doc/?type=model&url=https%3A%2F%2Fwww.alibabacloud.com%2Fhelp%2Fen%2Fdoc-detail%2F2840914.html\"\n
        \   },\n    \"moonshot/moonshot-v1-8k\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 8192,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        2e-06,\n        \"litellm_provider\": \"moonshot\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://platform.moonshot.ai/docs/pricing\"\n    },\n
        \   \"moonshot/moonshot-v1-32k\": {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\":
        32768,\n        \"max_output_tokens\": 32768,\n        \"input_cost_per_token\":
        1e-06,\n        \"output_cost_per_token\": 3e-06,\n        \"litellm_provider\":
        \"moonshot\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"mode\": \"chat\",\n        \"source\": \"https://platform.moonshot.ai/docs/pricing\"\n
        \   },\n    \"moonshot/moonshot-v1-128k\": {\n        \"max_tokens\": 131072,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 131072,\n
        \       \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        5e-06,\n        \"litellm_provider\": \"moonshot\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://platform.moonshot.ai/docs/pricing\"\n    },\n
        \   \"moonshot/moonshot-v1-auto\": {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\":
        131072,\n        \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        2e-06,\n        \"output_cost_per_token\": 5e-06,\n        \"litellm_provider\":
        \"moonshot\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"mode\": \"chat\",\n        \"source\": \"https://platform.moonshot.ai/docs/pricing\"\n
        \   },\n    \"moonshot/kimi-k2-0711-preview\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 6e-07,\n        \"output_cost_per_token\":
        2.5e-06,\n        \"cache_read_input_token_cost\": 1.5e-07,\n        \"litellm_provider\":
        \"moonshot\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_web_search\": true,\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2\"\n
        \   },\n    \"moonshot/moonshot-v1-32k-0430\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 1e-06,\n        \"output_cost_per_token\":
        3e-06,\n        \"litellm_provider\": \"moonshot\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://platform.moonshot.ai/docs/pricing\"\n    },\n
        \   \"moonshot/moonshot-v1-128k-0430\": {\n        \"max_tokens\": 131072,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 131072,\n
        \       \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        5e-06,\n        \"litellm_provider\": \"moonshot\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://platform.moonshot.ai/docs/pricing\"\n    },\n
        \   \"moonshot/moonshot-v1-8k-0430\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        2e-07,\n        \"output_cost_per_token\": 2e-06,\n        \"litellm_provider\":
        \"moonshot\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"mode\": \"chat\",\n        \"source\": \"https://platform.moonshot.ai/docs/pricing\"\n
        \   },\n    \"moonshot/kimi-latest\": {\n        \"max_tokens\": 131072,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 131072,\n
        \       \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        5e-06,\n        \"cache_read_input_token_cost\": 1.5e-07,\n        \"litellm_provider\":
        \"moonshot\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_vision\": true,\n        \"mode\": \"chat\",\n        \"source\":
        \"https://platform.moonshot.ai/docs/pricing\"\n    },\n    \"moonshot/kimi-latest-8k\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        2e-06,\n        \"cache_read_input_token_cost\": 1.5e-07,\n        \"litellm_provider\":
        \"moonshot\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_vision\": true,\n        \"mode\": \"chat\",\n        \"source\":
        \"https://platform.moonshot.ai/docs/pricing\"\n    },\n    \"moonshot/kimi-latest-32k\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 1e-06,\n
        \       \"output_cost_per_token\": 3e-06,\n        \"cache_read_input_token_cost\":
        1.5e-07,\n        \"litellm_provider\": \"moonshot\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_vision\":
        true,\n        \"mode\": \"chat\",\n        \"source\": \"https://platform.moonshot.ai/docs/pricing\"\n
        \   },\n    \"moonshot/kimi-latest-128k\": {\n        \"max_tokens\": 131072,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 131072,\n
        \       \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        5e-06,\n        \"cache_read_input_token_cost\": 1.5e-07,\n        \"litellm_provider\":
        \"moonshot\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_vision\": true,\n        \"mode\": \"chat\",\n        \"source\":
        \"https://platform.moonshot.ai/docs/pricing\"\n    },\n    \"moonshot/kimi-thinking-preview\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        3e-05,\n        \"output_cost_per_token\": 3e-05,\n        \"litellm_provider\":
        \"moonshot\",\n        \"supports_vision\": true,\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://platform.moonshot.ai/docs/pricing\"\n    },\n
        \   \"moonshot/moonshot-v1-8k-vision-preview\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        2e-06,\n        \"litellm_provider\": \"moonshot\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_vision\":
        true,\n        \"mode\": \"chat\",\n        \"source\": \"https://platform.moonshot.ai/docs/pricing\"\n
        \   },\n    \"moonshot/moonshot-v1-32k-vision-preview\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 1e-06,\n        \"output_cost_per_token\":
        3e-06,\n        \"litellm_provider\": \"moonshot\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_vision\":
        true,\n        \"mode\": \"chat\",\n        \"source\": \"https://platform.moonshot.ai/docs/pricing\"\n
        \   },\n    \"moonshot/moonshot-v1-128k-vision-preview\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072,\n        \"input_cost_per_token\": 2e-06,\n        \"output_cost_per_token\":
        5e-06,\n        \"litellm_provider\": \"moonshot\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_vision\":
        true,\n        \"mode\": \"chat\",\n        \"source\": \"https://platform.moonshot.ai/docs/pricing\"\n
        \   },\n    \"recraft/recraftv3\": {\n        \"mode\": \"image_generation\",\n
        \       \"output_cost_per_image\": 0.04,\n        \"litellm_provider\": \"recraft\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ],\n        \"source\": \"https://www.recraft.ai/docs#pricing\"\n
        \   },\n    \"recraft/recraftv2\": {\n        \"mode\": \"image_generation\",\n
        \       \"output_cost_per_image\": 0.022,\n        \"litellm_provider\": \"recraft\",\n
        \       \"supported_endpoints\": [\n            \"/v1/images/generations\"\n
        \       ],\n        \"source\": \"https://www.recraft.ai/docs#pricing\"\n
        \   },\n    \"morph/morph-v3-fast\": {\n        \"max_tokens\": 16000,\n        \"max_input_tokens\":
        16000,\n        \"max_output_tokens\": 16000,\n        \"input_cost_per_token\":
        8e-07,\n        \"output_cost_per_token\": 1.2e-06,\n        \"litellm_provider\":
        \"morph\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        false,\n        \"supports_parallel_function_calling\": false,\n        \"supports_vision\":
        false,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        false\n    },\n    \"morph/morph-v3-large\": {\n        \"max_tokens\": 16000,\n
        \       \"max_input_tokens\": 16000,\n        \"max_output_tokens\": 16000,\n
        \       \"input_cost_per_token\": 9e-07,\n        \"output_cost_per_token\":
        1.9e-06,\n        \"litellm_provider\": \"morph\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": false,\n        \"supports_parallel_function_calling\":
        false,\n        \"supports_vision\": false,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": false\n    },\n    \"oci/meta.llama-4-maverick-17b-128e-instruct-fp8\":
        {\n        \"max_tokens\": 512000,\n        \"max_input_tokens\": 512000,\n
        \       \"max_output_tokens\": 4000,\n        \"input_cost_per_token\": 7.2e-07,\n
        \       \"output_cost_per_token\": 7.2e-07,\n        \"litellm_provider\":
        \"oci\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": false,\n        \"source\": \"https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing\"\n
        \   },\n    \"oci/meta.llama-4-scout-17b-16e-instruct\": {\n        \"max_tokens\":
        192000,\n        \"max_input_tokens\": 192000,\n        \"max_output_tokens\":
        4000,\n        \"input_cost_per_token\": 7.2e-07,\n        \"output_cost_per_token\":
        7.2e-07,\n        \"litellm_provider\": \"oci\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing\"\n
        \   },\n    \"oci/meta.llama-3.3-70b-instruct\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4000,\n        \"input_cost_per_token\": 7.2e-07,\n        \"output_cost_per_token\":
        7.2e-07,\n        \"litellm_provider\": \"oci\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing\"\n
        \   },\n    \"oci/meta.llama-3.2-90b-vision-instruct\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4000,\n        \"input_cost_per_token\": 2.0e-06,\n        \"output_cost_per_token\":
        2.0e-06,\n        \"litellm_provider\": \"oci\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing\"\n
        \   },\n    \"oci/meta.llama-3.1-405b-instruct\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4000,\n        \"input_cost_per_token\": 1.068e-05,\n        \"output_cost_per_token\":
        1.068e-05,\n        \"litellm_provider\": \"oci\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing\"\n
        \   },\n\n    \"oci/xai.grok-4\": {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\":
        128000,\n        \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        3.0e-06,\n        \"output_cost_per_token\": 1.5e-07,\n        \"litellm_provider\":
        \"oci\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": false,\n        \"source\": \"https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing\"\n
        \   },\n    \"oci/xai.grok-3\": {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\":
        131072,\n        \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        3.0e-06,\n        \"output_cost_per_token\": 1.5e-07,\n        \"litellm_provider\":
        \"oci\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": false,\n        \"source\": \"https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing\"\n
        \   },\n    \"oci/xai.grok-3-mini\": {\n        \"max_tokens\": 131072,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 131072,\n
        \       \"input_cost_per_token\": 3.0e-07,\n        \"output_cost_per_token\":
        5.0e-07,\n        \"litellm_provider\": \"oci\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing\"\n
        \   },\n    \"oci/xai.grok-3-fast\": {\n        \"max_tokens\": 131072,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 131072,\n
        \       \"input_cost_per_token\": 5.0e-06,\n        \"output_cost_per_token\":
        2.5e-05,\n        \"litellm_provider\": \"oci\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing\"\n
        \   },\n    \"oci/xai.grok-3-mini-fast\": {\n        \"max_tokens\": 131072,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 131072,\n
        \       \"input_cost_per_token\": 6.0e-07,\n        \"output_cost_per_token\":
        4.0e-06,\n        \"litellm_provider\": \"oci\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://www.oracle.com/artificial-intelligence/generative-ai/generative-ai-service/pricing\"\n
        \   }\n}\n"
    headers: {}
    status:
      code: 200
      message: OK
- request:
    body: '{"model": "claude-3-7-sonnet-20250219", "messages": [{"role": "user", "content":
      [{"type": "text", "text": "Who won the World Cup in 2018? Answer in one word
      with no punctuation."}]}], "thinking": {"type": "enabled", "budget_tokens":
      4000}, "max_tokens": 8096}'
    headers: {}
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: '{"id":"msg_016oKa3ifBrev8uWGXRqgHkA","type":"message","role":"assistant","model":"claude-3-7-sonnet-20250219","content":[{"type":"thinking","thinking":"The
        question asks who won the 2018 FIFA World Cup. The 2018 World Cup was held
        in Russia, and France won the tournament by defeating Croatia 4-2 in the final
        match.\n\nI''m asked to answer in one word with no punctuation, so I''ll just
        write \"France\".","signature":"ErUBCkYIBhgCIkDF693+R4hGZ0O25ot6g4GeEASSHVbO2wgVlPKkAKTbp/KRyK3ldw2SqS0KhDYLhUq8c2KEwoAStjQZ1vgt+lrPEgwV1V8FFDHJcgNJGFwaDDvzX+roSIR977xKWCIwICayi7BYpfBWvyjt0ZfC4c+vlr3cHeneioVCexRyIHZYoQEWpV5eSHBehZPKYQuyKh1lSVG23TErxcByBWP8fV0rtct00oQ7hHDxH1g7ShgC"},{"type":"text","text":"France"}],"stop_reason":"end_turn","stop_sequence":null,"usage":{"input_tokens":54,"cache_creation_input_tokens":0,"cache_read_input_tokens":0,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":0},"output_tokens":79,"service_tier":"standard"}}'
    headers: {}
    status:
      code: 200
      message: OK
version: 1
