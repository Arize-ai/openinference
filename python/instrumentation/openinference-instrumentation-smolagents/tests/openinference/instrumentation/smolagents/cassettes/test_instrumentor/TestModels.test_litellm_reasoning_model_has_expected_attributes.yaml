interactions:
- request:
    body: ''
    headers: {}
    method: GET
    uri: https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json
  response:
    body:
      string: "{\n    \"sample_spec\": {\n        \"max_tokens\": \"LEGACY parameter.
        set to max_output_tokens if provider specifies it. IF not set to max_input_tokens,
        if provider specifies it.\", \n        \"max_input_tokens\": \"max input tokens,
        if the provider specifies it. if not default to max_tokens\",\n        \"max_output_tokens\":
        \"max output tokens, if the provider specifies it. if not default to max_tokens\",
        \n        \"input_cost_per_token\": 0.0000,\n        \"output_cost_per_token\":
        0.000,\n        \"output_cost_per_reasoning_token\": 0.000,\n        \"litellm_provider\":
        \"one of https://docs.litellm.ai/docs/providers\",\n        \"mode\": \"one
        of: chat, embedding, completion, image_generation, audio_transcription, audio_speech,
        image_generation, moderation, rerank\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_audio_input\": true, \n        \"supports_audio_output\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_web_search\": true,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.0000,\n            \"search_context_size_medium\":
        0.0000,\n            \"search_context_size_high\": 0.0000\n        },\n        \"deprecation_date\":
        \"date when the model becomes deprecated in the format YYYY-MM-DD\"\n    },\n
        \   \"omni-moderation-latest\": {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\":
        32768,\n        \"max_output_tokens\": 0, \n        \"input_cost_per_token\":
        0.0,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"moderation\"\n    },\n    \"omni-moderation-latest-intents\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 0, \n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"openai\",\n
        \       \"mode\": \"moderation\"\n    },\n    \"omni-moderation-2024-09-26\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 0, \n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"openai\",\n
        \       \"mode\": \"moderation\"\n    },\n    \"gpt-4\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.00003,\n        \"output_cost_per_token\":
        0.00006,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4.1\": {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\":
        1047576,\n        \"max_output_tokens\": 32768,\n        \"input_cost_per_token\":
        2e-6,\n        \"output_cost_per_token\": 8e-6,\n        \"input_cost_per_token_batches\":
        1e-6,\n        \"output_cost_per_token_batches\": 4e-6,\n        \"cache_read_input_token_cost\":
        0.5e-6,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\"/v1/chat/completions\", \"/v1/batch\",
        \"/v1/responses\"],\n        \"supported_modalities\": [\"text\", \"image\"],\n
        \       \"supported_output_modalities\": [\"text\"],\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true,\n        \"supports_web_search\": true,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 30e-3,\n            \"search_context_size_medium\":
        35e-3,\n            \"search_context_size_high\": 50e-3\n        }\n    },\n
        \   \"gpt-4.1-2025-04-14\": {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\":
        1047576,\n        \"max_output_tokens\": 32768,\n        \"input_cost_per_token\":
        2e-6,\n        \"output_cost_per_token\": 8e-6,\n        \"input_cost_per_token_batches\":
        1e-6,\n        \"output_cost_per_token_batches\": 4e-6,\n        \"cache_read_input_token_cost\":
        0.5e-6,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\"/v1/chat/completions\", \"/v1/batch\",
        \"/v1/responses\"],\n        \"supported_modalities\": [\"text\", \"image\"],\n
        \       \"supported_output_modalities\": [\"text\"],\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true,\n        \"supports_web_search\": true,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 30e-3,\n            \"search_context_size_medium\":
        35e-3,\n            \"search_context_size_high\": 50e-3\n        }\n    },\n
        \   \"gpt-4.1-mini\": {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\":
        1047576,\n        \"max_output_tokens\": 32768,\n        \"input_cost_per_token\":
        0.4e-6,\n        \"output_cost_per_token\": 1.6e-6,\n        \"input_cost_per_token_batches\":
        0.2e-6,\n        \"output_cost_per_token_batches\": 0.8e-6,\n        \"cache_read_input_token_cost\":
        0.1e-6,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\"/v1/chat/completions\", \"/v1/batch\",
        \"/v1/responses\"],\n        \"supported_modalities\": [\"text\", \"image\"],\n
        \       \"supported_output_modalities\": [\"text\"],\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true,\n        \"supports_web_search\": true,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 25e-3,\n            \"search_context_size_medium\":
        27.5e-3,\n            \"search_context_size_high\": 30e-3\n        }\n    },\n
        \   \"gpt-4.1-mini-2025-04-14\": {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\":
        1047576,\n        \"max_output_tokens\": 32768,\n        \"input_cost_per_token\":
        0.4e-6,\n        \"output_cost_per_token\": 1.6e-6,\n        \"input_cost_per_token_batches\":
        0.2e-6,\n        \"output_cost_per_token_batches\": 0.8e-6,\n        \"cache_read_input_token_cost\":
        0.1e-6,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\"/v1/chat/completions\", \"/v1/batch\",
        \"/v1/responses\"],\n        \"supported_modalities\": [\"text\", \"image\"],\n
        \       \"supported_output_modalities\": [\"text\"],\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true,\n        \"supports_web_search\": true,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 25e-3,\n            \"search_context_size_medium\":
        27.5e-3,\n            \"search_context_size_high\": 30e-3\n        }\n    },\n
        \   \"gpt-4.1-nano\": {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\":
        1047576,\n        \"max_output_tokens\": 32768,\n        \"input_cost_per_token\":
        0.1e-6,\n        \"output_cost_per_token\": 0.4e-6,\n        \"input_cost_per_token_batches\":
        0.05e-6,\n        \"output_cost_per_token_batches\": 0.2e-6,\n        \"cache_read_input_token_cost\":
        0.025e-6,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\"/v1/chat/completions\", \"/v1/batch\",
        \"/v1/responses\"],\n        \"supported_modalities\": [\"text\", \"image\"],\n
        \       \"supported_output_modalities\": [\"text\"],\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true\n    },\n    \"gpt-4.1-nano-2025-04-14\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 1047576,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 0.1e-6,\n        \"output_cost_per_token\":
        0.4e-6,\n        \"input_cost_per_token_batches\": 0.05e-6,\n        \"output_cost_per_token_batches\":
        0.2e-6,\n        \"cache_read_input_token_cost\": 0.025e-6,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supported_endpoints\":
        [\"/v1/chat/completions\", \"/v1/batch\", \"/v1/responses\"],\n        \"supported_modalities\":
        [\"text\", \"image\"],\n        \"supported_output_modalities\": [\"text\"],\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_native_streaming\": true\n    },\n    \"gpt-4o\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.0000025,\n
        \       \"output_cost_per_token\": 0.000010,\n        \"input_cost_per_token_batches\":
        0.00000125,\n        \"output_cost_per_token_batches\": 0.00000500,\n        \"cache_read_input_token_cost\":
        0.00000125,\n        \"litellm_provider\": \"openai\",\n        \"mode\":
        \"chat\",\n        \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_web_search\": true,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.030,\n            \"search_context_size_medium\":
        0.035,\n            \"search_context_size_high\": 0.050\n        }\n    },\n
        \   \"watsonx/ibm/granite-3-8b-instruct\": {\n        \"max_tokens\": 8192,
        \ \n        \"max_input_tokens\": 8192,  \n        \"max_output_tokens\":
        1024,  \n        \"input_cost_per_token\": 0.0002,  \n        \"output_cost_per_token\":
        0.0002,  \n        \"litellm_provider\": \"watsonx\",  \n        \"mode\":
        \"chat\",  \n        \"supports_function_calling\": true,  \n        \"supports_tool_choice\":
        true,\n        \"supports_parallel_function_calling\": false,  \n        \"supports_vision\":
        false,  \n        \"supports_audio_input\": false,  \n        \"supports_audio_output\":
        false,  \n        \"supports_prompt_caching\": true,  \n        \"supports_response_schema\":
        true,  \n        \"supports_system_messages\": true\n    },\n    \"gpt-4o-search-preview-2025-03-11\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.0000025,\n
        \       \"output_cost_per_token\": 0.000010,\n        \"input_cost_per_token_batches\":
        0.00000125,\n        \"output_cost_per_token_batches\": 0.00000500,\n        \"cache_read_input_token_cost\":
        0.00000125,\n        \"litellm_provider\": \"openai\",\n        \"mode\":
        \"chat\",\n        \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_web_search\": true,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.030,\n            \"search_context_size_medium\":
        0.035,\n            \"search_context_size_high\": 0.050\n        }\n     },\n
        \   \"gpt-4o-search-preview\": {\n       \"max_tokens\": 16384,\n        \"max_input_tokens\":
        128000,\n        \"max_output_tokens\": 16384,\n        \"input_cost_per_token\":
        0.0000025,\n        \"output_cost_per_token\": 0.000010,\n        \"input_cost_per_token_batches\":
        0.00000125,\n        \"output_cost_per_token_batches\": 0.00000500,\n        \"cache_read_input_token_cost\":
        0.00000125,\n        \"litellm_provider\": \"openai\",\n        \"mode\":
        \"chat\",\n        \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_web_search\": true,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.030,\n            \"search_context_size_medium\":
        0.035,\n            \"search_context_size_high\": 0.050\n        }\n    },\n
        \   \"gpt-4.5-preview\": {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\":
        128000,\n        \"max_output_tokens\": 16384,\n        \"input_cost_per_token\":
        0.000075,\n        \"output_cost_per_token\": 0.00015,\n        \"input_cost_per_token_batches\":
        0.0000375,\n        \"output_cost_per_token_batches\": 0.000075,\n        \"cache_read_input_token_cost\":
        0.0000375,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4.5-preview-2025-02-27\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.000075,\n        \"output_cost_per_token\":
        0.00015,\n        \"input_cost_per_token_batches\": 0.0000375,\n        \"output_cost_per_token_batches\":
        0.000075,\n        \"cache_read_input_token_cost\": 0.0000375,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2025-07-14\"\n    },\n    \"gpt-4o-audio-preview\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.0000025,\n        \"input_cost_per_audio_token\":
        0.0001,\n        \"output_cost_per_token\": 0.000010,\n        \"output_cost_per_audio_token\":
        0.0002,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4o-audio-preview-2024-12-17\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.0000025,\n        \"input_cost_per_audio_token\":
        0.00004,\n        \"output_cost_per_token\": 0.000010,\n        \"output_cost_per_audio_token\":
        0.00008,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4o-audio-preview-2024-10-01\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.0000025,\n        \"input_cost_per_audio_token\":
        0.0001,\n        \"output_cost_per_token\": 0.000010,\n        \"output_cost_per_audio_token\":
        0.0002,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4o-mini-audio-preview-2024-12-17\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.00000015,\n        \"input_cost_per_audio_token\":
        0.00001,\n        \"output_cost_per_token\": 0.0000006,\n        \"output_cost_per_audio_token\":
        0.00002,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4o-mini\": {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\":
        128000,\n        \"max_output_tokens\": 16384,\n        \"input_cost_per_token\":
        0.00000015,\n        \"output_cost_per_token\": 0.00000060,\n        \"input_cost_per_token_batches\":
        0.000000075,\n        \"output_cost_per_token_batches\": 0.00000030,\n        \"cache_read_input_token_cost\":
        0.000000075,\n        \"litellm_provider\": \"openai\",\n        \"mode\":
        \"chat\",\n        \"supports_pdf_input\": true, \n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_web_search\": true,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.025,\n            \"search_context_size_medium\":
        0.0275,\n            \"search_context_size_high\": 0.030\n        }\n    },\n
        \   \"gpt-4o-mini-search-preview-2025-03-11\":{\n        \"max_tokens\": 16384,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 16384,\n
        \       \"input_cost_per_token\": 0.00000015,\n        \"output_cost_per_token\":
        0.00000060,\n        \"input_cost_per_token_batches\": 0.000000075,\n        \"output_cost_per_token_batches\":
        0.00000030,\n        \"cache_read_input_token_cost\": 0.000000075,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_web_search\":
        true,\n        \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        0.025,\n            \"search_context_size_medium\": 0.0275,\n            \"search_context_size_high\":
        0.030\n        }\n    },\n    \"gpt-4o-mini-search-preview\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.00000015,\n        \"output_cost_per_token\":
        0.00000060,\n        \"input_cost_per_token_batches\": 0.000000075,\n        \"output_cost_per_token_batches\":
        0.00000030,\n        \"cache_read_input_token_cost\": 0.000000075,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_web_search\":
        true,\n        \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        0.025,\n            \"search_context_size_medium\": 0.0275,\n            \"search_context_size_high\":
        0.030\n        }\n    },\n    \"gpt-4o-mini-2024-07-18\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.00000015,\n        \"output_cost_per_token\":
        0.00000060,\n        \"input_cost_per_token_batches\": 0.000000075,\n        \"output_cost_per_token_batches\":
        0.00000030,\n        \"cache_read_input_token_cost\": 0.000000075,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 30.00,\n            \"search_context_size_medium\":
        35.00,\n            \"search_context_size_high\": 50.00\n        }\n    },\n
        \   \"o1-pro\": {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\":
        200000,\n        \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        0.00015,\n        \"output_cost_per_token\": 0.0006,\n        \"input_cost_per_token_batches\":
        0.000075,\n        \"output_cost_per_token_batches\": 0.0003,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"responses\",\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        false,\n        \"supports_reasoning\": true,\n        \"supported_modalities\":
        [\"text\", \"image\"],\n        \"supported_output_modalities\": [\"text\"],\n
        \       \"supported_endpoints\": [\"/v1/responses\", \"/v1/batch\"]\n    },\n
        \   \"o1-pro-2025-03-19\": {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\":
        200000,\n        \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        0.00015,\n        \"output_cost_per_token\": 0.0006,\n        \"input_cost_per_token_batches\":
        0.000075,\n        \"output_cost_per_token_batches\": 0.0003,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"responses\",\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        false,\n        \"supports_reasoning\": true,\n        \"supported_modalities\":
        [\"text\", \"image\"],\n        \"supported_output_modalities\": [\"text\"],\n
        \       \"supported_endpoints\": [\"/v1/responses\", \"/v1/batch\"]\n    },\n
        \   \"o1\": {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\":
        200000,\n        \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        0.000015,\n        \"output_cost_per_token\": 0.00006,\n        \"cache_read_input_token_cost\":
        0.0000075,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"o1-mini\": {\n
        \       \"max_tokens\": 65536,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        65536,\n        \"input_cost_per_token\": 0.0000011,\n        \"output_cost_per_token\":
        0.0000044,\n        \"cache_read_input_token_cost\": 0.00000055,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_vision\": true,\n
        \       \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true\n    },\n    \"computer-use-preview\": {\n        \"max_tokens\": 1024,\n
        \       \"max_input_tokens\": 8192,\n        \"max_output_tokens\": 1024,\n
        \       \"input_cost_per_token\": 3e-6,\n        \"output_cost_per_token\":
        12e-6,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\"/v1/responses\"],\n        \"supported_modalities\":
        [\"text\", \"image\"],\n        \"supported_output_modalities\": [\"text\"],\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": false,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true\n    },\n    \"o3\": {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\":
        200000,\n        \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        1e-5,\n        \"output_cost_per_token\": 4e-5,\n        \"cache_read_input_token_cost\":
        2.5e-6,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        false,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"o3-2025-04-16\": {\n        \"max_tokens\": 100000,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 100000,\n
        \       \"input_cost_per_token\": 1e-5,\n        \"output_cost_per_token\":
        4e-5,\n        \"cache_read_input_token_cost\": 2.5e-6,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": false,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"o3-mini\": {\n
        \       \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        100000,\n        \"input_cost_per_token\": 0.0000011,\n        \"output_cost_per_token\":
        0.0000044,\n        \"cache_read_input_token_cost\": 0.00000055,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": false,\n        \"supports_vision\":
        false,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"o3-mini-2025-01-31\": {\n        \"max_tokens\": 100000,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 100000,\n
        \       \"input_cost_per_token\": 0.0000011,\n        \"output_cost_per_token\":
        0.0000044,\n        \"cache_read_input_token_cost\": 0.00000055,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": false,\n        \"supports_vision\":
        false,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"o4-mini\": {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\":
        200000,\n        \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        1.1e-6,\n        \"output_cost_per_token\": 4.4e-6,\n        \"cache_read_input_token_cost\":
        2.75e-7,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": false,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"o4-mini-2025-04-16\": {\n        \"max_tokens\": 100000,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 100000,\n
        \       \"input_cost_per_token\": 1.1e-6,\n        \"output_cost_per_token\":
        4.4e-6,\n        \"cache_read_input_token_cost\": 2.75e-7,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        false,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"o1-mini-2024-09-12\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 65536,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000012,\n        \"cache_read_input_token_cost\":
        0.0000015,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_vision\": true,\n
        \       \"supports_reasoning\": true,\n        \"supports_prompt_caching\":
        true\n    },\n    \"o1-preview\": {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\":
        128000,\n        \"max_output_tokens\": 32768,\n        \"input_cost_per_token\":
        0.000015,\n        \"output_cost_per_token\": 0.000060,\n        \"cache_read_input_token_cost\":
        0.0000075,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_vision\": true,\n
        \       \"supports_reasoning\": true,\n        \"supports_prompt_caching\":
        true\n    },\n    \"o1-preview-2024-09-12\": {\n        \"max_tokens\": 32768,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 32768,\n
        \       \"input_cost_per_token\": 0.000015,\n        \"output_cost_per_token\":
        0.000060,\n        \"cache_read_input_token_cost\": 0.0000075,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_pdf_input\":
        true,\n        \"supports_vision\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_prompt_caching\": true\n    },\n    \"o1-2024-12-17\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        0.000015,\n        \"output_cost_per_token\": 0.000060,\n        \"cache_read_input_token_cost\":
        0.0000075,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"chatgpt-4o-latest\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000005,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4o-2024-05-13\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.000005,\n        \"output_cost_per_token\":
        0.000015,\n        \"input_cost_per_token_batches\": 0.0000025,\n        \"output_cost_per_token_batches\":
        0.0000075,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"gpt-4o-2024-08-06\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.0000025,\n
        \       \"output_cost_per_token\": 0.000010,\n        \"input_cost_per_token_batches\":
        0.00000125,\n        \"output_cost_per_token_batches\": 0.0000050,\n        \"cache_read_input_token_cost\":
        0.00000125,\n        \"litellm_provider\": \"openai\",\n        \"mode\":
        \"chat\",\n        \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_web_search\": true,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 0.030,\n            \"search_context_size_medium\":
        0.035,\n            \"search_context_size_high\": 0.050\n        }\n    },\n
        \   \"gpt-4o-2024-11-20\": {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\":
        128000,\n        \"max_output_tokens\": 16384,\n        \"input_cost_per_token\":
        0.0000025,\n        \"output_cost_per_token\": 0.000010,\n        \"input_cost_per_token_batches\":
        0.00000125,\n        \"output_cost_per_token_batches\": 0.0000050,\n        \"cache_read_input_token_cost\":
        0.00000125,\n        \"litellm_provider\": \"openai\",\n        \"mode\":
        \"chat\",\n        \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4o-realtime-preview-2024-10-01\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000005,\n        \"input_cost_per_audio_token\":
        0.0001,\n        \"cache_read_input_token_cost\": 0.0000025,\n        \"cache_creation_input_audio_token_cost\":
        0.00002,\n        \"output_cost_per_token\": 0.00002,\n        \"output_cost_per_audio_token\":
        0.0002,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4o-realtime-preview\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000005,\n        \"input_cost_per_audio_token\":
        0.00004,\n        \"cache_read_input_token_cost\": 0.0000025,\n        \"output_cost_per_token\":
        0.00002,\n        \"output_cost_per_audio_token\": 0.00008,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_audio_input\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"gpt-4o-realtime-preview-2024-12-17\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000005,\n
        \       \"input_cost_per_audio_token\": 0.00004,\n        \"cache_read_input_token_cost\":
        0.0000025,\n        \"output_cost_per_token\": 0.00002,\n        \"output_cost_per_audio_token\":
        0.00008,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4o-mini-realtime-preview\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000006,\n        \"input_cost_per_audio_token\":
        0.00001,\n        \"cache_read_input_token_cost\": 0.0000003,\n        \"cache_creation_input_audio_token_cost\":
        0.0000003,\n        \"output_cost_per_token\": 0.0000024,\n        \"output_cost_per_audio_token\":
        0.00002,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4o-mini-realtime-preview-2024-12-17\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000006,\n        \"input_cost_per_audio_token\":
        0.00001,\n        \"cache_read_input_token_cost\": 0.0000003,\n        \"cache_creation_input_audio_token_cost\":
        0.0000003,\n        \"output_cost_per_token\": 0.0000024,\n        \"output_cost_per_audio_token\":
        0.00002,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4-turbo-preview\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.00001,\n        \"output_cost_per_token\":
        0.00003,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4-0314\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.00003,\n        \"output_cost_per_token\": 0.00006,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4-0613\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.00003,\n        \"output_cost_per_token\": 0.00006,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"deprecation_date\": \"2025-06-06\",\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4-32k\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        32768,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.00006,\n        \"output_cost_per_token\": 0.00012,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4-32k-0314\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        32768,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.00006,\n        \"output_cost_per_token\": 0.00012,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4-32k-0613\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        32768,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.00006,\n        \"output_cost_per_token\": 0.00012,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4-turbo\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        128000,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.00001,\n        \"output_cost_per_token\": 0.00003,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4-turbo-2024-04-09\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.00001,\n        \"output_cost_per_token\":
        0.00003,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"gpt-4-1106-preview\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00001,\n
        \       \"output_cost_per_token\": 0.00003,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-4-0125-preview\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.00001,\n        \"output_cost_per_token\":
        0.00003,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"gpt-4-vision-preview\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00001,\n
        \       \"output_cost_per_token\": 0.00003,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_vision\": true,\n
        \       \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"deprecation_date\":
        \"2024-12-06\",\n        \"supports_tool_choice\": true\n    },\n    \"gpt-4-1106-vision-preview\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00001,\n
        \       \"output_cost_per_token\": 0.00003,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_vision\": true,\n
        \       \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"deprecation_date\":
        \"2024-12-06\",\n        \"supports_tool_choice\": true\n    },\n    \"gpt-3.5-turbo\":
        {\n        \"max_tokens\": 4097,\n        \"max_input_tokens\": 16385,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000015,\n        \"output_cost_per_token\":
        0.000002,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-3.5-turbo-0301\": {\n        \"max_tokens\": 4097,\n
        \       \"max_input_tokens\": 4097,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.0000015,\n        \"output_cost_per_token\":
        0.000002,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"gpt-3.5-turbo-0613\":
        {\n        \"max_tokens\": 4097,\n        \"max_input_tokens\": 4097,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000015,\n        \"output_cost_per_token\":
        0.000002,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-3.5-turbo-1106\": {\n        \"max_tokens\": 16385,\n
        \       \"max_input_tokens\": 16385,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.0000010,\n        \"output_cost_per_token\":
        0.0000020,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"gpt-3.5-turbo-0125\":
        {\n        \"max_tokens\": 16385,\n        \"max_input_tokens\": 16385,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.0000005,\n
        \       \"output_cost_per_token\": 0.0000015,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"gpt-3.5-turbo-16k\": {\n        \"max_tokens\": 16385,\n
        \       \"max_input_tokens\": 16385,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000004,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"gpt-3.5-turbo-16k-0613\":
        {\n        \"max_tokens\": 16385,\n        \"max_input_tokens\": 16385,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000004,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"ft:gpt-3.5-turbo\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 16385,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000006,\n        \"input_cost_per_token_batches\": 0.0000015,\n        \"output_cost_per_token_batches\":
        0.000003,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"ft:gpt-3.5-turbo-0125\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 16385,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000006,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"ft:gpt-3.5-turbo-1106\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 16385,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000006,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"ft:gpt-3.5-turbo-0613\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 4096,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000006,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"ft:gpt-4-0613\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.00003,\n        \"output_cost_per_token\": 0.00006,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"source\": \"OpenAI needs to add pricing for this ft model,
        will be updated when added by OpenAI. Defaulting to base model pricing\",\n
        \       \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"ft:gpt-4o-2024-08-06\": {\n        \"max_tokens\": 16384,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 16384,\n
        \       \"input_cost_per_token\": 0.00000375,\n        \"output_cost_per_token\":
        0.000015,\n        \"input_cost_per_token_batches\": 0.000001875,\n        \"output_cost_per_token_batches\":
        0.000007500,\n        \"litellm_provider\": \"openai\",\n        \"mode\":
        \"chat\",\n        \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"ft:gpt-4o-2024-11-20\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.00000375,\n
        \       \"cache_creation_input_token_cost\": 0.000001875,\n        \"output_cost_per_token\":
        0.000015,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"ft:gpt-4o-mini-2024-07-18\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.0000003,\n        \"output_cost_per_token\":
        0.0000012,\n        \"input_cost_per_token_batches\": 0.000000150,\n        \"output_cost_per_token_batches\":
        0.000000600,\n        \"cache_read_input_token_cost\": 0.00000015,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"ft:davinci-002\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000002,\n
        \       \"output_cost_per_token\": 0.000002,\n        \"input_cost_per_token_batches\":
        0.000001,\n        \"output_cost_per_token_batches\": 0.000001,\n        \"litellm_provider\":
        \"text-completion-openai\",\n        \"mode\": \"completion\"\n    },\n    \"ft:babbage-002\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.0000004,\n
        \       \"output_cost_per_token\": 0.0000004,\n        \"input_cost_per_token_batches\":
        0.0000002,\n        \"output_cost_per_token_batches\": 0.0000002,\n        \"litellm_provider\":
        \"text-completion-openai\",\n        \"mode\": \"completion\"\n    },\n    \"text-embedding-3-large\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 8191,\n        \"output_vector_size\":
        3072,\n        \"input_cost_per_token\": 0.00000013,\n        \"output_cost_per_token\":
        0.000000,\n        \"input_cost_per_token_batches\": 0.000000065,\n        \"output_cost_per_token_batches\":
        0.000000000,\n        \"litellm_provider\": \"openai\",\n        \"mode\":
        \"embedding\"\n    },\n    \"text-embedding-3-small\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 8191,\n        \"output_vector_size\":
        1536, \n        \"input_cost_per_token\": 0.00000002,\n        \"output_cost_per_token\":
        0.000000,\n        \"input_cost_per_token_batches\": 0.000000010,\n        \"output_cost_per_token_batches\":
        0.000000000,\n        \"litellm_provider\": \"openai\",\n        \"mode\":
        \"embedding\"\n    },\n    \"text-embedding-ada-002\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 8191,\n        \"output_vector_size\":
        1536, \n        \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"openai\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"text-embedding-ada-002-v2\": {\n        \"max_tokens\": 8191,\n
        \       \"max_input_tokens\": 8191,\n        \"input_cost_per_token\": 0.0000001,\n
        \       \"output_cost_per_token\": 0.000000,\n        \"input_cost_per_token_batches\":
        0.000000050,\n        \"output_cost_per_token_batches\": 0.000000000,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"embedding\"\n    },\n    \"text-moderation-stable\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 0,\n        \"input_cost_per_token\": 0.000000,\n
        \       \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"moderation\"\n    },\n    \"text-moderation-007\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 0,\n        \"input_cost_per_token\": 0.000000,\n
        \       \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"moderation\"\n    },\n    \"text-moderation-latest\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 0,\n        \"input_cost_per_token\": 0.000000,\n
        \       \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"openai\",\n        \"mode\": \"moderation\"\n    },\n    \"256-x-256/dall-e-2\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        0.00000024414,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"openai\"\n    },\n    \"512-x-512/dall-e-2\": {\n        \"mode\": \"image_generation\",\n
        \       \"input_cost_per_pixel\": 0.0000000686,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"openai\"\n    },\n    \"1024-x-1024/dall-e-2\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        0.000000019,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"openai\"\n    },\n    \"hd/1024-x-1792/dall-e-3\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 0.00000006539,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"openai\"\n
        \   },\n    \"hd/1792-x-1024/dall-e-3\": {\n        \"mode\": \"image_generation\",\n
        \       \"input_cost_per_pixel\": 0.00000006539,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"openai\"\n    },\n    \"hd/1024-x-1024/dall-e-3\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        0.00000007629,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"openai\"\n    },\n    \"standard/1024-x-1792/dall-e-3\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 0.00000004359,\n
        \       \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\": \"openai\"\n
        \   },\n    \"standard/1792-x-1024/dall-e-3\": {\n        \"mode\": \"image_generation\",\n
        \       \"input_cost_per_pixel\": 0.00000004359,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"openai\"\n    },\n    \"standard/1024-x-1024/dall-e-3\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        0.0000000381469,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"openai\"\n    },\n    \"gpt-image-1\": {\n        \"mode\": \"image_generation\",\n
        \       \"input_cost_per_pixel\": 4.0054321e-8,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"openai\",\n        \"supported_endpoints\":
        [\"/v1/images/generations\"]\n    },\n    \"low/1024-x-1024/gpt-image-1\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        1.0490417e-8,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"openai\",\n        \"supported_endpoints\": [\"/v1/images/generations\"]\n
        \   },\n    \"medium/1024-x-1024/gpt-image-1\": {\n        \"mode\": \"image_generation\",\n
        \       \"input_cost_per_pixel\": 4.0054321e-8,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"openai\",\n        \"supported_endpoints\":
        [\"/v1/images/generations\"]\n    },\n    \"high/1024-x-1024/gpt-image-1\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        1.59263611e-7,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"openai\",\n        \"supported_endpoints\": [\"/v1/images/generations\"]\n
        \   },\n    \"low/1024-x-1536/gpt-image-1\": {\n        \"mode\": \"image_generation\",\n
        \       \"input_cost_per_pixel\": 1.0172526e-8,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"openai\",\n        \"supported_endpoints\":
        [\"/v1/images/generations\"]\n    },\n    \"medium/1024-x-1536/gpt-image-1\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        4.0054321e-8,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"openai\",\n        \"supported_endpoints\": [\"/v1/images/generations\"]\n
        \   },\n    \"high/1024-x-1536/gpt-image-1\": {\n        \"mode\": \"image_generation\",\n
        \       \"input_cost_per_pixel\": 1.58945719e-7,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"openai\",\n        \"supported_endpoints\":
        [\"/v1/images/generations\"]\n    },\n    \"low/1536-x-1024/gpt-image-1\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        1.0172526e-8,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"openai\",\n        \"supported_endpoints\": [\"/v1/images/generations\"]\n
        \   },\n    \"medium/1536-x-1024/gpt-image-1\": {\n        \"mode\": \"image_generation\",\n
        \       \"input_cost_per_pixel\": 4.0054321e-8,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"openai\",\n        \"supported_endpoints\":
        [\"/v1/images/generations\"]\n    },\n    \"high/1536-x-1024/gpt-image-1\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        1.58945719e-7,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"openai\",\n        \"supported_endpoints\": [\"/v1/images/generations\"]\n
        \   },\n    \"gpt-4o-transcribe\": {\n        \"mode\": \"audio_transcription\",\n
        \       \"max_input_tokens\": 16000,\n        \"max_output_tokens\": 2000,\n
        \       \"input_cost_per_token\": 0.0000025,\n        \"input_cost_per_audio_token\":
        0.000006,\n        \"output_cost_per_token\": 0.00001, \n        \"litellm_provider\":
        \"openai\",\n        \"supported_endpoints\": [\"/v1/audio/transcriptions\"]\n
        \   }, \n    \"gpt-4o-mini-transcribe\": {\n        \"mode\": \"audio_transcription\",\n
        \       \"max_input_tokens\": 16000,\n        \"max_output_tokens\": 2000,\n
        \       \"input_cost_per_token\": 0.00000125,\n        \"input_cost_per_audio_token\":
        0.000003,\n        \"output_cost_per_token\": 0.000005, \n        \"litellm_provider\":
        \"openai\",\n        \"supported_endpoints\": [\"/v1/audio/transcriptions\"]\n
        \   }, \n    \"whisper-1\": {\n        \"mode\": \"audio_transcription\",\n
        \       \"input_cost_per_second\": 0.0001,\n        \"output_cost_per_second\":
        0.0001, \n        \"litellm_provider\": \"openai\",\n        \"supported_endpoints\":
        [\"/v1/audio/transcriptions\"]\n    }, \n    \"tts-1\": {\n        \"mode\":
        \"audio_speech\", \n        \"input_cost_per_character\": 0.000015,\n        \"litellm_provider\":
        \"openai\",\n        \"supported_endpoints\": [\"/v1/audio/speech\"]\n    },\n
        \   \"tts-1-hd\": {\n        \"mode\": \"audio_speech\", \n        \"input_cost_per_character\":
        0.000030,\n        \"litellm_provider\": \"openai\",\n        \"supported_endpoints\":
        [\"/v1/audio/speech\"]\n    },\n    \"gpt-4o-mini-tts\": {\n        \"mode\":
        \"audio_speech\", \n        \"input_cost_per_token\": 2.5e-6,\n        \"output_cost_per_token\":
        10e-6,\n        \"output_cost_per_audio_token\": 12e-6,\n        \"output_cost_per_second\":
        0.00025,\n        \"litellm_provider\": \"openai\",\n        \"supported_modalities\":
        [\"text\", \"audio\"],\n        \"supported_output_modalities\": [\"audio\"],\n
        \       \"supported_endpoints\": [\"/v1/audio/speech\"]\n    },\n    \"azure/gpt-4o-mini-tts\":
        {\n        \"mode\": \"audio_speech\", \n        \"input_cost_per_token\":
        2.5e-6,\n        \"output_cost_per_token\": 10e-6,\n        \"output_cost_per_audio_token\":
        12e-6,\n        \"output_cost_per_second\": 0.00025,\n        \"litellm_provider\":
        \"azure\",\n        \"supported_modalities\": [\"text\", \"audio\"],\n        \"supported_output_modalities\":
        [\"audio\"],\n        \"supported_endpoints\": [\"/v1/audio/speech\"]\n    },\n
        \   \"azure/computer-use-preview\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        3e-6,\n        \"output_cost_per_token\": 12e-6,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supported_endpoints\":
        [\"/v1/responses\"],\n        \"supported_modalities\": [\"text\", \"image\"],\n
        \       \"supported_output_modalities\": [\"text\"],\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        false,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"azure/gpt-4o-audio-preview-2024-12-17\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.0000025,\n
        \       \"input_cost_per_audio_token\": 0.00004,\n        \"output_cost_per_token\":
        0.00001,\n        \"output_cost_per_audio_token\": 0.00008,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supported_endpoints\":
        [\"/v1/chat/completions\"],\n        \"supported_modalities\": [\"text\",
        \"audio\"],\n        \"supported_output_modalities\": [\"text\", \"audio\"],\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": false,\n        \"supports_vision\":
        false,\n        \"supports_prompt_caching\": false,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true,\n        \"supports_reasoning\": false\n    },\n    \"azure/gpt-4o-mini-audio-preview-2024-12-17\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.0000025,\n
        \       \"input_cost_per_audio_token\": 0.00004,\n        \"output_cost_per_token\":
        0.00001,\n        \"output_cost_per_audio_token\": 0.00008,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supported_endpoints\":
        [\"/v1/chat/completions\"],\n        \"supported_modalities\": [\"text\",
        \"audio\"],\n        \"supported_output_modalities\": [\"text\", \"audio\"],\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": false,\n        \"supports_vision\":
        false,\n        \"supports_prompt_caching\": false,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true,\n        \"supports_reasoning\": false\n    },\n    \"azure/gpt-4.1\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 1047576,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 2e-6,\n
        \       \"output_cost_per_token\": 8e-6,\n        \"input_cost_per_token_batches\":
        1e-6,\n        \"output_cost_per_token_batches\": 4e-6,\n        \"cache_read_input_token_cost\":
        0.5e-6,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\"/v1/chat/completions\", \"/v1/batch\",
        \"/v1/responses\"],\n        \"supported_modalities\": [\"text\", \"image\"],\n
        \       \"supported_output_modalities\": [\"text\"],\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_native_streaming\": true,\n        \"supports_web_search\":
        true,\n        \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        30e-3,\n            \"search_context_size_medium\": 35e-3,\n            \"search_context_size_high\":
        50e-3\n        }\n    },\n    \"azure/gpt-4.1-2025-04-14\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 1047576,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 2e-6,\n        \"output_cost_per_token\":
        8e-6,\n        \"input_cost_per_token_batches\": 1e-6,\n        \"output_cost_per_token_batches\":
        4e-6,\n        \"cache_read_input_token_cost\": 0.5e-6,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supported_endpoints\":
        [\"/v1/chat/completions\", \"/v1/batch\", \"/v1/responses\"],\n        \"supported_modalities\":
        [\"text\", \"image\"],\n        \"supported_output_modalities\": [\"text\"],\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true,\n        \"supports_web_search\": true,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 30e-3,\n            \"search_context_size_medium\":
        35e-3,\n            \"search_context_size_high\": 50e-3\n        }\n    },\n
        \   \"azure/gpt-4.1-mini\": {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\":
        1047576,\n        \"max_output_tokens\": 32768,\n        \"input_cost_per_token\":
        0.4e-6,\n        \"output_cost_per_token\": 1.6e-6,\n        \"input_cost_per_token_batches\":
        0.2e-6,\n        \"output_cost_per_token_batches\": 0.8e-6,\n        \"cache_read_input_token_cost\":
        0.1e-6,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\"/v1/chat/completions\", \"/v1/batch\",
        \"/v1/responses\"],\n        \"supported_modalities\": [\"text\", \"image\"],\n
        \       \"supported_output_modalities\": [\"text\"],\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_native_streaming\": true,\n        \"supports_web_search\":
        true,\n        \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        25e-3,\n            \"search_context_size_medium\": 27.5e-3,\n            \"search_context_size_high\":
        30e-3\n        }\n    },\n    \"azure/gpt-4.1-mini-2025-04-14\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 1047576,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 0.4e-6,\n        \"output_cost_per_token\":
        1.6e-6,\n        \"input_cost_per_token_batches\": 0.2e-6,\n        \"output_cost_per_token_batches\":
        0.8e-6,\n        \"cache_read_input_token_cost\": 0.1e-6,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supported_endpoints\":
        [\"/v1/chat/completions\", \"/v1/batch\", \"/v1/responses\"],\n        \"supported_modalities\":
        [\"text\", \"image\"],\n        \"supported_output_modalities\": [\"text\"],\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_native_streaming\":
        true,\n        \"supports_web_search\": true,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 25e-3,\n            \"search_context_size_medium\":
        27.5e-3,\n            \"search_context_size_high\": 30e-3\n        }\n    },\n
        \   \"azure/gpt-4.1-nano\": {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\":
        1047576,\n        \"max_output_tokens\": 32768,\n        \"input_cost_per_token\":
        0.1e-6,\n        \"output_cost_per_token\": 0.4e-6,\n        \"input_cost_per_token_batches\":
        0.05e-6,\n        \"output_cost_per_token_batches\": 0.2e-6,\n        \"cache_read_input_token_cost\":
        0.025e-6,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\"/v1/chat/completions\", \"/v1/batch\",
        \"/v1/responses\"],\n        \"supported_modalities\": [\"text\", \"image\"],\n
        \       \"supported_output_modalities\": [\"text\"],\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_native_streaming\": true\n    },\n    \"azure/gpt-4.1-nano-2025-04-14\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 1047576,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 0.1e-6,\n
        \       \"output_cost_per_token\": 0.4e-6,\n        \"input_cost_per_token_batches\":
        0.05e-6,\n        \"output_cost_per_token_batches\": 0.2e-6,\n        \"cache_read_input_token_cost\":
        0.025e-6,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\"/v1/chat/completions\", \"/v1/batch\",
        \"/v1/responses\"],\n        \"supported_modalities\": [\"text\", \"image\"],\n
        \       \"supported_output_modalities\": [\"text\"],\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_native_streaming\": true\n    },\n    \"azure/o3\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        1e-5,\n        \"output_cost_per_token\": 4e-5,\n        \"cache_read_input_token_cost\":
        2.5e-6,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\"/v1/chat/completions\", \"/v1/batch\",
        \"/v1/responses\"],\n        \"supported_modalities\": [\"text\", \"image\"],\n
        \       \"supported_output_modalities\": [\"text\"],\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": false,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/o3-2025-04-16\": {\n        \"max_tokens\": 100000,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 100000,\n
        \       \"input_cost_per_token\": 1e-5,\n        \"output_cost_per_token\":
        4e-5,\n        \"cache_read_input_token_cost\": 2.5e-6,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supported_endpoints\":
        [\"/v1/chat/completions\", \"/v1/batch\", \"/v1/responses\"],\n        \"supported_modalities\":
        [\"text\", \"image\"],\n        \"supported_output_modalities\": [\"text\"],\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        false,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/o4-mini\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        1.1e-6,\n        \"output_cost_per_token\": 4.4e-6,\n        \"cache_read_input_token_cost\":
        2.75e-7,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_endpoints\": [\"/v1/chat/completions\", \"/v1/batch\",
        \"/v1/responses\"],\n        \"supported_modalities\": [\"text\", \"image\"],\n
        \       \"supported_output_modalities\": [\"text\"],\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": false,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-4o-mini-realtime-preview-2024-12-17\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000006,\n        \"input_cost_per_audio_token\":
        0.00001,\n        \"cache_read_input_token_cost\": 0.0000003,\n        \"cache_creation_input_audio_token_cost\":
        0.0000003,\n        \"output_cost_per_token\": 0.0000024,\n        \"output_cost_per_audio_token\":
        0.00002,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/eu/gpt-4o-mini-realtime-preview-2024-12-17\": {\n
        \       \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000066,\n        \"input_cost_per_audio_token\":
        0.000011,\n        \"cache_read_input_token_cost\": 0.00000033,\n        \"cache_creation_input_audio_token_cost\":
        0.00000033,\n        \"output_cost_per_token\": 0.00000264,\n        \"output_cost_per_audio_token\":
        0.000022,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/us/gpt-4o-mini-realtime-preview-2024-12-17\": {\n
        \       \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000066,\n        \"input_cost_per_audio_token\":
        0.000011,\n        \"cache_read_input_token_cost\": 0.00000033,\n        \"cache_creation_input_audio_token_cost\":
        0.00000033,\n        \"output_cost_per_token\": 0.00000264,\n        \"output_cost_per_audio_token\":
        0.000022,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-4o-realtime-preview-2024-12-17\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000005,\n        \"input_cost_per_audio_token\":
        0.00004,\n        \"cache_read_input_token_cost\": 0.0000025,\n        \"output_cost_per_token\":
        0.00002,\n        \"output_cost_per_audio_token\": 0.00008,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supported_modalities\":
        [\"text\", \"audio\"],\n        \"supported_output_modalities\": [\"text\",
        \"audio\"],\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/us/gpt-4o-realtime-preview-2024-12-17\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 5.5e-6,\n        \"input_cost_per_audio_token\":
        44e-6,\n        \"cache_read_input_token_cost\": 2.75e-6,\n        \"cache_read_input_audio_token_cost\":
        2.5e-6,\n        \"output_cost_per_token\": 22e-6,\n        \"output_cost_per_audio_token\":
        80e-6,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_modalities\": [\"text\", \"audio\"],\n        \"supported_output_modalities\":
        [\"text\", \"audio\"],\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/eu/gpt-4o-realtime-preview-2024-12-17\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 5.5e-6,\n        \"input_cost_per_audio_token\":
        44e-6,\n        \"cache_read_input_token_cost\": 2.75e-6,\n        \"cache_read_input_audio_token_cost\":
        2.5e-6,\n        \"output_cost_per_token\": 22e-6,\n        \"output_cost_per_audio_token\":
        80e-6,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supported_modalities\": [\"text\", \"audio\"],\n        \"supported_output_modalities\":
        [\"text\", \"audio\"],\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-4o-realtime-preview-2024-10-01\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000005,\n        \"input_cost_per_audio_token\":
        0.0001,\n        \"cache_read_input_token_cost\": 0.0000025,\n        \"cache_creation_input_audio_token_cost\":
        0.00002,\n        \"output_cost_per_token\": 0.00002,\n        \"output_cost_per_audio_token\":
        0.0002,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/us/gpt-4o-realtime-preview-2024-10-01\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000055,\n        \"input_cost_per_audio_token\":
        0.00011,\n        \"cache_read_input_token_cost\": 0.00000275,\n        \"cache_creation_input_audio_token_cost\":
        0.000022,\n        \"output_cost_per_token\": 0.000022,\n        \"output_cost_per_audio_token\":
        0.00022,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/eu/gpt-4o-realtime-preview-2024-10-01\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000055,\n        \"input_cost_per_audio_token\":
        0.00011,\n        \"cache_read_input_token_cost\": 0.00000275,\n        \"cache_creation_input_audio_token_cost\":
        0.000022,\n        \"output_cost_per_token\": 0.000022,\n        \"output_cost_per_audio_token\":
        0.00022,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/o4-mini-2025-04-16\": {\n        \"max_tokens\":
        100000,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        100000,\n        \"input_cost_per_token\": 1.1e-6,\n        \"output_cost_per_token\":
        4.4e-6,\n        \"cache_read_input_token_cost\": 2.75e-7,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": false,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/o3-mini-2025-01-31\": {\n        \"max_tokens\":
        100000,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        100000,\n        \"input_cost_per_token\": 0.0000011,\n        \"output_cost_per_token\":
        0.0000044,\n        \"cache_read_input_token_cost\": 0.00000055,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_reasoning\": true,\n
        \       \"supports_vision\": false,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/us/o3-mini-2025-01-31\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        0.00000121,\n        \"input_cost_per_token_batches\": 0.000000605,\n        \"output_cost_per_token\":
        0.00000484,\n        \"output_cost_per_token_batches\": 0.00000242,\n        \"cache_read_input_token_cost\":
        0.000000605,\n        \"litellm_provider\": \"azure\",\n        \"mode\":
        \"chat\",\n        \"supports_vision\": false,\n        \"supports_reasoning\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/eu/o3-mini-2025-01-31\": {\n        \"max_tokens\":
        100000,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        100000,\n        \"input_cost_per_token\": 0.00000121,\n        \"input_cost_per_token_batches\":
        0.000000605,\n        \"output_cost_per_token\": 0.00000484,\n        \"output_cost_per_token_batches\":
        0.00000242,\n        \"cache_read_input_token_cost\": 0.000000605,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_vision\": false,\n
        \       \"supports_reasoning\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/tts-1\":
        {\n        \"mode\": \"audio_speech\", \n        \"input_cost_per_character\":
        0.000015,\n        \"litellm_provider\": \"azure\"\n    },\n    \"azure/tts-1-hd\":
        {\n        \"mode\": \"audio_speech\", \n        \"input_cost_per_character\":
        0.000030,\n        \"litellm_provider\": \"azure\"\n    },\n    \"azure/whisper-1\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0.0001, \n        \"output_cost_per_second\": 0.0001, \n        \"litellm_provider\":
        \"azure\"\n    },\n    \"azure/o3-mini\": {\n        \"max_tokens\": 100000,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 100000,\n
        \       \"input_cost_per_token\": 0.0000011,\n        \"output_cost_per_token\":
        0.0000044,\n        \"cache_read_input_token_cost\": 0.00000055,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_vision\": false,\n
        \       \"supports_prompt_caching\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/o1-mini\": {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\":
        128000,\n        \"max_output_tokens\": 65536,\n        \"input_cost_per_token\":
        0.00000121,\n        \"output_cost_per_token\": 0.00000484,\n        \"cache_read_input_token_cost\":
        0.000000605,\n        \"litellm_provider\": \"azure\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": false,\n        \"supports_reasoning\":
        true,\n        \"supports_prompt_caching\": true\n    },\n    \"azure/o1-mini-2024-09-12\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 65536,\n        \"input_cost_per_token\": 1.1e-6,\n
        \       \"output_cost_per_token\": 4.4e-6,\n        \"cache_read_input_token_cost\":
        0.55e-6,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": false,\n        \"supports_reasoning\":
        true,\n        \"supports_prompt_caching\": true\n    },\n    \"azure/us/o1-mini-2024-09-12\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 65536,\n        \"input_cost_per_token\": 0.00000121,\n
        \       \"input_cost_per_token_batches\": 0.000000605,\n        \"output_cost_per_token\":
        0.00000484,\n        \"output_cost_per_token_batches\": 0.00000242,\n        \"cache_read_input_token_cost\":
        0.000000605,\n        \"litellm_provider\": \"azure\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": false,\n        \"supports_prompt_caching\":
        true\n    },\n    \"azure/eu/o1-mini-2024-09-12\": {\n        \"max_tokens\":
        65536,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        65536,\n        \"input_cost_per_token\": 0.00000121,\n        \"input_cost_per_token_batches\":
        0.000000605,\n        \"output_cost_per_token\": 0.00000484,\n        \"output_cost_per_token_batches\":
        0.00000242,\n        \"cache_read_input_token_cost\": 0.000000605,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        false,\n        \"supports_prompt_caching\": true\n    },\n    \"azure/o1\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        0.000015,\n        \"output_cost_per_token\": 0.000060,\n        \"cache_read_input_token_cost\":
        0.0000075,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/o1-2024-12-17\": {\n        \"max_tokens\": 100000,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 100000,\n
        \       \"input_cost_per_token\": 0.000015,\n        \"output_cost_per_token\":
        0.000060,\n        \"cache_read_input_token_cost\": 0.0000075,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/us/o1-2024-12-17\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        0.0000165,\n        \"output_cost_per_token\": 0.000066,\n        \"cache_read_input_token_cost\":
        0.00000825,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/eu/o1-2024-12-17\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        0.0000165,\n        \"output_cost_per_token\": 0.000066,\n        \"cache_read_input_token_cost\":
        0.00000825,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/o1-preview\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 0.000015,\n
        \       \"output_cost_per_token\": 0.000060,\n        \"cache_read_input_token_cost\":
        0.0000075,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": false,\n        \"supports_reasoning\":
        true,\n        \"supports_prompt_caching\": true\n    },\n    \"azure/o1-preview-2024-09-12\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 0.000015,\n
        \       \"output_cost_per_token\": 0.000060,\n        \"cache_read_input_token_cost\":
        0.0000075,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        false,\n        \"supports_reasoning\": true,\n        \"supports_prompt_caching\":
        true\n    },\n    \"azure/us/o1-preview-2024-09-12\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 0.0000165,\n        \"output_cost_per_token\":
        0.000066,\n        \"cache_read_input_token_cost\": 0.00000825,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        false,\n        \"supports_prompt_caching\": true\n    },\n    \"azure/eu/o1-preview-2024-09-12\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 0.0000165,\n
        \       \"output_cost_per_token\": 0.000066,\n        \"cache_read_input_token_cost\":
        0.00000825,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": false,\n        \"supports_prompt_caching\":
        true\n    },\n    \"azure/gpt-4.5-preview\": {\n        \"max_tokens\": 16384,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 16384,\n
        \       \"input_cost_per_token\": 0.000075,\n        \"output_cost_per_token\":
        0.00015,\n        \"input_cost_per_token_batches\": 0.0000375,\n        \"output_cost_per_token_batches\":
        0.000075,\n        \"cache_read_input_token_cost\": 0.0000375,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-4o\": {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\":
        128000,\n        \"max_output_tokens\": 16384,\n        \"input_cost_per_token\":
        0.0000025,\n        \"output_cost_per_token\": 0.00001,\n        \"cache_read_input_token_cost\":
        0.00000125,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/global/gpt-4o-2024-11-20\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.0000025,\n        \"output_cost_per_token\":
        0.00001,\n        \"cache_read_input_token_cost\": 0.00000125,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/gpt-4o-2024-08-06\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.0000025,\n
        \       \"output_cost_per_token\": 0.00001,\n        \"cache_read_input_token_cost\":
        0.00000125,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/global/gpt-4o-2024-08-06\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.0000025,\n        \"output_cost_per_token\":
        0.00001,\n        \"cache_read_input_token_cost\": 0.00000125,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/gpt-4o-2024-11-20\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.00000275,\n
        \       \"output_cost_per_token\": 0.000011,\n        \"cache_read_input_token_cost\":
        0.00000125,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/us/gpt-4o-2024-11-20\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.00000275,\n        \"cache_creation_input_token_cost\":
        0.00000138,\n        \"output_cost_per_token\": 0.000011,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/eu/gpt-4o-2024-11-20\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.00000275,\n        \"cache_creation_input_token_cost\":
        0.00000138,\n        \"output_cost_per_token\": 0.000011,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-4o-2024-05-13\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000005,\n        \"output_cost_per_token\":
        0.000015,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/global-standard/gpt-4o-2024-08-06\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.0000025,\n
        \       \"output_cost_per_token\": 0.000010,\n        \"cache_read_input_token_cost\":
        0.00000125,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_tool_choice\":
        true,\n        \"deprecation_date\": \"2025-08-20\"\n    },\n    \"azure/us/gpt-4o-2024-08-06\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.00000275,\n
        \       \"output_cost_per_token\": 0.000011,\n        \"cache_read_input_token_cost\":
        0.000001375,\n        \"litellm_provider\": \"azure\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/eu/gpt-4o-2024-08-06\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.00000275,\n        \"output_cost_per_token\":
        0.000011,\n        \"cache_read_input_token_cost\": 0.000001375,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/global-standard/gpt-4o-2024-11-20\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.0000025,\n
        \       \"output_cost_per_token\": 0.000010,\n        \"cache_read_input_token_cost\":
        0.00000125,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2025-12-20\"\n    },\n    \"azure/global-standard/gpt-4o-mini\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.00000015,\n        \"output_cost_per_token\":
        0.00000060,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/gpt-4o-mini\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.000000165,\n
        \       \"output_cost_per_token\": 0.00000066,\n        \"cache_read_input_token_cost\":
        0.000000075,\n        \"litellm_provider\": \"azure\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-4o-mini-2024-07-18\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.000000165,\n        \"output_cost_per_token\":
        0.00000066,\n        \"cache_read_input_token_cost\": 0.000000075,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/us/gpt-4o-mini-2024-07-18\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.000000165,\n
        \       \"output_cost_per_token\": 0.00000066,\n        \"cache_read_input_token_cost\":
        0.000000083,\n        \"litellm_provider\": \"azure\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/eu/gpt-4o-mini-2024-07-18\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.000000165,\n        \"output_cost_per_token\":
        0.00000066,\n        \"cache_read_input_token_cost\": 0.000000083,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/gpt-4-turbo-2024-04-09\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00001,\n
        \       \"output_cost_per_token\": 0.00003,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/gpt-4-0125-preview\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00001,\n
        \       \"output_cost_per_token\": 0.00003,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-4-1106-preview\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00001,\n        \"output_cost_per_token\":
        0.00003,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/gpt-4-0613\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00003,\n        \"output_cost_per_token\":
        0.00006,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-4-32k-0613\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 32768,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.00006,\n        \"output_cost_per_token\":
        0.00012,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure/gpt-4-32k\": {\n
        \       \"max_tokens\": 4096,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00006,\n        \"output_cost_per_token\":
        0.00012,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure/gpt-4\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00003,\n        \"output_cost_per_token\":
        0.00006,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-4-turbo\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.00001,\n        \"output_cost_per_token\":
        0.00003,\n        \"litellm_provider\": \"azure\", \n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure/gpt-4-turbo-vision-preview\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00001,\n
        \       \"output_cost_per_token\": 0.00003,\n        \"litellm_provider\":
        \"azure\", \n        \"mode\": \"chat\",\n        \"supports_vision\": true,\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure/gpt-35-turbo-16k-0613\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 16385,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000004,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-35-turbo-1106\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000001,\n        \"output_cost_per_token\":
        0.000002,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"deprecation_date\": \"2025-03-31\",\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-35-turbo-0613\": {\n        \"max_tokens\":
        4097,\n        \"max_input_tokens\": 4097,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000015,\n        \"output_cost_per_token\":
        0.000002,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"deprecation_date\": \"2025-02-13\",\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-35-turbo-0301\": {\n        \"max_tokens\":
        4097,\n        \"max_input_tokens\": 4097,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000002,\n        \"output_cost_per_token\":
        0.000002,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"deprecation_date\": \"2025-02-13\",\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-35-turbo-0125\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000005,\n        \"output_cost_per_token\":
        0.0000015,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"deprecation_date\": \"2025-05-31\",\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-3.5-turbo-0125\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000005,\n        \"output_cost_per_token\":
        0.0000015,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"deprecation_date\": \"2025-03-31\",\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-35-turbo-16k\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 16385,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000004,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure/gpt-35-turbo\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4097,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000005,\n        \"output_cost_per_token\":
        0.0000015,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-3.5-turbo\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 4097,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.0000005,\n        \"output_cost_per_token\":
        0.0000015,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure/gpt-3.5-turbo-instruct-0914\": {\n        \"max_tokens\":
        4097,\n        \"max_input_tokens\": 4097,\n        \"input_cost_per_token\":
        0.0000015,\n        \"output_cost_per_token\": 0.000002,\n        \"litellm_provider\":
        \"azure_text\",\n        \"mode\": \"completion\"\n    },\n    \"azure/gpt-35-turbo-instruct\":
        {\n        \"max_tokens\": 4097,\n        \"max_input_tokens\": 4097,\n        \"input_cost_per_token\":
        0.0000015,\n        \"output_cost_per_token\": 0.000002,\n        \"litellm_provider\":
        \"azure_text\",\n        \"mode\": \"completion\"\n    },\n    \"azure/gpt-35-turbo-instruct-0914\":
        {\n        \"max_tokens\": 4097,\n        \"max_input_tokens\": 4097,\n        \"input_cost_per_token\":
        0.0000015,\n        \"output_cost_per_token\": 0.000002,\n        \"litellm_provider\":
        \"azure_text\",\n        \"mode\": \"completion\"\n    },\n    \"azure/mistral-large-latest\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 32000,\n
        \       \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"azure/mistral-large-2402\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 32000,\n
        \       \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"azure/command-r-plus\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true\n    },\n    \"azure/ada\": {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\":
        8191,\n        \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"azure\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"azure/text-embedding-ada-002\": {\n        \"max_tokens\": 8191,\n
        \       \"max_input_tokens\": 8191,\n        \"input_cost_per_token\": 0.0000001,\n
        \       \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"embedding\"\n    },\n    \"azure/text-embedding-3-large\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 8191,\n        \"input_cost_per_token\":
        0.00000013,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"embedding\"\n    },\n    \"azure/text-embedding-3-small\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 8191,\n        \"input_cost_per_token\":
        0.00000002,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"azure\",\n        \"mode\": \"embedding\"\n    },\n    \"azure/gpt-image-1\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        4.0054321e-8,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"azure\",\n        \"supported_endpoints\": [\"/v1/images/generations\"]\n
        \   },\n    \"azure/low/1024-x-1024/gpt-image-1\": {\n        \"mode\": \"image_generation\",\n
        \       \"input_cost_per_pixel\": 1.0490417e-8,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"azure\",\n        \"supported_endpoints\":
        [\"/v1/images/generations\"]\n    },\n    \"azure/medium/1024-x-1024/gpt-image-1\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        4.0054321e-8,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"azure\",\n        \"supported_endpoints\": [\"/v1/images/generations\"]\n
        \   },\n    \"azure/high/1024-x-1024/gpt-image-1\": {\n        \"mode\": \"image_generation\",\n
        \       \"input_cost_per_pixel\": 1.59263611e-7,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"azure\",\n        \"supported_endpoints\":
        [\"/v1/images/generations\"]\n    },\n    \"azure/low/1024-x-1536/gpt-image-1\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        1.0172526e-8,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"azure\",\n        \"supported_endpoints\": [\"/v1/images/generations\"]\n
        \   },\n    \"azure/medium/1024-x-1536/gpt-image-1\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 4.0054321e-8,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"azure\",\n        \"supported_endpoints\":
        [\"/v1/images/generations\"]\n    },\n    \"azure/high/1024-x-1536/gpt-image-1\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        1.58945719e-7,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"azure\",\n        \"supported_endpoints\": [\"/v1/images/generations\"]\n
        \   },\n    \"azure/low/1536-x-1024/gpt-image-1\": {\n        \"mode\": \"image_generation\",\n
        \       \"input_cost_per_pixel\": 1.0172526e-8,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"azure\",\n        \"supported_endpoints\":
        [\"/v1/images/generations\"]\n    },\n    \"azure/medium/1536-x-1024/gpt-image-1\":
        {\n        \"mode\": \"image_generation\",\n        \"input_cost_per_pixel\":
        4.0054321e-8,\n        \"output_cost_per_pixel\": 0.0,\n        \"litellm_provider\":
        \"azure\",\n        \"supported_endpoints\": [\"/v1/images/generations\"]\n
        \   },\n    \"azure/high/1536-x-1024/gpt-image-1\": {\n        \"mode\": \"image_generation\",\n
        \       \"input_cost_per_pixel\": 1.58945719e-7,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"azure\",\n        \"supported_endpoints\":
        [\"/v1/images/generations\"]\n    },   \n    \"azure/standard/1024-x-1024/dall-e-3\":
        {\n        \"input_cost_per_pixel\": 0.0000000381469,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure\", \n        \"mode\": \"image_generation\"\n
        \   },\n    \"azure/hd/1024-x-1024/dall-e-3\": {\n        \"input_cost_per_pixel\":
        0.00000007629,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"azure\", \n        \"mode\": \"image_generation\"\n    },\n    \"azure/standard/1024-x-1792/dall-e-3\":
        {\n        \"input_cost_per_pixel\": 0.00000004359,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure\", \n        \"mode\": \"image_generation\"\n
        \   },\n    \"azure/standard/1792-x-1024/dall-e-3\": {\n        \"input_cost_per_pixel\":
        0.00000004359,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"azure\", \n        \"mode\": \"image_generation\"\n    },\n    \"azure/hd/1024-x-1792/dall-e-3\":
        {\n        \"input_cost_per_pixel\": 0.00000006539,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure\", \n        \"mode\": \"image_generation\"\n
        \   },\n    \"azure/hd/1792-x-1024/dall-e-3\": {\n        \"input_cost_per_pixel\":
        0.00000006539,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"azure\", \n        \"mode\": \"image_generation\"\n    },\n    \"azure/standard/1024-x-1024/dall-e-2\":
        {\n        \"input_cost_per_pixel\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure\", \n        \"mode\": \"image_generation\"\n
        \   },\n    \"azure_ai/deepseek-r1\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        128000,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        0.00000135,\n        \"output_cost_per_token\": 0.0000054,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"source\": \"https://techcommunity.microsoft.com/blog/machinelearningblog/deepseek-r1-improved-performance-higher-limits-and-transparent-pricing/4386367\"\n
        \   },\n    \"azure_ai/deepseek-v3\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        128000,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        0.00000114,\n        \"output_cost_per_token\": 0.00000456,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true,\n        \"source\": \"https://techcommunity.microsoft.com/blog/machinelearningblog/announcing-deepseek-v3-on-azure-ai-foundry-and-github/4390438\"\n
        \   },\n    \"azure_ai/deepseek-v3-0324\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 0.00000114,\n        \"output_cost_per_token\":
        0.00000456,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"source\": \"https://techcommunity.microsoft.com/blog/machinelearningblog/announcing-deepseek-v3-on-azure-ai-foundry-and-github/4390438\"\n
        \   },\n    \"azure_ai/jamba-instruct\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 70000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.0000005,\n        \"output_cost_per_token\":
        0.0000007,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"azure_ai/mistral-nemo\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000015,\n
        \       \"output_cost_per_token\": 0.00000015,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"source\": \"https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-nemo-12b-2407?tab=PlansAndPrice\"\n
        \   },\n    \"azure_ai/mistral-medium-2505\": {\n        \"max_tokens\": 8191,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 8191,\n
        \       \"input_cost_per_token\": 0.0000004,\n        \"output_cost_per_token\":
        0.000002,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure_ai/mistral-large\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000004,\n        \"output_cost_per_token\":
        0.000012,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure_ai/mistral-small\": {\n        \"max_tokens\": 8191,\n
        \       \"max_input_tokens\": 32000,\n        \"max_output_tokens\": 8191,\n
        \       \"input_cost_per_token\": 0.000001,\n        \"output_cost_per_token\":
        0.000003,\n        \"litellm_provider\": \"azure_ai\",\n        \"supports_function_calling\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"azure_ai/mistral-small-2503\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 128000,\n
        \       \"input_cost_per_token\": 0.000001,\n        \"output_cost_per_token\":
        0.000003,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"azure_ai/mistral-large-2407\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000002,\n
        \       \"output_cost_per_token\": 0.000006,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"supports_function_calling\": true,\n        \"mode\":
        \"chat\",\n        \"source\": \"https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/mistral-large-latest\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000002,\n
        \       \"output_cost_per_token\": 0.000006,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"supports_function_calling\": true,\n        \"mode\":
        \"chat\",\n        \"source\": \"https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.mistral-ai-large-2407-offer?tab=Overview\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/ministral-3b\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000004,\n
        \       \"output_cost_per_token\": 0.00000004,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"supports_function_calling\": true,\n        \"mode\":
        \"chat\",\n        \"source\": \"https://azuremarketplace.microsoft.com/en/marketplace/apps/000-000.ministral-3b-2410-offer?tab=Overview\",\n
        \       \"supports_tool_choice\": true\n    },    \n    \"azure_ai/Llama-3.2-11B-Vision-Instruct\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 2048,\n        \"input_cost_per_token\": 0.00000037,\n
        \       \"output_cost_per_token\": 0.00000037,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"mode\": \"chat\",\n        \"source\": \"https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-11b-vision-instruct-offer?tab=Overview\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Llama-3.3-70B-Instruct\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 2048,\n        \"input_cost_per_token\": 0.00000071,\n
        \       \"output_cost_per_token\": 0.00000071,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"supports_function_calling\": true,\n        \"mode\":
        \"chat\",\n        \"source\": \"https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.llama-3-3-70b-instruct-offer?tab=Overview\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Llama-4-Scout-17B-16E-Instruct\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 10000000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.0000002,\n
        \       \"output_cost_per_token\": 0.00000078,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"mode\": \"chat\",\n        \"source\": \"https://azure.microsoft.com/en-us/blog/introducing-the-llama-4-herd-in-azure-ai-foundry-and-azure-databricks/\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Llama-4-Maverick-17B-128E-Instruct-FP8\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.00000141,\n
        \       \"output_cost_per_token\": 0.00000035,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"mode\": \"chat\",\n        \"source\": \"https://azure.microsoft.com/en-us/blog/introducing-the-llama-4-herd-in-azure-ai-foundry-and-azure-databricks/\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Llama-3.2-90B-Vision-Instruct\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 2048,\n        \"input_cost_per_token\": 0.00000204,\n
        \       \"output_cost_per_token\": 0.00000204,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"mode\": \"chat\",\n        \"source\": \"https://azuremarketplace.microsoft.com/en/marketplace/apps/metagenai.meta-llama-3-2-90b-vision-instruct-offer?tab=Overview\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Meta-Llama-3-70B-Instruct\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        2048,\n        \"input_cost_per_token\": 0.0000011,\n        \"output_cost_per_token\":
        0.00000037,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"azure_ai/Meta-Llama-3.1-8B-Instruct\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 2048,\n        \"input_cost_per_token\": 0.0000003,\n
        \       \"output_cost_per_token\": 0.00000061,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"source\":\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-8b-instruct-offer?tab=PlansAndPrice\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Meta-Llama-3.1-70B-Instruct\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 2048,\n        \"input_cost_per_token\": 0.00000268,\n
        \       \"output_cost_per_token\": 0.00000354,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"source\":\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-70b-instruct-offer?tab=PlansAndPrice\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Meta-Llama-3.1-405B-Instruct\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 2048,\n        \"input_cost_per_token\": 0.00000533,\n
        \       \"output_cost_per_token\": 0.000016,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"source\":\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/metagenai.meta-llama-3-1-405b-instruct-offer?tab=PlansAndPrice\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Phi-4-mini-instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000000075,\n
        \       \"output_cost_per_token\": 0.0000003,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"source\": \"https://techcommunity.microsoft.com/blog/Azure-AI-Services-blog/announcing-new-phi-pricing-empowering-your-business-with-small-language-models/4395112\"\n
        \   },\n    \"azure_ai/Phi-4-multimodal-instruct\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000008,\n        \"input_cost_per_audio_token\":
        0.000004,\n        \"output_cost_per_token\": 0.00000032,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_audio_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"source\": \"https://techcommunity.microsoft.com/blog/Azure-AI-Services-blog/announcing-new-phi-pricing-empowering-your-business-with-small-language-models/4395112\"\n
        \   },\n    \"azure_ai/Phi-4\": {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\":
        16384,\n        \"max_output_tokens\": 16384,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.0000005,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_vision\": false,\n
        \       \"source\": \"https://techcommunity.microsoft.com/blog/machinelearningblog/affordable-innovation-unveiling-the-pricing-of-phi-3-slms-on-models-as-a-service/4156495\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"azure_ai/Phi-3.5-mini-instruct\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000013,\n        \"output_cost_per_token\":
        0.00000052,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\":
        \"chat\",\n        \"supports_vision\": false,\n        \"source\": \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Phi-3.5-vision-instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000013,\n
        \       \"output_cost_per_token\": 0.00000052,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_vision\": true,\n
        \       \"source\": \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Phi-3.5-MoE-instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000016,\n
        \       \"output_cost_per_token\": 0.00000064,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_vision\": false,\n
        \       \"source\": \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Phi-3-mini-4k-instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000013,\n        \"output_cost_per_token\":
        0.00000052,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\":
        \"chat\",\n        \"supports_vision\": false,\n        \"source\": \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Phi-3-mini-128k-instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000013,\n
        \       \"output_cost_per_token\": 0.00000052,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_vision\": false,\n
        \       \"source\": \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Phi-3-small-8k-instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000015,\n        \"output_cost_per_token\":
        0.0000006,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\":
        \"chat\",\n        \"supports_vision\": false,\n        \"source\": \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Phi-3-small-128k-instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000015,\n
        \       \"output_cost_per_token\": 0.0000006,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_vision\": false,\n
        \       \"source\": \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Phi-3-medium-4k-instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000017,\n        \"output_cost_per_token\":
        0.00000068,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\":
        \"chat\",\n        \"supports_vision\": false,\n        \"source\": \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/Phi-3-medium-128k-instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000017,\n
        \       \"output_cost_per_token\": 0.00000068,\n        \"litellm_provider\":
        \"azure_ai\",\n        \"mode\": \"chat\",\n        \"supports_vision\": false,\n
        \       \"source\": \"https://azure.microsoft.com/en-us/pricing/details/phi-3/\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"azure_ai/cohere-rerank-v3-multilingual\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"max_query_tokens\": 2048,\n        \"input_cost_per_token\":
        0.0,\n        \"input_cost_per_query\": 0.002,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"rerank\"\n
        \   },\n    \"azure_ai/cohere-rerank-v3-english\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"max_query_tokens\": 2048,\n        \"input_cost_per_token\":
        0.0,\n        \"input_cost_per_query\": 0.002,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"rerank\"\n
        \   },\n    \"azure_ai/Cohere-embed-v3-english\": {\n        \"max_tokens\":
        512,\n        \"max_input_tokens\": 512,\n        \"output_vector_size\":
        1024,\n        \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"embedding\",\n
        \       \"supports_embedding_image_input\": true,\n        \"source\":\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice\"\n
        \   },\n    \"azure_ai/Cohere-embed-v3-multilingual\": {\n        \"max_tokens\":
        512,\n        \"max_input_tokens\": 512,\n        \"output_vector_size\":
        1024,\n        \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"embedding\",\n
        \       \"supports_embedding_image_input\": true,\n        \"source\":\"https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cohere.cohere-embed-v3-english-offer?tab=PlansAndPrice\"\n
        \   },\n    \"azure_ai/embed-v-4-0\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"output_vector_size\": 3072,\n
        \       \"input_cost_per_token\": 0.00000012,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"azure_ai\",\n        \"mode\": \"embedding\",\n
        \       \"supports_embedding_image_input\": true,\n        \"supported_endpoints\":
        [\"/v1/embeddings\"],\n        \"supported_modalities\": [\"text\", \"image\"],\n
        \       \"source\":\"https://azuremarketplace.microsoft.com/pt-br/marketplace/apps/cohere.cohere-embed-4-offer?tab=PlansAndPrice\"\n
        \   },\n    \"babbage-002\": {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\":
        16384,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.0000004,\n        \"output_cost_per_token\": 0.0000004,\n        \"litellm_provider\":
        \"text-completion-openai\",\n        \"mode\": \"completion\"\n    },\n    \"davinci-002\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000002,\n
        \       \"output_cost_per_token\": 0.000002,\n        \"litellm_provider\":
        \"text-completion-openai\",\n        \"mode\": \"completion\"\n    },    \n
        \   \"gpt-3.5-turbo-instruct\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.0000015,\n        \"output_cost_per_token\": 0.000002,\n        \"litellm_provider\":
        \"text-completion-openai\",\n        \"mode\": \"completion\"\n    },\n    \"gpt-3.5-turbo-instruct-0914\":
        {\n        \"max_tokens\": 4097,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        4097,\n        \"input_cost_per_token\": 0.0000015,\n        \"output_cost_per_token\":
        0.000002,\n        \"litellm_provider\": \"text-completion-openai\",\n        \"mode\":
        \"completion\"\n\n    },\n    \"claude-instant-1\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 100000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000163,\n        \"output_cost_per_token\":
        0.00000551,\n        \"litellm_provider\": \"anthropic\",\n        \"mode\":
        \"chat\"\n    },\n    \"mistral/mistral-tiny\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000025,\n        \"output_cost_per_token\":
        0.00000025,\n        \"litellm_provider\": \"mistral\",\n        \"mode\":
        \"chat\",\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"mistral/mistral-small\": {\n        \"max_tokens\": 8191,\n
        \       \"max_input_tokens\": 32000,\n        \"max_output_tokens\": 8191,\n
        \       \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0.0000003,\n        \"litellm_provider\": \"mistral\",\n        \"supports_function_calling\":
        true,\n        \"mode\": \"chat\",\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"mistral/mistral-small-latest\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0.0000003,\n        \"litellm_provider\": \"mistral\",\n        \"supports_function_calling\":
        true,\n        \"mode\": \"chat\",\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"mistral/mistral-medium\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.0000027,\n        \"output_cost_per_token\":
        0.0000081,\n        \"litellm_provider\": \"mistral\",\n        \"mode\":
        \"chat\",\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"mistral/mistral-medium-latest\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.0000027,\n        \"output_cost_per_token\":
        0.0000081,\n        \"litellm_provider\": \"mistral\",\n        \"mode\":
        \"chat\",\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"mistral/mistral-medium-2312\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.0000027,\n        \"output_cost_per_token\":
        0.0000081,\n        \"litellm_provider\": \"mistral\",\n        \"mode\":
        \"chat\",\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"mistral/mistral-large-latest\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 0.000002,\n        \"output_cost_per_token\":
        0.000006,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"mistral/mistral-large-2411\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        0.000002,\n        \"output_cost_per_token\": 0.000006,\n        \"litellm_provider\":
        \"mistral\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"mistral/mistral-large-2402\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000004,\n        \"output_cost_per_token\":
        0.000012,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"mistral/mistral-large-2407\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        0.000003,\n        \"output_cost_per_token\": 0.000009,\n        \"litellm_provider\":
        \"mistral\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"mistral/pixtral-large-latest\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 0.000002,\n        \"output_cost_per_token\":
        0.000006,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"mistral/pixtral-large-2411\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 0.000002,\n        \"output_cost_per_token\":
        0.000006,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"mistral/pixtral-12b-2409\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 0.00000015,\n        \"output_cost_per_token\":
        0.00000015,\n        \"litellm_provider\": \"mistral\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"mistral/open-mistral-7b\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000025,\n        \"output_cost_per_token\":
        0.00000025,\n        \"litellm_provider\": \"mistral\",\n        \"mode\":
        \"chat\",\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"mistral/open-mixtral-8x7b\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.0000007,\n        \"output_cost_per_token\":
        0.0000007,\n        \"litellm_provider\": \"mistral\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"mistral/open-mixtral-8x22b\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 65336,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000002,\n        \"output_cost_per_token\":
        0.000006,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"mistral/codestral-latest\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000001,\n        \"output_cost_per_token\":
        0.000003,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"mistral/codestral-2405\": {\n        \"max_tokens\": 8191,\n
        \       \"max_input_tokens\": 32000,\n        \"max_output_tokens\": 8191,\n
        \       \"input_cost_per_token\": 0.000001,\n        \"output_cost_per_token\":
        0.000003,\n        \"litellm_provider\": \"mistral\",\n        \"mode\": \"chat\",\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"mistral/open-mistral-nemo\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\":  0.0000003,\n        \"output_cost_per_token\":
        0.0000003,\n        \"litellm_provider\": \"mistral\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://mistral.ai/technology/\",\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"mistral/open-mistral-nemo-2407\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        \ 0.0000003,\n        \"output_cost_per_token\": 0.0000003,\n        \"litellm_provider\":
        \"mistral\",\n        \"mode\": \"chat\",\n        \"source\": \"https://mistral.ai/technology/\",\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"mistral/open-codestral-mamba\": {\n        \"max_tokens\":
        256000,\n        \"max_input_tokens\": 256000,\n        \"max_output_tokens\":
        256000,\n        \"input_cost_per_token\": 0.00000025,\n        \"output_cost_per_token\":
        0.00000025,\n        \"litellm_provider\": \"mistral\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://mistral.ai/technology/\",\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"mistral/codestral-mamba-latest\":
        {\n        \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n
        \       \"max_output_tokens\": 256000,\n        \"input_cost_per_token\":
        0.00000025,\n        \"output_cost_per_token\": 0.00000025,\n        \"litellm_provider\":
        \"mistral\",\n        \"mode\": \"chat\",\n        \"source\": \"https://mistral.ai/technology/\",\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"mistral/devstral-small-2505\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0.0000003,\n        \"litellm_provider\": \"mistral\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://mistral.ai/news/devstral\",\n        \"supports_function_calling\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"mistral/mistral-embed\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 8192,\n        \"input_cost_per_token\": 0.0000001,\n
        \       \"litellm_provider\": \"mistral\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"deepseek/deepseek-reasoner\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 65536,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 0.00000055,\n        \"input_cost_per_token_cache_hit\":
        0.00000014,\n        \"output_cost_per_token\": 0.00000219,\n        \"litellm_provider\":
        \"deepseek\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true, \n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_prompt_caching\":
        true\n    },\n    \"deepseek/deepseek-chat\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 65536,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 0.00000027,\n        \"input_cost_per_token_cache_hit\":
        0.00000007,\n        \"cache_read_input_token_cost\": 0.00000007,\n        \"cache_creation_input_token_cost\":
        0.0,\n        \"output_cost_per_token\": 0.0000011,\n        \"litellm_provider\":
        \"deepseek\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true, \n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_prompt_caching\": true\n    },\n    \"codestral/codestral-latest\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000000,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"codestral\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://docs.mistral.ai/capabilities/code_generation/\",\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"codestral/codestral-2405\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000000,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"codestral\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://docs.mistral.ai/capabilities/code_generation/\",\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"text-completion-codestral/codestral-latest\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000000,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"text-completion-codestral\",\n
        \       \"mode\": \"completion\",\n        \"source\": \"https://docs.mistral.ai/capabilities/code_generation/\"\n
        \   },\n    \"text-completion-codestral/codestral-2405\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000000,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"text-completion-codestral\",\n
        \       \"mode\": \"completion\",\n        \"source\": \"https://docs.mistral.ai/capabilities/code_generation/\"\n
        \   },\n    \"xai/grok-beta\": {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\":
        131072,\n        \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        0.000005,\n        \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"xai/grok-2-vision-1212\": {\n        \"max_tokens\": 32768,\n
        \       \"max_input_tokens\": 32768,\n        \"max_output_tokens\": 32768,\n
        \       \"input_cost_per_token\": 0.000002,\n        \"input_cost_per_image\":
        0.000002,\n        \"output_cost_per_token\": 0.00001,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"xai/grok-2-vision-latest\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 0.000002,\n        \"input_cost_per_image\":
        0.000002,\n        \"output_cost_per_token\": 0.00001,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"xai/grok-2-vision\": {\n        \"max_tokens\": 32768,\n
        \       \"max_input_tokens\": 32768,\n        \"max_output_tokens\": 32768,\n
        \       \"input_cost_per_token\": 0.000002,\n        \"input_cost_per_image\":
        0.000002,\n        \"output_cost_per_token\": 0.00001,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"xai/grok-3\": {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\":
        131072,\n        \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        0.000003,\n        \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://x.ai/api#pricing\"\n    },\n    \"xai/grok-3-beta\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        0.000003,\n        \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://x.ai/api#pricing\"\n    },\n    \"xai/grok-3-fast-beta\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        0.000005,\n        \"output_cost_per_token\": 0.000025,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://x.ai/api#pricing\"\n    },\n    \"xai/grok-3-fast-latest\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        0.000005,\n        \"output_cost_per_token\": 0.000025,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://x.ai/api#pricing\"\n    },\n    \"xai/grok-3-mini-beta\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        0.0000003,\n        \"output_cost_per_token\": 0.0000005,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_response_schema\": false,\n        \"source\": \"https://x.ai/api#pricing\"\n
        \   },\n    \"xai/grok-3-mini-fast-beta\": {\n        \"max_tokens\": 131072,\n
        \       \"max_input_tokens\": 131072,\n        \"max_output_tokens\": 131072,\n
        \       \"input_cost_per_token\": 0.0000006,\n        \"output_cost_per_token\":
        0.000004,\n        \"litellm_provider\": \"xai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_response_schema\":
        false,\n        \"source\": \"https://x.ai/api#pricing\"\n    },\n    \"xai/grok-3-mini-fast-latest\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        0.0000006,\n        \"output_cost_per_token\": 0.000004,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_reasoning\": true,\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": false,\n        \"source\": \"https://x.ai/api#pricing\"\n
        \   },\n    \"xai/grok-vision-beta\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        0.000005,\n        \"input_cost_per_image\": 0.000005,\n        \"output_cost_per_token\":
        0.000015,\n        \"litellm_provider\": \"xai\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"xai/grok-2-1212\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        0.000002,\n        \"output_cost_per_token\": 0.00001,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"xai/grok-2\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        0.000002,\n        \"output_cost_per_token\": 0.00001,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"xai/grok-2-latest\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        0.000002,\n        \"output_cost_per_token\": 0.00001,\n        \"litellm_provider\":
        \"xai\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"deepseek/deepseek-coder\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000014,\n
        \       \"input_cost_per_token_cache_hit\": 0.000000014,\n        \"output_cost_per_token\":
        0.00000028,\n        \"litellm_provider\": \"deepseek\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true, \n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_prompt_caching\":
        true\n    },\n    \"groq/deepseek-r1-distill-llama-70b\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 7.5e-07,\n        \"output_cost_per_token\":
        9.9e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"groq/llama-3.3-70b-versatile\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 5.9e-07,\n        \"output_cost_per_token\":
        7.9e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"groq/llama-3.3-70b-specdec\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 5.9e-07,\n        \"output_cost_per_token\":
        9.9e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true,\n        \"deprecation_date\": \"2025-04-14\"\n
        \   },\n    \"groq/llama-guard-3-8b\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 8192,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        2e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\"\n
        \   },\n    \"groq/llama2-70b-4096\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        4096,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.00000070,\n        \"output_cost_per_token\": 0.00000080,\n        \"litellm_provider\":
        \"groq\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"groq/llama3-8b-8192\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 8192,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 5e-08,\n        \"output_cost_per_token\":
        8e-08,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"groq/llama-3.2-1b-preview\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 4e-08,\n        \"output_cost_per_token\":
        4e-08,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2025-04-14\"\n    },\n    \"groq/llama-3.2-3b-preview\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 6e-08,\n        \"output_cost_per_token\":
        6e-08,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2025-04-14\"\n    },\n    \"groq/llama-3.2-11b-text-preview\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 1.8e-07,\n        \"output_cost_per_token\":
        1.8e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2024-10-28\"\n    },\n    \"groq/llama-3.2-11b-vision-preview\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 1.8e-07,\n        \"output_cost_per_token\":
        1.8e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true,\n        \"deprecation_date\": \"2025-04-14\"\n    },\n    \"groq/llama-3.2-90b-text-preview\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 9e-07,\n        \"output_cost_per_token\":
        9e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2024-11-25\"\n    },\n    \"groq/llama-3.2-90b-vision-preview\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 9e-07,\n        \"output_cost_per_token\":
        9e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true,\n        \"deprecation_date\": \"2025-04-14\"\n    },\n    \"groq/llama3-70b-8192\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 5.9e-07,\n        \"output_cost_per_token\":
        7.9e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"groq/llama-3.1-8b-instant\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 5e-08,\n        \"output_cost_per_token\":
        8e-08,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"groq/llama-3.1-70b-versatile\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 5.9e-07,\n        \"output_cost_per_token\":
        7.9e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2025-01-24\"\n    },\n    \"groq/llama-3.1-405b-reasoning\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.00000059,\n        \"output_cost_per_token\":
        0.00000079,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"groq/meta-llama/llama-4-scout-17b-16e-instruct\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 1.1e-07,\n
        \       \"output_cost_per_token\": 3.4e-07,\n        \"litellm_provider\":
        \"groq\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"groq/meta-llama/llama-4-maverick-17b-128e-instruct\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 2e-07,\n
        \       \"output_cost_per_token\": 6e-07,\n        \"litellm_provider\": \"groq\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"groq/mistral-saba-24b\": {\n        \"max_tokens\": 32000,\n
        \       \"max_input_tokens\": 32000,\n        \"max_output_tokens\": 32000,\n
        \       \"input_cost_per_token\": 7.9e-07,\n        \"output_cost_per_token\":
        7.9e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\"\n
        \   },\n    \"groq/mixtral-8x7b-32768\": {\n        \"max_tokens\": 32768,\n
        \       \"max_input_tokens\": 32768,\n        \"max_output_tokens\": 32768,\n
        \       \"input_cost_per_token\": 2.4e-07,\n        \"output_cost_per_token\":
        2.4e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2025-03-20\"\n    },\n    \"groq/gemma-7b-it\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 7e-08,\n        \"output_cost_per_token\":
        7e-08,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2024-12-18\"\n    },\n    \"groq/gemma2-9b-it\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 2e-07,\n        \"output_cost_per_token\":
        2e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": false,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": false\n    },\n    \"groq/llama3-groq-70b-8192-tool-use-preview\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 8.9e-07,\n        \"output_cost_per_token\":
        8.9e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2025-01-06\"\n    },\n    \"groq/llama3-groq-8b-8192-tool-use-preview\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 1.9e-07,\n        \"output_cost_per_token\":
        1.9e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"deprecation_date\":
        \"2025-01-06\"\n    },\n    \"groq/qwen-qwq-32b\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 2.9e-07,\n        \"output_cost_per_token\":
        3.9e-07,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"groq/playai-tts\": {\n        \"max_tokens\": 10000,\n
        \       \"max_input_tokens\": 10000,\n        \"max_output_tokens\": 10000,\n
        \       \"input_cost_per_character\": 5e-05,\n        \"litellm_provider\":
        \"groq\",\n        \"mode\": \"audio_speech\"\n    },\n    \"groq/whisper-large-v3\":
        {\n        \"input_cost_per_second\": 3.083e-05,\n        \"output_cost_per_second\":
        0.0,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"audio_transcription\"\n
        \   },\n    \"groq/whisper-large-v3-turbo\": {\n        \"input_cost_per_second\":
        1.111e-05,\n        \"output_cost_per_second\": 0.0,\n        \"litellm_provider\":
        \"groq\",\n        \"mode\": \"audio_transcription\"\n    },\n    \"groq/distil-whisper-large-v3-en\":
        {\n        \"input_cost_per_second\": 5.56e-06,\n        \"output_cost_per_second\":
        0.0,\n        \"litellm_provider\": \"groq\",\n        \"mode\": \"audio_transcription\"\n
        \   },\n    \"cerebras/llama3.1-8b\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 128000,\n
        \       \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0.0000001,\n        \"litellm_provider\": \"cerebras\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"cerebras/llama3.1-70b\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 128000,\n
        \       \"input_cost_per_token\": 0.0000006,\n        \"output_cost_per_token\":
        0.0000006,\n        \"litellm_provider\": \"cerebras\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"cerebras/llama-3.3-70b\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 128000,\n
        \       \"input_cost_per_token\": 0.00000085,\n        \"output_cost_per_token\":
        0.0000012,\n        \"litellm_provider\": \"cerebras\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"friendliai/meta-llama-3.1-8b-instruct\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0.0000001,\n        \"litellm_provider\": \"friendliai\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"friendliai/meta-llama-3.1-70b-instruct\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0000006,\n        \"output_cost_per_token\":
        0.0000006,\n        \"litellm_provider\": \"friendliai\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"claude-instant-1.2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.000000163,\n
        \       \"output_cost_per_token\": 0.000000551,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"claude-2\": {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\":
        100000,\n        \"max_output_tokens\": 8191,\n        \"input_cost_per_token\":
        0.000008,\n        \"output_cost_per_token\": 0.000024,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\"\n    },\n    \"claude-2.1\": {\n
        \       \"max_tokens\": 8191,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"anthropic\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"claude-3-haiku-20240307\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000025,\n
        \       \"output_cost_per_token\": 0.00000125,\n        \"cache_creation_input_token_cost\":
        0.0000003,\n        \"cache_read_input_token_cost\": 0.00000003,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        264,\n        \"supports_assistant_prefill\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"deprecation_date\":
        \"2025-03-01\",\n        \"supports_tool_choice\": true\n    },\n    \"claude-3-5-haiku-20241022\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.0000008,\n
        \       \"output_cost_per_token\": 0.000004,\n        \"cache_creation_input_token_cost\":
        0.000001,\n        \"cache_read_input_token_cost\": 0.00000008,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 1e-2, \n            \"search_context_size_medium\":
        1e-2,\n            \"search_context_size_high\": 1e-2\n        },\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        264,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"deprecation_date\": \"2025-10-01\",\n        \"supports_tool_choice\":
        true,\n        \"supports_web_search\": true\n    },\n    \"claude-3-5-haiku-latest\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.000001,\n
        \       \"output_cost_per_token\": 0.000005,\n        \"cache_creation_input_token_cost\":
        0.00000125,\n        \"cache_read_input_token_cost\": 0.0000001,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 1e-2, \n            \"search_context_size_medium\":
        1e-2,\n            \"search_context_size_high\": 1e-2\n        },\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        264,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"deprecation_date\": \"2025-10-01\",\n        \"supports_tool_choice\":
        true,\n        \"supports_web_search\": true\n    },\n    \"claude-3-opus-latest\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000015,\n
        \       \"output_cost_per_token\": 0.000075,\n        \"cache_creation_input_token_cost\":
        0.00001875,\n        \"cache_read_input_token_cost\": 0.0000015,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        395,\n        \"supports_assistant_prefill\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"deprecation_date\":
        \"2025-03-01\",\n        \"supports_tool_choice\": true\n    },\n    \"claude-3-opus-20240229\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000015,\n
        \       \"output_cost_per_token\": 0.000075,\n        \"cache_creation_input_token_cost\":
        0.00001875,\n        \"cache_read_input_token_cost\": 0.0000015,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        395,\n        \"supports_assistant_prefill\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"deprecation_date\":
        \"2025-03-01\",\n        \"supports_tool_choice\": true\n    },\n    \"claude-3-sonnet-20240229\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"deprecation_date\":
        \"2025-07-21\",\n        \"supports_tool_choice\": true\n    },\n    \"claude-3-5-sonnet-latest\":
        {\n        \"supports_computer_use\": true,\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000015,\n        \"cache_creation_input_token_cost\": 0.00000375,\n        \"cache_read_input_token_cost\":
        0.0000003,\n        \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        1e-2, \n            \"search_context_size_medium\": 1e-2,\n            \"search_context_size_high\":
        1e-2\n        },\n        \"litellm_provider\": \"anthropic\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"tool_use_system_prompt_tokens\": 159,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"deprecation_date\":
        \"2025-06-01\",\n        \"supports_tool_choice\": true,\n        \"supports_web_search\":
        true\n    },\n    \"claude-3-5-sonnet-20240620\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000015,\n        \"cache_creation_input_token_cost\": 0.00000375,\n        \"cache_read_input_token_cost\":
        0.0000003,\n        \"litellm_provider\": \"anthropic\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"tool_use_system_prompt_tokens\": 159,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"deprecation_date\":
        \"2025-06-01\",\n        \"supports_tool_choice\": true\n    },\n    \"claude-opus-4-20250514\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 32000,\n        \"input_cost_per_token\": 15e-6,\n
        \       \"output_cost_per_token\": 75e-6,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 1e-2, \n            \"search_context_size_medium\":
        1e-2,\n            \"search_context_size_high\": 1e-2\n        },\n        \"cache_creation_input_token_cost\":
        18.75e-6,\n        \"cache_read_input_token_cost\": 1.5e-6,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"claude-sonnet-4-20250514\":
        {\n        \"max_tokens\": 64000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 64000,\n        \"input_cost_per_token\": 3e-6,\n
        \       \"output_cost_per_token\": 15e-6,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 1e-2, \n            \"search_context_size_medium\":
        1e-2,\n            \"search_context_size_high\": 1e-2\n        },\n        \"cache_creation_input_token_cost\":
        3.75e-6,\n        \"cache_read_input_token_cost\": 0.3e-6,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"claude-3-7-sonnet-latest\":
        {\n        \"supports_computer_use\": true,\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 128000,\n
        \       \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000015,\n        \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        1e-2, \n            \"search_context_size_medium\": 1e-2,\n            \"search_context_size_high\":
        1e-2\n        },\n        \"cache_creation_input_token_cost\": 0.00000375,\n
        \       \"cache_read_input_token_cost\": 0.0000003,\n        \"litellm_provider\":
        \"anthropic\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"deprecation_date\": \"2025-06-01\",\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"claude-3-7-sonnet-20250219\":
        {\n        \"supports_computer_use\": true,\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 128000,\n
        \       \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000015,\n        \"cache_creation_input_token_cost\": 0.00000375,\n        \"cache_read_input_token_cost\":
        0.0000003,\n        \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        1e-2, \n            \"search_context_size_medium\": 1e-2,\n            \"search_context_size_high\":
        1e-2\n        },\n        \"litellm_provider\": \"anthropic\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"tool_use_system_prompt_tokens\": 159,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"deprecation_date\":
        \"2026-02-01\",\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_web_search\": true\n    },\n    \"claude-3-5-sonnet-20241022\":
        {\n        \"supports_computer_use\": true,\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000015,\n        \"cache_creation_input_token_cost\": 0.00000375,\n        \"cache_read_input_token_cost\":
        0.0000003,\n        \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        1e-2, \n            \"search_context_size_medium\": 1e-2,\n            \"search_context_size_high\":
        1e-2\n        },\n        \"litellm_provider\": \"anthropic\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"tool_use_system_prompt_tokens\": 159,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"deprecation_date\":
        \"2025-10-01\",\n        \"supports_tool_choice\": true,\n        \"supports_web_search\":
        true\n    },\n    \"text-bison\": {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 2048,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"text-bison@001\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"text-bison@002\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"text-bison32k\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"text-bison32k@002\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"text-unicorn\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.00001,\n        \"output_cost_per_token\": 0.000028,\n        \"litellm_provider\":
        \"vertex_ai-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"text-unicorn@001\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.00001,\n        \"output_cost_per_token\": 0.000028,\n        \"litellm_provider\":
        \"vertex_ai-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"chat-bison\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-chat-models\",\n        \"mode\": \"chat\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"chat-bison@001\": {\n
        \       \"max_tokens\": 4096,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000000125,\n        \"output_cost_per_token\":
        0.000000125,\n        \"input_cost_per_character\": 0.00000025,\n        \"output_cost_per_character\":
        0.0000005,\n        \"litellm_provider\": \"vertex_ai-chat-models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"chat-bison@002\": {\n
        \       \"max_tokens\": 4096,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000000125,\n        \"output_cost_per_token\":
        0.000000125,\n        \"input_cost_per_character\": 0.00000025,\n        \"output_cost_per_character\":
        0.0000005,\n        \"litellm_provider\": \"vertex_ai-chat-models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"deprecation_date\": \"2025-04-09\",\n        \"supports_tool_choice\":
        true\n    },\n    \"chat-bison-32k\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        32000,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-chat-models\",\n        \"mode\": \"chat\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"chat-bison-32k@002\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.000000125,\n        \"output_cost_per_token\":
        0.000000125,\n        \"input_cost_per_character\": 0.00000025,\n        \"output_cost_per_character\":
        0.0000005,\n        \"litellm_provider\": \"vertex_ai-chat-models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"code-bison\": {\n        \"max_tokens\":
        1024,\n        \"max_input_tokens\": 6144,\n        \"max_output_tokens\":
        1024,\n        \"input_cost_per_token\": 0.000000125,\n        \"output_cost_per_token\":
        0.000000125,\n        \"input_cost_per_character\": 0.00000025,\n        \"output_cost_per_character\":
        0.0000005,\n        \"litellm_provider\": \"vertex_ai-code-text-models\",\n
        \       \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"code-bison@001\": {\n
        \       \"max_tokens\": 1024,\n        \"max_input_tokens\": 6144,\n        \"max_output_tokens\":
        1024,\n        \"input_cost_per_token\": 0.000000125,\n        \"output_cost_per_token\":
        0.000000125,\n        \"input_cost_per_character\": 0.00000025,\n        \"output_cost_per_character\":
        0.0000005,\n        \"litellm_provider\": \"vertex_ai-code-text-models\",\n
        \       \"mode\": \"completion\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-bison@002\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        6144,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-bison32k\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        6144,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-bison-32k@002\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        6144,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"input_cost_per_character\":
        0.00000025,\n        \"output_cost_per_character\": 0.0000005,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-gecko@001\": {\n        \"max_tokens\": 64,\n        \"max_input_tokens\":
        2048,\n        \"max_output_tokens\": 64,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-gecko@002\": {\n        \"max_tokens\": 64,\n        \"max_input_tokens\":
        2048,\n        \"max_output_tokens\": 64,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-gecko\": {\n        \"max_tokens\": 64,\n        \"max_input_tokens\":
        2048,\n        \"max_output_tokens\": 64,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"code-gecko-latest\": {\n        \"max_tokens\": 64,\n        \"max_input_tokens\":
        2048,\n        \"max_output_tokens\": 64,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"litellm_provider\":
        \"vertex_ai-code-text-models\",\n        \"mode\": \"completion\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"codechat-bison@latest\": {\n        \"max_tokens\": 1024,\n
        \       \"max_input_tokens\": 6144,\n        \"max_output_tokens\": 1024,\n
        \       \"input_cost_per_token\": 0.000000125,\n        \"output_cost_per_token\":
        0.000000125,\n        \"input_cost_per_character\": 0.00000025,\n        \"output_cost_per_character\":
        0.0000005,\n        \"litellm_provider\": \"vertex_ai-code-chat-models\",\n
        \       \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"codechat-bison\": {\n
        \       \"max_tokens\": 1024,\n        \"max_input_tokens\": 6144,\n        \"max_output_tokens\":
        1024,\n        \"input_cost_per_token\": 0.000000125,\n        \"output_cost_per_token\":
        0.000000125,\n        \"input_cost_per_character\": 0.00000025,\n        \"output_cost_per_character\":
        0.0000005,\n        \"litellm_provider\": \"vertex_ai-code-chat-models\",\n
        \       \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"codechat-bison@001\":
        {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\": 6144,\n        \"max_output_tokens\":
        1024,\n        \"input_cost_per_token\": 0.000000125,\n        \"output_cost_per_token\":
        0.000000125,\n        \"input_cost_per_character\": 0.00000025,\n        \"output_cost_per_character\":
        0.0000005,\n        \"litellm_provider\": \"vertex_ai-code-chat-models\",\n
        \       \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"codechat-bison@002\":
        {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\": 6144,\n        \"max_output_tokens\":
        1024,\n        \"input_cost_per_token\": 0.000000125,\n        \"output_cost_per_token\":
        0.000000125,\n        \"input_cost_per_character\": 0.00000025,\n        \"output_cost_per_character\":
        0.0000005,\n        \"litellm_provider\": \"vertex_ai-code-chat-models\",\n
        \       \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"codechat-bison-32k\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.000000125,\n        \"output_cost_per_token\":
        0.000000125,\n        \"input_cost_per_character\": 0.00000025,\n        \"output_cost_per_character\":
        0.0000005,\n        \"litellm_provider\": \"vertex_ai-code-chat-models\",\n
        \       \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"codechat-bison-32k@002\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.000000125,\n        \"output_cost_per_token\":
        0.000000125,\n        \"input_cost_per_character\": 0.00000025,\n        \"output_cost_per_character\":
        0.0000005,\n        \"litellm_provider\": \"vertex_ai-code-chat-models\",\n
        \       \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"meta_llama/Llama-4-Scout-17B-16E-Instruct-FP8\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 10000000,\n
        \       \"max_output_tokens\": 4028,\n        \"litellm_provider\": \"meta_llama\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": false,\n
        \       \"source\": \"https://llama.developer.meta.com/docs/models\",\n        \"supports_tool_choice\":
        false,\n        \"supported_modalities\": [\"text\", \"image\"],\n        \"supported_output_modalities\":
        [\"text\"]\n    },\n    \"meta_llama/Llama-4-Maverick-17B-128E-Instruct-FP8\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 4028,\n        \"litellm_provider\": \"meta_llama\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": false,\n
        \       \"source\": \"https://llama.developer.meta.com/docs/models\",\n        \"supports_tool_choice\":
        false,\n        \"supported_modalities\": [\"text\", \"image\"],\n        \"supported_output_modalities\":
        [\"text\"]\n    },\n    \"meta_llama/Llama-3.3-70B-Instruct\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4028,\n        \"litellm_provider\": \"meta_llama\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": false,\n        \"source\": \"https://llama.developer.meta.com/docs/models\",\n
        \       \"supports_tool_choice\": false,\n        \"supported_modalities\":
        [\"text\"],\n        \"supported_output_modalities\": [\"text\"]\n    },\n
        \   \"meta_llama/Llama-3.3-8B-Instruct\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4028,\n
        \       \"litellm_provider\": \"meta_llama\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": false,\n        \"source\": \"https://llama.developer.meta.com/docs/models\",\n
        \       \"supports_tool_choice\": false,\n        \"supported_modalities\":
        [\"text\"],\n        \"supported_output_modalities\": [\"text\"]\n    },\n
        \   \"gemini-pro\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        32760,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_image\":
        0.0025,\n        \"input_cost_per_video_per_second\": 0.002,\n        \"input_cost_per_token\":
        0.0000005, \n        \"input_cost_per_character\": 0.000000125, \n        \"output_cost_per_token\":
        0.0000015,\n        \"output_cost_per_character\": 0.000000375,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini-1.0-pro\": {
        \n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 32760,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_image\": 0.0025,\n        \"input_cost_per_video_per_second\":
        0.002,\n        \"input_cost_per_token\": 0.0000005, \n        \"input_cost_per_character\":
        0.000000125, \n        \"output_cost_per_token\": 0.0000015,\n        \"output_cost_per_character\":
        0.000000375,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing#google_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini-1.0-pro-001\":
        { \n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 32760,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_image\": 0.0025,\n
        \       \"input_cost_per_video_per_second\": 0.002,\n        \"input_cost_per_token\":
        0.0000005, \n        \"input_cost_per_character\": 0.000000125, \n        \"output_cost_per_token\":
        0.0000015,\n        \"output_cost_per_character\": 0.000000375,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"deprecation_date\": \"2025-04-09\",\n        \"supports_tool_choice\":
        true\n    },\n    \"gemini-1.0-ultra\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 8192,\n        \"max_output_tokens\": 2048,\n
        \       \"input_cost_per_image\": 0.0025,\n        \"input_cost_per_video_per_second\":
        0.002,\n        \"input_cost_per_token\": 0.0000005, \n        \"input_cost_per_character\":
        0.000000125, \n        \"output_cost_per_token\": 0.0000015,\n        \"output_cost_per_character\":
        0.000000375,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"source\": \"As of Jun, 2024. There is no available doc on vertex
        ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens
        info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini-1.0-ultra-001\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        2048,\n        \"input_cost_per_image\": 0.0025,\n        \"input_cost_per_video_per_second\":
        0.002,\n        \"input_cost_per_token\": 0.0000005, \n        \"input_cost_per_character\":
        0.000000125, \n        \"output_cost_per_token\": 0.0000015,\n        \"output_cost_per_character\":
        0.000000375,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"source\": \"As of Jun, 2024. There is no available doc on vertex
        ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens
        info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini-1.0-pro-002\":
        { \n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 32760,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_image\": 0.0025,\n
        \       \"input_cost_per_video_per_second\": 0.002,\n        \"input_cost_per_token\":
        0.0000005, \n        \"input_cost_per_character\": 0.000000125, \n        \"output_cost_per_token\":
        0.0000015,\n        \"output_cost_per_character\": 0.000000375,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"deprecation_date\": \"2025-04-09\",\n        \"supports_tool_choice\":
        true\n    },\n    \"gemini-1.5-pro\": { \n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 2097152,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_image\": 0.00032875,\n        \"input_cost_per_audio_per_second\":
        0.00003125,\n        \"input_cost_per_video_per_second\": 0.00032875,\n        \"input_cost_per_token\":
        0.00000125,\n        \"input_cost_per_character\": 0.0000003125,\n        \"input_cost_per_image_above_128k_tokens\":
        0.0006575, \n        \"input_cost_per_video_per_second_above_128k_tokens\":
        0.0006575, \n        \"input_cost_per_audio_per_second_above_128k_tokens\":
        0.0000625, \n        \"input_cost_per_token_above_128k_tokens\": 0.0000025,
        \n        \"input_cost_per_character_above_128k_tokens\": 0.000000625,\n        \"output_cost_per_token\":
        0.000005,\n        \"output_cost_per_character\": 0.00000125,\n        \"output_cost_per_token_above_128k_tokens\":
        0.00001,\n        \"output_cost_per_character_above_128k_tokens\": 0.0000025,\n
        \       \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true, \n        \"supports_response_schema\":
        true, \n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini-1.5-pro-002\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        2097152,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_image\":
        0.00032875,\n        \"input_cost_per_audio_per_second\": 0.00003125,\n        \"input_cost_per_video_per_second\":
        0.00032875,\n        \"input_cost_per_token\": 0.00000125,\n        \"input_cost_per_character\":
        0.0000003125,\n        \"input_cost_per_image_above_128k_tokens\": 0.0006575,
        \n        \"input_cost_per_video_per_second_above_128k_tokens\": 0.0006575,
        \n        \"input_cost_per_audio_per_second_above_128k_tokens\": 0.0000625,
        \n        \"input_cost_per_token_above_128k_tokens\": 0.0000025, \n        \"input_cost_per_character_above_128k_tokens\":
        0.000000625,\n        \"output_cost_per_token\": 0.000005,\n        \"output_cost_per_character\":
        0.00000125,\n        \"output_cost_per_token_above_128k_tokens\": 0.00001,\n
        \       \"output_cost_per_character_above_128k_tokens\": 0.0000025,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_vision\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true, \n        \"supports_response_schema\":
        true, \n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-pro\",\n
        \       \"deprecation_date\": \"2025-09-24\"\n    },\n    \"gemini-1.5-pro-001\":
        { \n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_image\": 0.00032875,\n
        \       \"input_cost_per_audio_per_second\": 0.00003125,\n        \"input_cost_per_video_per_second\":
        0.00032875,\n        \"input_cost_per_token\": 0.00000125,\n        \"input_cost_per_character\":
        0.0000003125,\n        \"input_cost_per_image_above_128k_tokens\": 0.0006575,
        \n        \"input_cost_per_video_per_second_above_128k_tokens\": 0.0006575,
        \n        \"input_cost_per_audio_per_second_above_128k_tokens\": 0.0000625,
        \n        \"input_cost_per_token_above_128k_tokens\": 0.0000025, \n        \"input_cost_per_character_above_128k_tokens\":
        0.000000625,\n        \"output_cost_per_token\": 0.000005,\n        \"output_cost_per_character\":
        0.00000125,\n        \"output_cost_per_token_above_128k_tokens\": 0.00001,\n
        \       \"output_cost_per_character_above_128k_tokens\": 0.0000025,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_vision\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true, \n        \"supports_response_schema\":
        true, \n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"deprecation_date\": \"2025-05-24\"\n    },\n    \"gemini-1.5-pro-preview-0514\":
        { \n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_image\": 0.00032875,\n
        \       \"input_cost_per_audio_per_second\": 0.00003125,\n        \"input_cost_per_video_per_second\":
        0.00032875,\n        \"input_cost_per_token\": 0.000000078125, \n        \"input_cost_per_character\":
        0.0000003125, \n        \"input_cost_per_image_above_128k_tokens\": 0.0006575,
        \n        \"input_cost_per_video_per_second_above_128k_tokens\": 0.0006575,
        \n        \"input_cost_per_audio_per_second_above_128k_tokens\": 0.0000625,
        \n        \"input_cost_per_token_above_128k_tokens\": 0.00000015625, \n        \"input_cost_per_character_above_128k_tokens\":
        0.000000625, \n        \"output_cost_per_token\": 0.0000003125,\n        \"output_cost_per_character\":
        0.00000125,\n        \"output_cost_per_token_above_128k_tokens\": 0.000000625,\n
        \       \"output_cost_per_character_above_128k_tokens\": 0.0000025,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true, \n        \"supports_response_schema\": true, \n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini-1.5-pro-preview-0215\": { \n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 1000000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_image\": 0.00032875,\n        \"input_cost_per_audio_per_second\":
        0.00003125,\n        \"input_cost_per_video_per_second\": 0.00032875,\n        \"input_cost_per_token\":
        0.000000078125, \n        \"input_cost_per_character\": 0.0000003125, \n        \"input_cost_per_image_above_128k_tokens\":
        0.0006575, \n        \"input_cost_per_video_per_second_above_128k_tokens\":
        0.0006575, \n        \"input_cost_per_audio_per_second_above_128k_tokens\":
        0.0000625, \n        \"input_cost_per_token_above_128k_tokens\": 0.00000015625,
        \n        \"input_cost_per_character_above_128k_tokens\": 0.000000625, \n
        \       \"output_cost_per_token\": 0.0000003125,\n        \"output_cost_per_character\":
        0.00000125,\n        \"output_cost_per_token_above_128k_tokens\": 0.000000625,\n
        \       \"output_cost_per_character_above_128k_tokens\": 0.0000025,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true, \n        \"supports_response_schema\": true, \n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini-1.5-pro-preview-0409\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 1000000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_image\": 0.00032875,\n        \"input_cost_per_audio_per_second\":
        0.00003125,\n        \"input_cost_per_video_per_second\": 0.00032875,\n        \"input_cost_per_token\":
        0.000000078125, \n        \"input_cost_per_character\": 0.0000003125, \n        \"input_cost_per_image_above_128k_tokens\":
        0.0006575, \n        \"input_cost_per_video_per_second_above_128k_tokens\":
        0.0006575, \n        \"input_cost_per_audio_per_second_above_128k_tokens\":
        0.0000625, \n        \"input_cost_per_token_above_128k_tokens\": 0.00000015625,
        \n        \"input_cost_per_character_above_128k_tokens\": 0.000000625, \n
        \       \"output_cost_per_token\": 0.0000003125,\n        \"output_cost_per_character\":
        0.00000125,\n        \"output_cost_per_token_above_128k_tokens\": 0.000000625,\n
        \       \"output_cost_per_character_above_128k_tokens\": 0.0000025,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_response_schema\":
        true, \n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini-1.5-flash\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        1000000,\n        \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_image\": 0.00002,\n
        \       \"input_cost_per_video_per_second\": 0.00002,\n        \"input_cost_per_audio_per_second\":
        0.000002,\n        \"input_cost_per_token\": 0.000000075,\n        \"input_cost_per_character\":
        0.00000001875, \n        \"input_cost_per_token_above_128k_tokens\": 0.000001,
        \n        \"input_cost_per_character_above_128k_tokens\": 0.00000025, \n        \"input_cost_per_image_above_128k_tokens\":
        0.00004,\n        \"input_cost_per_video_per_second_above_128k_tokens\": 0.00004,\n
        \       \"input_cost_per_audio_per_second_above_128k_tokens\": 0.000004,\n
        \       \"output_cost_per_token\": 0.0000003,\n        \"output_cost_per_character\":
        0.000000075,\n        \"output_cost_per_token_above_128k_tokens\": 0.0000006,\n
        \       \"output_cost_per_character_above_128k_tokens\": 0.00000015,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini-1.5-flash-exp-0827\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_image\": 0.00002,\n
        \       \"input_cost_per_video_per_second\": 0.00002,\n        \"input_cost_per_audio_per_second\":
        0.000002,\n        \"input_cost_per_token\": 0.000000004688, \n        \"input_cost_per_character\":
        0.00000001875, \n        \"input_cost_per_token_above_128k_tokens\": 0.000001,
        \n        \"input_cost_per_character_above_128k_tokens\": 0.00000025, \n        \"input_cost_per_image_above_128k_tokens\":
        0.00004,\n        \"input_cost_per_video_per_second_above_128k_tokens\": 0.00004,\n
        \       \"input_cost_per_audio_per_second_above_128k_tokens\": 0.000004,\n
        \       \"output_cost_per_token\": 0.0000000046875,\n        \"output_cost_per_character\":
        0.00000001875,\n        \"output_cost_per_token_above_128k_tokens\": 0.000000009375,\n
        \       \"output_cost_per_character_above_128k_tokens\": 0.0000000375,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini-1.5-flash-002\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_image\": 0.00002,\n
        \       \"input_cost_per_video_per_second\": 0.00002,\n        \"input_cost_per_audio_per_second\":
        0.000002,\n        \"input_cost_per_token\": 0.000000075,\n        \"input_cost_per_character\":
        0.00000001875, \n        \"input_cost_per_token_above_128k_tokens\": 0.000001,
        \n        \"input_cost_per_character_above_128k_tokens\": 0.00000025, \n        \"input_cost_per_image_above_128k_tokens\":
        0.00004,\n        \"input_cost_per_video_per_second_above_128k_tokens\": 0.00004,\n
        \       \"input_cost_per_audio_per_second_above_128k_tokens\": 0.000004,\n
        \       \"output_cost_per_token\": 0.0000003,\n        \"output_cost_per_character\":
        0.000000075,\n        \"output_cost_per_token_above_128k_tokens\": 0.0000006,\n
        \       \"output_cost_per_character_above_128k_tokens\": 0.00000015,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-flash\",\n
        \       \"deprecation_date\": \"2025-09-24\",\n        \"supports_tool_choice\":
        true\n    },\n    \"gemini-1.5-flash-001\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 1000000,\n        \"max_output_tokens\": 8192,\n
        \       \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_image\": 0.00002,\n        \"input_cost_per_video_per_second\":
        0.00002,\n        \"input_cost_per_audio_per_second\": 0.000002,\n        \"input_cost_per_token\":
        0.000000075,\n        \"input_cost_per_character\": 0.00000001875, \n        \"input_cost_per_token_above_128k_tokens\":
        0.000001, \n        \"input_cost_per_character_above_128k_tokens\": 0.00000025,
        \n        \"input_cost_per_image_above_128k_tokens\": 0.00004,\n        \"input_cost_per_video_per_second_above_128k_tokens\":
        0.00004,\n        \"input_cost_per_audio_per_second_above_128k_tokens\": 0.000004,\n
        \       \"output_cost_per_token\": 0.0000003,\n        \"output_cost_per_character\":
        0.000000075,\n        \"output_cost_per_token_above_128k_tokens\": 0.0000006,\n
        \       \"output_cost_per_character_above_128k_tokens\": 0.00000015,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"deprecation_date\": \"2025-05-24\",\n        \"supports_tool_choice\":
        true\n    },\n    \"gemini-1.5-flash-preview-0514\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1000000,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_image\": 0.00002,\n        \"input_cost_per_video_per_second\":
        0.00002,\n        \"input_cost_per_audio_per_second\": 0.000002,\n        \"input_cost_per_token\":
        0.000000075,\n        \"input_cost_per_character\": 0.00000001875, \n        \"input_cost_per_token_above_128k_tokens\":
        0.000001, \n        \"input_cost_per_character_above_128k_tokens\": 0.00000025,
        \n        \"input_cost_per_image_above_128k_tokens\": 0.00004,\n        \"input_cost_per_video_per_second_above_128k_tokens\":
        0.00004,\n        \"input_cost_per_audio_per_second_above_128k_tokens\": 0.000004,\n
        \       \"output_cost_per_token\": 0.0000000046875,\n        \"output_cost_per_character\":
        0.00000001875,\n        \"output_cost_per_token_above_128k_tokens\": 0.000000009375,\n
        \       \"output_cost_per_character_above_128k_tokens\": 0.0000000375,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini-pro-experimental\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0,\n
        \       \"output_cost_per_token\": 0,\n        \"input_cost_per_character\":
        0,\n        \"output_cost_per_character\": 0,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        false,\n        \"supports_tool_choice\": true, \n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental\"\n
        \   },\n    \"gemini-flash-experimental\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 1000000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 0,\n        \"output_cost_per_token\": 0,\n
        \       \"input_cost_per_character\": 0,\n        \"output_cost_per_character\":
        0,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": false,\n        \"supports_tool_choice\":
        true, \n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental\"\n
        \   },\n    \"gemini-pro-vision\": {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\":
        16384,\n        \"max_output_tokens\": 2048,\n        \"max_images_per_prompt\":
        16,\n        \"max_videos_per_prompt\": 1,\n        \"max_video_length\":
        2,\n        \"input_cost_per_token\": 0.0000005, \n        \"output_cost_per_token\":
        0.0000015,\n        \"input_cost_per_image\": 0.0025,\n        \"litellm_provider\":
        \"vertex_ai-vision-models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini-1.0-pro-vision\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        2048,\n        \"max_images_per_prompt\": 16,\n        \"max_videos_per_prompt\":
        1,\n        \"max_video_length\": 2,\n        \"input_cost_per_token\": 0.0000005,
        \n        \"output_cost_per_token\": 0.0000015,\n        \"input_cost_per_image\":
        0.0025,\n        \"litellm_provider\": \"vertex_ai-vision-models\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini-1.0-pro-vision-001\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        2048,\n        \"max_images_per_prompt\": 16,\n        \"max_videos_per_prompt\":
        1,\n        \"max_video_length\": 2,\n        \"input_cost_per_token\": 0.0000005,
        \n        \"output_cost_per_token\": 0.0000015,\n        \"input_cost_per_image\":
        0.0025,\n        \"litellm_provider\": \"vertex_ai-vision-models\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"deprecation_date\": \"2025-04-09\",\n        \"supports_tool_choice\":
        true\n    },\n    \"medlm-medium\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        32768,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_character\":
        0.0000005,\n        \"output_cost_per_character\": 0.000001,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"medlm-large\": {\n        \"max_tokens\":
        1024,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        1024,\n        \"input_cost_per_character\": 0.000005,\n        \"output_cost_per_character\":
        0.000015,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n
        \       \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini-2.5-pro-exp-03-25\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_token\": 0.00000125,\n
        \       \"input_cost_per_token_above_200k_tokens\": 0.0000025,\n        \"output_cost_per_token\":
        0.00001,\n        \"output_cost_per_token_above_200k_tokens\": 0.000015,\n
        \       \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_audio_input\":
        true,\n        \"supports_video_input\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true,\n        \"supported_endpoints\": [\"/v1/chat/completions\", \"/v1/completions\"],\n
        \       \"supported_modalities\": [\"text\", \"image\", \"audio\", \"video\"],\n
        \       \"supported_output_modalities\": [\"text\"],\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n    },\n    \"gemini-2.0-pro-exp-02-05\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 2097152,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_token\": 0.00000125,\n
        \       \"input_cost_per_token_above_200k_tokens\": 0.0000025,\n        \"output_cost_per_token\":
        0.00001,\n        \"output_cost_per_token_above_200k_tokens\": 0.000015,\n
        \       \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_audio_input\":
        true,\n        \"supports_video_input\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true,\n        \"supported_endpoints\": [\"/v1/chat/completions\", \"/v1/completions\"],\n
        \       \"supported_modalities\": [\"text\", \"image\", \"audio\", \"video\"],\n
        \       \"supported_output_modalities\": [\"text\"],\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n    },\n    \"gemini-2.0-flash-exp\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_image\": 0,\n
        \       \"input_cost_per_video_per_second\": 0,\n        \"input_cost_per_audio_per_second\":
        0,\n        \"input_cost_per_token\": 0.00000015,\n        \"input_cost_per_character\":
        0, \n        \"input_cost_per_token_above_128k_tokens\": 0, \n        \"input_cost_per_character_above_128k_tokens\":
        0, \n        \"input_cost_per_image_above_128k_tokens\": 0,\n        \"input_cost_per_video_per_second_above_128k_tokens\":
        0,\n        \"input_cost_per_audio_per_second_above_128k_tokens\": 0,\n        \"output_cost_per_token\":
        0.0000006,\n        \"output_cost_per_character\": 0,\n        \"output_cost_per_token_above_128k_tokens\":
        0,\n        \"output_cost_per_character_above_128k_tokens\": 0,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        true,\n        \"supported_modalities\": [\"text\", \"image\", \"audio\",
        \"video\"],\n        \"supported_output_modalities\": [\"text\", \"image\"],\n
        \       \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini-2.0-flash-001\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        0.000001,\n        \"input_cost_per_token\": 0.00000015,\n        \"output_cost_per_token\":
        0.0000006,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n
        \       \"mode\": \"chat\",\n        \"supports_system_messages\": true,\n
        \       \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_tool_choice\": true,\n        \"supported_modalities\":
        [\"text\", \"image\", \"audio\", \"video\"],\n        \"supported_output_modalities\":
        [\"text\", \"image\"],\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\",\n
        \       \"deprecation_date\": \"2026-02-05\"\n    },\n    \"gemini-2.0-flash-thinking-exp\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_image\": 0,\n
        \       \"input_cost_per_video_per_second\": 0,\n        \"input_cost_per_audio_per_second\":
        0,\n        \"input_cost_per_token\": 0,\n        \"input_cost_per_character\":
        0, \n        \"input_cost_per_token_above_128k_tokens\": 0, \n        \"input_cost_per_character_above_128k_tokens\":
        0, \n        \"input_cost_per_image_above_128k_tokens\": 0,\n        \"input_cost_per_video_per_second_above_128k_tokens\":
        0,\n        \"input_cost_per_audio_per_second_above_128k_tokens\": 0,\n        \"output_cost_per_token\":
        0,\n        \"output_cost_per_character\": 0,\n        \"output_cost_per_token_above_128k_tokens\":
        0,\n        \"output_cost_per_character_above_128k_tokens\": 0,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        true,\n        \"supported_modalities\": [\"text\", \"image\", \"audio\",
        \"video\"],\n        \"supported_output_modalities\": [\"text\", \"image\"],\n
        \       \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini-2.0-flash-thinking-exp-01-21\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65536,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_image\": 0,\n
        \       \"input_cost_per_video_per_second\": 0,\n        \"input_cost_per_audio_per_second\":
        0,\n        \"input_cost_per_token\": 0,\n        \"input_cost_per_character\":
        0, \n        \"input_cost_per_token_above_128k_tokens\": 0, \n        \"input_cost_per_character_above_128k_tokens\":
        0, \n        \"input_cost_per_image_above_128k_tokens\": 0,\n        \"input_cost_per_video_per_second_above_128k_tokens\":
        0,\n        \"input_cost_per_audio_per_second_above_128k_tokens\": 0,\n        \"output_cost_per_token\":
        0,\n        \"output_cost_per_character\": 0,\n        \"output_cost_per_token_above_128k_tokens\":
        0,\n        \"output_cost_per_character_above_128k_tokens\": 0,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": false,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": false,\n        \"supports_audio_output\":
        false,\n        \"supported_modalities\": [\"text\", \"image\", \"audio\",
        \"video\"],\n        \"supported_output_modalities\": [\"text\", \"image\"],\n
        \       \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini/gemini-2.5-pro-exp-03-25\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_token\": 0.0,\n
        \       \"input_cost_per_token_above_200k_tokens\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"output_cost_per_token_above_200k_tokens\": 0.0,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"rpm\": 5,\n        \"tpm\":
        250000,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_audio_input\":
        true,\n        \"supports_video_input\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true,\n        \"supported_endpoints\": [\"/v1/chat/completions\", \"/v1/completions\"],\n
        \       \"supported_modalities\": [\"text\", \"image\", \"audio\", \"video\"],\n
        \       \"supported_output_modalities\": [\"text\"],\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n    },\n    \"gemini/gemini-2.5-flash-preview-tts\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        1e-6,\n        \"input_cost_per_token\": 0.15e-6,\n        \"output_cost_per_token\":
        0.6e-6,\n        \"output_cost_per_reasoning_token\": 3.5e-6,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"rpm\": 10,\n        \"tpm\":
        250000,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_endpoints\":
        [\"/v1/chat/completions\", \"/v1/completions\"],\n        \"supported_modalities\":
        [\"text\"],\n        \"supported_output_modalities\": [\"audio\"],\n        \"source\":
        \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\"\n
        \   },\n    \"gemini/gemini-2.5-flash-preview-05-20\": {\n        \"max_tokens\":
        65535,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        65535,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 1e-6,\n        \"input_cost_per_token\":
        0.15e-6,\n        \"output_cost_per_token\": 0.6e-6,\n        \"output_cost_per_reasoning_token\":
        3.5e-6,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"rpm\": 10,\n        \"tpm\": 250000,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": false,\n        \"supports_tool_choice\":
        true,\n        \"supported_endpoints\": [\"/v1/chat/completions\", \"/v1/completions\"],\n
        \       \"supported_modalities\": [\"text\", \"image\", \"audio\", \"video\"],\n
        \       \"supported_output_modalities\": [\"text\"],\n        \"source\":
        \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\"\n
        \   },\n    \"gemini/gemini-2.5-flash-preview-04-17\": {\n        \"max_tokens\":
        65535,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        65535,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 1e-6,\n        \"input_cost_per_token\":
        0.15e-6,\n        \"output_cost_per_token\": 0.6e-6,\n        \"output_cost_per_reasoning_token\":
        3.5e-6,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"rpm\": 10,\n        \"tpm\": 250000,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": false,\n        \"supports_tool_choice\":
        true,\n        \"supported_endpoints\": [\"/v1/chat/completions\", \"/v1/completions\"],\n
        \       \"supported_modalities\": [\"text\", \"image\", \"audio\", \"video\"],\n
        \       \"supported_output_modalities\": [\"text\"],\n        \"source\":
        \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\"\n
        \   },\n    \"gemini-2.5-flash-preview-05-20\": {\n        \"max_tokens\":
        65535,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        65535,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 1e-6,\n        \"input_cost_per_token\":
        0.15e-6,\n        \"output_cost_per_token\": 0.6e-6,\n        \"output_cost_per_reasoning_token\":
        3.5e-6,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_reasoning\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_endpoints\":
        [\"/v1/chat/completions\", \"/v1/completions\", \"/v1/batch\"],\n        \"supported_modalities\":
        [\"text\", \"image\", \"audio\", \"video\"],\n        \"supported_output_modalities\":
        [\"text\"],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\"\n
        \   },\n    \"gemini-2.5-flash-preview-04-17\": {\n        \"max_tokens\":
        65535,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        65535,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 1e-6,\n        \"input_cost_per_token\":
        0.15e-6,\n        \"output_cost_per_token\": 0.6e-6,\n        \"output_cost_per_reasoning_token\":
        3.5e-6,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n        \"mode\":
        \"chat\",\n        \"supports_reasoning\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_endpoints\":
        [\"/v1/chat/completions\", \"/v1/completions\", \"/v1/batch\"],\n        \"supported_modalities\":
        [\"text\", \"image\", \"audio\", \"video\"],\n        \"supported_output_modalities\":
        [\"text\"],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\"\n
        \   },\n    \"gemini-2.0-flash\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        1048576,\n        \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        0.0000007,\n        \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0.0000004,\n        \"litellm_provider\": \"vertex_ai-language-models\",\n
        \       \"mode\": \"chat\",\n        \"supports_system_messages\": true,\n
        \       \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_audio_input\": true,\n        \"supported_modalities\":
        [\"text\", \"image\", \"audio\", \"video\"],\n        \"supported_output_modalities\":
        [\"text\", \"image\"],\n        \"supports_tool_choice\": true,\n        \"source\":
        \"https://ai.google.dev/pricing#2_0flash\"\n    },\n    \"gemini-2.0-flash-lite\":
        {\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 50,\n
        \       \"input_cost_per_audio_token\": 0.000000075,\n        \"input_cost_per_token\":
        0.000000075,\n        \"output_cost_per_token\": 0.0000003,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        true,\n        \"supported_modalities\": [\"text\", \"image\", \"audio\",
        \"video\"],\n        \"supported_output_modalities\": [\"text\"],\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini-2.0-flash-lite-001\":
        {\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 50,\n
        \       \"input_cost_per_audio_token\": 0.000000075,\n        \"input_cost_per_token\":
        0.000000075,\n        \"output_cost_per_token\": 0.0000003,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        true,\n        \"supported_modalities\": [\"text\", \"image\", \"audio\",
        \"video\"],\n        \"supported_output_modalities\": [\"text\"],\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash\",\n
        \       \"supports_tool_choice\": true,\n        \"deprecation_date\": \"2026-02-25\"\n
        \   },\n    \"gemini-2.5-pro-preview-05-06\": {\n        \"max_tokens\": 65535,\n
        \       \"max_input_tokens\": 1048576,\n        \"max_output_tokens\": 65535,\n
        \       \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 0.00000125,\n        \"input_cost_per_token\":
        0.00000125,\n        \"input_cost_per_token_above_200k_tokens\": 0.0000025,\n
        \       \"output_cost_per_token\": 0.00001,\n        \"output_cost_per_token_above_200k_tokens\":
        0.000015, \n        \"litellm_provider\": \"vertex_ai-language-models\",\n
        \       \"mode\": \"chat\",\n        \"supports_reasoning\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_endpoints\":
        [\"/v1/chat/completions\", \"/v1/completions\", \"/v1/batch\"],\n        \"supported_modalities\":
        [\"text\", \"image\", \"audio\", \"video\"],\n        \"supported_output_modalities\":
        [\"text\"],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\"\n
        \   },\n    \"gemini-2.5-pro-preview-03-25\": {\n        \"max_tokens\": 65535,\n
        \       \"max_input_tokens\": 1048576,\n        \"max_output_tokens\": 65535,\n
        \       \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 0.00000125,\n        \"input_cost_per_token\":
        0.00000125,\n        \"input_cost_per_token_above_200k_tokens\": 0.0000025,\n
        \       \"output_cost_per_token\": 0.00001,\n        \"output_cost_per_token_above_200k_tokens\":
        0.000015, \n        \"litellm_provider\": \"vertex_ai-language-models\",\n
        \       \"mode\": \"chat\",\n        \"supports_reasoning\": true,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_endpoints\":
        [\"/v1/chat/completions\", \"/v1/completions\", \"/v1/batch\"],\n        \"supported_modalities\":
        [\"text\", \"image\", \"audio\", \"video\"],\n        \"supported_output_modalities\":
        [\"text\"],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview\"\n
        \   },\n    \"gemini-2.0-flash-preview-image-generation\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 0.0000007,\n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0.0000004,\n        \"litellm_provider\":
        \"vertex_ai-language-models\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_audio_input\": true,\n        \"supported_modalities\":
        [\"text\", \"image\", \"audio\", \"video\"],\n        \"supported_output_modalities\":
        [\"text\", \"image\"],\n        \"supports_tool_choice\": true,\n        \"source\":
        \"https://ai.google.dev/pricing#2_0flash\"\n    },\n    \"gemini-2.5-pro-preview-tts\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        0.0000007,\n        \"input_cost_per_token\": 0.00000125,\n        \"input_cost_per_token_above_200k_tokens\":
        0.0000025, \n        \"output_cost_per_token\": 0.00001,\n        \"output_cost_per_token_above_200k_tokens\":
        0.000015, \n        \"litellm_provider\": \"vertex_ai-language-models\",\n
        \       \"mode\": \"chat\",\n        \"supports_system_messages\": true,\n
        \       \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_modalities\":
        [\"text\"],\n        \"supported_output_modalities\": [\"audio\"],\n        \"source\":
        \"https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview\"\n
        \   },\n    \"gemini/gemini-2.0-pro-exp-02-05\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 2097152,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_image\": 0,\n        \"input_cost_per_video_per_second\":
        0,\n        \"input_cost_per_audio_per_second\": 0,\n        \"input_cost_per_token\":
        0,\n        \"input_cost_per_character\": 0, \n        \"input_cost_per_token_above_128k_tokens\":
        0, \n        \"input_cost_per_character_above_128k_tokens\": 0, \n        \"input_cost_per_image_above_128k_tokens\":
        0,\n        \"input_cost_per_video_per_second_above_128k_tokens\": 0,\n        \"input_cost_per_audio_per_second_above_128k_tokens\":
        0,\n        \"output_cost_per_token\": 0,\n        \"output_cost_per_character\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_character_above_128k_tokens\":
        0,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"rpm\": 2,\n        \"tpm\": 1000000,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_audio_input\": true,\n        \"supports_video_input\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n
        \   },\n    \"gemini/gemini-2.0-flash-preview-image-generation\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 0.0000007,\n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0.0000004,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"rpm\": 10000,\n        \"tpm\":
        10000000,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_audio_input\":
        true,\n        \"supported_modalities\": [\"text\", \"image\", \"audio\",
        \"video\"],\n        \"supported_output_modalities\": [\"text\", \"image\"],\n
        \       \"supports_tool_choice\": true,\n        \"source\": \"https://ai.google.dev/pricing#2_0flash\"\n
        \   },\n    \"gemini/gemini-2.0-flash\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 1048576,\n        \"max_output_tokens\": 8192,\n
        \       \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 0.0000007,\n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0.0000004,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"rpm\": 10000,\n        \"tpm\":
        10000000,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_audio_input\":
        true,\n        \"supported_modalities\": [\"text\", \"image\", \"audio\",
        \"video\"],\n        \"supported_output_modalities\": [\"text\", \"image\"],\n
        \       \"supports_tool_choice\": true,\n        \"source\": \"https://ai.google.dev/pricing#2_0flash\"\n
        \   },\n    \"gemini/gemini-2.0-flash-lite\": {\n        \"max_input_tokens\":
        1048576,\n        \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 50,\n        \"input_cost_per_audio_token\":
        0.000000075,\n        \"input_cost_per_token\": 0.000000075,\n        \"output_cost_per_token\":
        0.0000003,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"tpm\": 4000000,\n        \"rpm\": 4000,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        true,\n        \"supports_tool_choice\": true,\n        \"supported_modalities\":
        [\"text\", \"image\", \"audio\", \"video\"],\n        \"supported_output_modalities\":
        [\"text\"],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/pricing#gemini-2.0-flash-lite\"\n
        \   },\n    \"gemini/gemini-2.0-flash-001\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 1048576,\n        \"max_output_tokens\": 8192,\n
        \       \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 0.0000007,\n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0.0000004,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"rpm\": 10000,\n        \"tpm\":
        10000000,\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": false,\n        \"supports_tool_choice\":
        true,\n        \"supported_modalities\": [\"text\", \"image\", \"audio\",
        \"video\"],\n        \"supported_output_modalities\": [\"text\", \"image\"],\n
        \       \"source\": \"https://ai.google.dev/pricing#2_0flash\"\n    },\n    \"gemini/gemini-2.5-pro-preview-tts\":
        {\n        \"max_tokens\": 65535,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65535,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        0.0000007,\n        \"input_cost_per_token\": 0.00000125,\n        \"input_cost_per_token_above_200k_tokens\":
        0.0000025, \n        \"output_cost_per_token\": 0.00001,\n        \"output_cost_per_token_above_200k_tokens\":
        0.000015, \n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"rpm\": 10000,\n        \"tpm\": 10000000,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_modalities\":
        [\"text\"],\n        \"supported_output_modalities\": [\"audio\"],\n        \"source\":
        \"https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview\"\n
        \   },\n    \"gemini/gemini-2.5-pro-preview-05-06\": {\n        \"max_tokens\":
        65535,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        65535,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 0.0000007,\n        \"input_cost_per_token\":
        0.00000125,\n        \"input_cost_per_token_above_200k_tokens\": 0.0000025,
        \n        \"output_cost_per_token\": 0.00001,\n        \"output_cost_per_token_above_200k_tokens\":
        0.000015, \n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"rpm\": 10000,\n        \"tpm\": 10000000,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_modalities\":
        [\"text\", \"image\", \"audio\", \"video\"],\n        \"supported_output_modalities\":
        [\"text\"],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview\"\n
        \   },\n    \"gemini/gemini-2.5-pro-preview-03-25\": {\n        \"max_tokens\":
        65535,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        65535,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_audio_token\": 0.0000007,\n        \"input_cost_per_token\":
        0.00000125,\n        \"input_cost_per_token_above_200k_tokens\": 0.0000025,
        \n        \"output_cost_per_token\": 0.00001,\n        \"output_cost_per_token_above_200k_tokens\":
        0.000015, \n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"rpm\": 10000,\n        \"tpm\": 10000000,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_modalities\":
        [\"text\", \"image\", \"audio\", \"video\"],\n        \"supported_output_modalities\":
        [\"text\"],\n        \"source\": \"https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview\"\n
        \   },\n    \"gemini/gemini-2.0-flash-exp\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 1048576,\n        \"max_output_tokens\": 8192,\n
        \       \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_image\": 0,\n        \"input_cost_per_video_per_second\":
        0,\n        \"input_cost_per_audio_per_second\": 0,\n        \"input_cost_per_token\":
        0,\n        \"input_cost_per_character\": 0, \n        \"input_cost_per_token_above_128k_tokens\":
        0, \n        \"input_cost_per_character_above_128k_tokens\": 0, \n        \"input_cost_per_image_above_128k_tokens\":
        0,\n        \"input_cost_per_video_per_second_above_128k_tokens\": 0,\n        \"input_cost_per_audio_per_second_above_128k_tokens\":
        0,\n        \"output_cost_per_token\": 0,\n        \"output_cost_per_character\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_character_above_128k_tokens\":
        0,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": true,\n        \"tpm\": 4000000,\n
        \       \"rpm\": 10,\n        \"supported_modalities\": [\"text\", \"image\",
        \"audio\", \"video\"],\n        \"supported_output_modalities\": [\"text\",
        \"image\"],\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini/gemini-2.0-flash-lite-preview-02-05\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        0.000000075,\n        \"input_cost_per_token\": 0.000000075,\n        \"output_cost_per_token\":
        0.0000003,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"rpm\": 60000,\n        \"tpm\": 10000000,\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"supports_tool_choice\": true,\n        \"supported_modalities\":
        [\"text\", \"image\", \"audio\", \"video\"],\n        \"supported_output_modalities\":
        [\"text\"],\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash-lite\"\n
        \   },\n    \"gemini/gemini-2.0-flash-thinking-exp\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        65536,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,\n
        \       \"input_cost_per_image\": 0,\n        \"input_cost_per_video_per_second\":
        0,\n        \"input_cost_per_audio_per_second\": 0,\n        \"input_cost_per_token\":
        0,\n        \"input_cost_per_character\": 0, \n        \"input_cost_per_token_above_128k_tokens\":
        0, \n        \"input_cost_per_character_above_128k_tokens\": 0, \n        \"input_cost_per_image_above_128k_tokens\":
        0,\n        \"input_cost_per_video_per_second_above_128k_tokens\": 0,\n        \"input_cost_per_audio_per_second_above_128k_tokens\":
        0,\n        \"output_cost_per_token\": 0,\n        \"output_cost_per_character\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_character_above_128k_tokens\":
        0,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": true,\n        \"tpm\": 4000000,\n
        \       \"rpm\": 10,\n        \"supported_modalities\": [\"text\", \"image\",
        \"audio\", \"video\"],\n        \"supported_output_modalities\": [\"text\",
        \"image\"],\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini/gemini-2.0-flash-thinking-exp-01-21\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 65536,\n        \"max_images_per_prompt\":
        3000,\n        \"max_videos_per_prompt\": 10,\n        \"max_video_length\":
        1,\n        \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_image\": 0,\n
        \       \"input_cost_per_video_per_second\": 0,\n        \"input_cost_per_audio_per_second\":
        0,\n        \"input_cost_per_token\": 0,\n        \"input_cost_per_character\":
        0, \n        \"input_cost_per_token_above_128k_tokens\": 0, \n        \"input_cost_per_character_above_128k_tokens\":
        0, \n        \"input_cost_per_image_above_128k_tokens\": 0,\n        \"input_cost_per_video_per_second_above_128k_tokens\":
        0,\n        \"input_cost_per_audio_per_second_above_128k_tokens\": 0,\n        \"output_cost_per_token\":
        0,\n        \"output_cost_per_character\": 0,\n        \"output_cost_per_token_above_128k_tokens\":
        0,\n        \"output_cost_per_character_above_128k_tokens\": 0,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        true,\n        \"tpm\": 4000000,\n        \"rpm\": 10,\n        \"supported_modalities\":
        [\"text\", \"image\", \"audio\", \"video\"],\n        \"supported_output_modalities\":
        [\"text\", \"image\"],\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini/gemma-3-27b-it\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_image\": 0,\n
        \       \"input_cost_per_video_per_second\": 0,\n        \"input_cost_per_audio_per_second\":
        0,\n        \"input_cost_per_token\": 0,\n        \"input_cost_per_character\":
        0, \n        \"input_cost_per_token_above_128k_tokens\": 0, \n        \"input_cost_per_character_above_128k_tokens\":
        0, \n        \"input_cost_per_image_above_128k_tokens\": 0,\n        \"input_cost_per_video_per_second_above_128k_tokens\":
        0,\n        \"input_cost_per_audio_per_second_above_128k_tokens\": 0,\n        \"output_cost_per_token\":
        0,\n        \"output_cost_per_character\": 0,\n        \"output_cost_per_token_above_128k_tokens\":
        0,\n        \"output_cost_per_character_above_128k_tokens\": 0,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_audio_output\":
        false,\n        \"source\": \"https://aistudio.google.com\",\n        \"supports_tool_choice\":
        true\n    },\n    \"gemini/learnlm-1.5-pro-experimental\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 32767,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_image\": 0,\n        \"input_cost_per_video_per_second\":
        0,\n        \"input_cost_per_audio_per_second\": 0,\n        \"input_cost_per_token\":
        0,\n        \"input_cost_per_character\": 0, \n        \"input_cost_per_token_above_128k_tokens\":
        0, \n        \"input_cost_per_character_above_128k_tokens\": 0, \n        \"input_cost_per_image_above_128k_tokens\":
        0,\n        \"input_cost_per_video_per_second_above_128k_tokens\": 0,\n        \"input_cost_per_audio_per_second_above_128k_tokens\":
        0,\n        \"output_cost_per_token\": 0,\n        \"output_cost_per_character\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_character_above_128k_tokens\":
        0,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": false,\n        \"source\": \"https://aistudio.google.com\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"vertex_ai/claude-3-sonnet\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/claude-3-sonnet@20240229\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/claude-3-5-sonnet\":
        {\n        \"supports_computer_use\": true,\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000015,\n        \"litellm_provider\": \"vertex_ai-anthropic_models\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_pdf_input\": true,\n        \"supports_vision\": true,\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/claude-3-5-sonnet@20240620\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000015,\n        \"litellm_provider\": \"vertex_ai-anthropic_models\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_pdf_input\": true,\n        \"supports_vision\": true,\n
        \       \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/claude-3-5-sonnet-v2\": {\n        \"supports_computer_use\":
        true,\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_vision\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/claude-3-5-sonnet-v2@20241022\": {\n        \"supports_computer_use\":
        true,\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_vision\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/claude-3-7-sonnet@20250219\": {\n        \"supports_computer_use\":
        true,\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"cache_creation_input_token_cost\":
        0.00000375,\n        \"cache_read_input_token_cost\": 0.0000003,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_vision\":
        true,\n        \"tool_use_system_prompt_tokens\": 159,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"deprecation_date\": \"2025-06-01\",\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/claude-opus-4@20250514\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 32000,\n        \"input_cost_per_token\": 15e-6,\n
        \       \"output_cost_per_token\": 75e-6,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 1e-2, \n            \"search_context_size_medium\":
        1e-2,\n            \"search_context_size_high\": 1e-2\n        },\n        \"cache_creation_input_token_cost\":
        18.75e-6,\n        \"cache_read_input_token_cost\": 1.5e-6,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"vertex_ai/claude-sonnet-4@20250514\":
        {\n        \"max_tokens\": 64000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 64000,\n        \"input_cost_per_token\": 3e-6,\n
        \       \"output_cost_per_token\": 15e-6,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 1e-2, \n            \"search_context_size_medium\":
        1e-2,\n            \"search_context_size_high\": 1e-2\n        },\n        \"cache_creation_input_token_cost\":
        3.75e-6,\n        \"cache_read_input_token_cost\": 0.3e-6,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"vertex_ai/claude-3-haiku\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000025,\n
        \       \"output_cost_per_token\": 0.00000125,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/claude-3-haiku@20240307\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000025,\n
        \       \"output_cost_per_token\": 0.00000125,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/claude-3-5-haiku\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.000001,\n
        \       \"output_cost_per_token\": 0.000005,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/claude-3-5-haiku@20241022\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.000001,\n
        \       \"output_cost_per_token\": 0.000005,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/claude-3-opus\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000015,\n
        \       \"output_cost_per_token\": 0.000075,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/claude-3-opus@20240229\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000015,\n
        \       \"output_cost_per_token\": 0.000075,\n        \"litellm_provider\":
        \"vertex_ai-anthropic_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/meta/llama3-405b-instruct-maas\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 32000,\n
        \       \"max_output_tokens\": 32000,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"vertex_ai-llama_models\",\n
        \       \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"vertex_ai/meta/llama-4-scout-17b-16e-instruct-maas\":
        {\n        \"max_tokens\": 10e6,\n        \"max_input_tokens\": 10e6,\n        \"max_output_tokens\":
        10e6,\n        \"input_cost_per_token\": 0.25e-6,\n        \"output_cost_per_token\":
        0.70e-6,\n        \"litellm_provider\": \"vertex_ai-llama_models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\",\n
        \       \"supports_tool_choice\": true,\n        \"supports_function_calling\":
        true,\n        \"supported_modalities\": [\"text\", \"image\"],\n        \"supported_output_modalities\":
        [\"text\", \"code\"]\n    },\n    \"vertex_ai/meta/llama-4-scout-17b-128e-instruct-maas\":
        {\n        \"max_tokens\": 10e6,\n        \"max_input_tokens\": 10e6,\n        \"max_output_tokens\":
        10e6,\n        \"input_cost_per_token\": 0.25e-6,\n        \"output_cost_per_token\":
        0.70e-6,\n        \"litellm_provider\": \"vertex_ai-llama_models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\",\n
        \       \"supports_tool_choice\": true,\n        \"supports_function_calling\":
        true,\n        \"supported_modalities\": [\"text\", \"image\"],\n        \"supported_output_modalities\":
        [\"text\", \"code\"]\n    },\n    \"vertex_ai/meta/llama-4-maverick-17b-128e-instruct-maas\":
        {\n        \"max_tokens\": 1e6,\n        \"max_input_tokens\": 1e6,\n        \"max_output_tokens\":
        1e6,\n        \"input_cost_per_token\": 0.35e-6,\n        \"output_cost_per_token\":
        1.15e-6,\n        \"litellm_provider\": \"vertex_ai-llama_models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\",\n
        \       \"supports_tool_choice\": true,\n        \"supports_function_calling\":
        true,\n        \"supported_modalities\": [\"text\", \"image\"],\n        \"supported_output_modalities\":
        [\"text\", \"code\"]\n    },\n    \"vertex_ai/meta/llama-4-maverick-17b-16e-instruct-maas\":
        {\n        \"max_tokens\": 1e6,\n        \"max_input_tokens\": 1e6,\n        \"max_output_tokens\":
        1e6,\n        \"input_cost_per_token\": 0.35e-6,\n        \"output_cost_per_token\":
        1.15e-6,\n        \"litellm_provider\": \"vertex_ai-llama_models\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\",\n
        \       \"supports_tool_choice\": true,\n        \"supports_function_calling\":
        true,\n        \"supported_modalities\": [\"text\", \"image\"],\n        \"supported_output_modalities\":
        [\"text\", \"code\"]\n    },\n    \"vertex_ai/meta/llama3-70b-instruct-maas\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 32000,\n
        \       \"max_output_tokens\": 32000,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"vertex_ai-llama_models\",\n
        \       \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"vertex_ai/meta/llama3-8b-instruct-maas\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 32000,\n
        \       \"max_output_tokens\": 32000,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"vertex_ai-llama_models\",\n
        \       \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/pricing#partner-models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"vertex_ai/meta/llama-3.2-90b-vision-instruct-maas\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 2048,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"vertex_ai-llama_models\",\n
        \       \"mode\": \"chat\",\n        \"supports_system_messages\": true,\n
        \       \"supports_vision\": true,\n        \"source\": \"https://console.cloud.google.com/vertex-ai/publishers/meta/model-garden/llama-3.2-90b-vision-instruct-maas\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"vertex_ai/mistral-large@latest\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.000002,\n
        \       \"output_cost_per_token\": 0.000006,\n        \"litellm_provider\":
        \"vertex_ai-mistral_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/mistral-large@2411-001\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.000002,\n
        \       \"output_cost_per_token\": 0.000006,\n        \"litellm_provider\":
        \"vertex_ai-mistral_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/mistral-large-2411\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.000002,\n
        \       \"output_cost_per_token\": 0.000006,\n        \"litellm_provider\":
        \"vertex_ai-mistral_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/mistral-large@2407\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.000002,\n
        \       \"output_cost_per_token\": 0.000006,\n        \"litellm_provider\":
        \"vertex_ai-mistral_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/mistral-nemo@latest\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        0.00000015,\n        \"output_cost_per_token\": 0.00000015,\n        \"litellm_provider\":
        \"vertex_ai-mistral_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/mistral-small-2503@001\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000001,\n        \"output_cost_per_token\":
        0.000003,\n        \"litellm_provider\": \"vertex_ai-mistral_models\",\n        \"supports_function_calling\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"vertex_ai/mistral-small-2503\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 128000,\n
        \       \"input_cost_per_token\": 0.000001,\n        \"output_cost_per_token\":
        0.000003,\n        \"litellm_provider\": \"vertex_ai-mistral_models\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/jamba-1.5-mini@001\":
        {\n        \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n
        \       \"max_output_tokens\": 256000,\n        \"input_cost_per_token\":
        0.0000002,\n        \"output_cost_per_token\": 0.0000004,\n        \"litellm_provider\":
        \"vertex_ai-ai21_models\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/jamba-1.5-large@001\": {\n        \"max_tokens\":
        256000,\n        \"max_input_tokens\": 256000,\n        \"max_output_tokens\":
        256000,\n        \"input_cost_per_token\": 0.000002,\n        \"output_cost_per_token\":
        0.000008,\n        \"litellm_provider\": \"vertex_ai-ai21_models\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/jamba-1.5\":
        {\n        \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n
        \       \"max_output_tokens\": 256000,\n        \"input_cost_per_token\":
        0.0000002,\n        \"output_cost_per_token\": 0.0000004,\n        \"litellm_provider\":
        \"vertex_ai-ai21_models\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/jamba-1.5-mini\": {\n        \"max_tokens\":
        256000,\n        \"max_input_tokens\": 256000,\n        \"max_output_tokens\":
        256000,\n        \"input_cost_per_token\": 0.0000002,\n        \"output_cost_per_token\":
        0.0000004,\n        \"litellm_provider\": \"vertex_ai-ai21_models\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/jamba-1.5-large\":
        {\n        \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n
        \       \"max_output_tokens\": 256000,\n        \"input_cost_per_token\":
        0.000002,\n        \"output_cost_per_token\": 0.000008,\n        \"litellm_provider\":
        \"vertex_ai-ai21_models\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/mistral-nemo@2407\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000003,\n        \"litellm_provider\": \"vertex_ai-mistral_models\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"vertex_ai/codestral@latest\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000,\n        \"input_cost_per_token\": 0.0000002,\n        \"output_cost_per_token\":
        0.0000006,\n        \"litellm_provider\": \"vertex_ai-mistral_models\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true,\n
        \       \"supports_tool_choice\": true\n    },\n    \"vertex_ai/codestral@2405\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        0.0000002,\n        \"output_cost_per_token\": 0.0000006,\n        \"litellm_provider\":
        \"vertex_ai-mistral_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/codestral-2501\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000,\n        \"input_cost_per_token\":
        0.0000002,\n        \"output_cost_per_token\": 0.0000006,\n        \"litellm_provider\":
        \"vertex_ai-mistral_models\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"vertex_ai/imagegeneration@006\":
        {\n        \"output_cost_per_image\": 0.020,\n        \"litellm_provider\":
        \"vertex_ai-image-models\",\n        \"mode\": \"image_generation\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n    },\n    \"vertex_ai/imagen-3.0-generate-002\":
        {\n        \"output_cost_per_image\": 0.04,\n        \"litellm_provider\":
        \"vertex_ai-image-models\",\n        \"mode\": \"image_generation\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n    },\n    \"vertex_ai/imagen-3.0-generate-001\":
        {\n        \"output_cost_per_image\": 0.04,\n        \"litellm_provider\":
        \"vertex_ai-image-models\",\n        \"mode\": \"image_generation\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n    },\n    \"vertex_ai/imagen-3.0-fast-generate-001\":
        {\n        \"output_cost_per_image\": 0.02,\n        \"litellm_provider\":
        \"vertex_ai-image-models\",\n        \"mode\": \"image_generation\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n    },\n    \"text-embedding-004\":
        {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\": 2048,\n        \"output_vector_size\":
        768,\n        \"input_cost_per_character\": 0.000000025,\n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0,\n        \"litellm_provider\":
        \"vertex_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\"\n    },\n
        \   \"text-embedding-005\": {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\":
        2048,\n        \"output_vector_size\": 768,\n        \"input_cost_per_character\":
        0.000000025,\n        \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0,\n        \"litellm_provider\": \"vertex_ai-embedding-models\",\n        \"mode\":
        \"embedding\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\"\n
        \   },\n    \"text-multilingual-embedding-002\": {\n        \"max_tokens\":
        2048,\n        \"max_input_tokens\": 2048,\n        \"output_vector_size\":
        768,\n        \"input_cost_per_character\": 0.000000025,\n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0,\n        \"litellm_provider\":
        \"vertex_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\"\n    },\n
        \   \"multimodalembedding\": {\n        \"max_tokens\": 2048,\n        \"max_input_tokens\":
        2048,\n        \"output_vector_size\": 768,\n        \"input_cost_per_character\":
        0.0000002,\n        \"input_cost_per_image\": 0.0001,\n        \"input_cost_per_video_per_second\":
        0.0005,\n        \"input_cost_per_video_per_second_above_8s_interval\": 0.0010,\n
        \       \"input_cost_per_video_per_second_above_15s_interval\": 0.0020,\n
        \       \"input_cost_per_token\": 0.0000008,\n        \"output_cost_per_token\":
        0,\n        \"litellm_provider\": \"vertex_ai-embedding-models\",\n        \"mode\":
        \"embedding\",\n        \"supported_endpoints\": [\"/v1/embeddings\"],\n        \"supported_modalities\":
        [\"text\", \"image\", \"video\"],\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\"\n
        \   },\n    \"multimodalembedding@001\": {\n        \"max_tokens\": 2048,\n
        \       \"max_input_tokens\": 2048,\n        \"output_vector_size\": 768,\n
        \       \"input_cost_per_character\": 0.0000002,\n        \"input_cost_per_image\":
        0.0001,\n        \"input_cost_per_video_per_second\": 0.0005,\n        \"input_cost_per_video_per_second_above_8s_interval\":
        0.0010,\n        \"input_cost_per_video_per_second_above_15s_interval\": 0.0020,\n
        \       \"input_cost_per_token\": 0.0000008,\n        \"output_cost_per_token\":
        0,\n        \"litellm_provider\": \"vertex_ai-embedding-models\",\n        \"mode\":
        \"embedding\",\n        \"supported_endpoints\": [\"/v1/embeddings\"],\n        \"supported_modalities\":
        [\"text\", \"image\", \"video\"],\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\"\n
        \   },\n    \"text-embedding-large-exp-03-07\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"output_vector_size\":
        3072,\n        \"input_cost_per_character\": 0.000000025,\n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0,\n        \"litellm_provider\":
        \"vertex_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\"\n    },\n
        \   \"textembedding-gecko\": {\n        \"max_tokens\": 3072,\n        \"max_input_tokens\":
        3072,\n        \"output_vector_size\": 768,\n        \"input_cost_per_character\":
        0.000000025,\n        \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0,\n        \"litellm_provider\": \"vertex_ai-embedding-models\",\n        \"mode\":
        \"embedding\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"textembedding-gecko-multilingual\": {\n        \"max_tokens\":
        3072,\n        \"max_input_tokens\": 3072,\n        \"output_vector_size\":
        768,\n        \"input_cost_per_character\": 0.000000025,\n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0,\n        \"litellm_provider\":
        \"vertex_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"textembedding-gecko-multilingual@001\": {\n        \"max_tokens\":
        3072,\n        \"max_input_tokens\": 3072,\n        \"output_vector_size\":
        768,\n        \"input_cost_per_character\": 0.000000025,\n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0,\n        \"litellm_provider\":
        \"vertex_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"textembedding-gecko@001\": {\n        \"max_tokens\": 3072,\n
        \       \"max_input_tokens\": 3072,\n        \"output_vector_size\": 768,\n
        \       \"input_cost_per_character\": 0.000000025,\n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0,\n        \"litellm_provider\":
        \"vertex_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"textembedding-gecko@003\": {\n        \"max_tokens\": 3072,\n
        \       \"max_input_tokens\": 3072,\n        \"output_vector_size\": 768,\n
        \       \"input_cost_per_character\": 0.000000025,\n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0,\n        \"litellm_provider\":
        \"vertex_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"text-embedding-preview-0409\": {\n        \"max_tokens\": 3072,\n
        \       \"max_input_tokens\": 3072,\n        \"output_vector_size\": 768,\n
        \       \"input_cost_per_token\": 0.00000000625,\n        \"input_cost_per_token_batch_requests\":
        0.000000005,\n        \"output_cost_per_token\": 0,\n        \"litellm_provider\":
        \"vertex_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://cloud.google.com/vertex-ai/generative-ai/pricing\"\n    },\n    \"text-multilingual-embedding-preview-0409\":{\n
        \       \"max_tokens\": 3072,\n        \"max_input_tokens\": 3072,\n        \"output_vector_size\":
        768,\n        \"input_cost_per_token\": 0.00000000625,\n        \"output_cost_per_token\":
        0,\n        \"litellm_provider\": \"vertex_ai-embedding-models\",\n        \"mode\":
        \"embedding\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"palm/chat-bison\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"litellm_provider\":
        \"palm\",\n        \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"palm/chat-bison-001\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"litellm_provider\":
        \"palm\",\n        \"mode\": \"chat\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"palm/text-bison\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"litellm_provider\":
        \"palm\",\n        \"mode\": \"completion\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"palm/text-bison-001\": {\n        \"max_tokens\": 1024,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 1024,\n        \"input_cost_per_token\":
        0.000000125,\n        \"output_cost_per_token\": 0.000000125,\n        \"litellm_provider\":
        \"palm\",\n        \"mode\": \"completion\",\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"palm/text-bison-safety-off\": {\n        \"max_tokens\": 1024,\n
        \       \"max_input_tokens\": 8192,\n        \"max_output_tokens\": 1024,\n
        \       \"input_cost_per_token\": 0.000000125,\n        \"output_cost_per_token\":
        0.000000125,\n        \"litellm_provider\": \"palm\",\n        \"mode\": \"completion\",\n
        \       \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"palm/text-bison-safety-recitation-off\": {\n        \"max_tokens\":
        1024,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        1024,\n        \"input_cost_per_token\": 0.000000125,\n        \"output_cost_per_token\":
        0.000000125,\n        \"litellm_provider\": \"palm\",\n        \"mode\": \"completion\",\n
        \       \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\"\n
        \   },\n    \"gemini/gemini-1.5-flash-002\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 1048576,\n        \"max_output_tokens\": 8192,\n
        \       \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,
        \n        \"cache_read_input_token_cost\": 0.00000001875,\n        \"cache_creation_input_token_cost\":
        0.000001,\n        \"input_cost_per_token\": 0.000000075,\n        \"input_cost_per_token_above_128k_tokens\":
        0.00000015,\n        \"output_cost_per_token\": 0.0000003,\n        \"output_cost_per_token_above_128k_tokens\":
        0.0000006,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_prompt_caching\": true,\n        \"tpm\": 4000000,\n
        \       \"rpm\": 2000,\n        \"source\": \"https://ai.google.dev/pricing\",\n
        \       \"deprecation_date\": \"2025-09-24\",\n        \"supports_tool_choice\":
        true\n    },\n    \"gemini/gemini-1.5-flash-001\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,
        \n        \"cache_read_input_token_cost\": 0.00000001875,\n        \"cache_creation_input_token_cost\":
        0.000001,\n        \"input_cost_per_token\": 0.000000075,\n        \"input_cost_per_token_above_128k_tokens\":
        0.00000015,\n        \"output_cost_per_token\": 0.0000003,\n        \"output_cost_per_token_above_128k_tokens\":
        0.0000006,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_prompt_caching\": true,\n        \"tpm\": 4000000,\n
        \       \"rpm\": 2000,\n        \"source\": \"https://ai.google.dev/pricing\",\n
        \       \"deprecation_date\": \"2025-05-24\",\n        \"supports_tool_choice\":
        true\n    },\n    \"gemini/gemini-1.5-flash\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,
        \n        \"input_cost_per_token\": 0.000000075,\n        \"input_cost_per_token_above_128k_tokens\":
        0.00000015,\n        \"output_cost_per_token\": 0.0000003,\n        \"output_cost_per_token_above_128k_tokens\":
        0.0000006,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true, \n        \"tpm\": 4000000,\n        \"rpm\": 2000,\n        \"source\":
        \"https://ai.google.dev/pricing\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"gemini/gemini-1.5-flash-latest\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,
        \n        \"input_cost_per_token\": 0.000000075,\n        \"input_cost_per_token_above_128k_tokens\":
        0.00000015,\n        \"output_cost_per_token\": 0.0000003,\n        \"output_cost_per_token_above_128k_tokens\":
        0.0000006,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_prompt_caching\": true,\n        \"tpm\": 4000000,\n
        \       \"rpm\": 2000,\n        \"source\": \"https://ai.google.dev/pricing\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini/gemini-1.5-flash-8b\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30, \n        \"input_cost_per_token\": 0,\n
        \       \"input_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_token\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_prompt_caching\":
        true,\n        \"tpm\": 4000000,\n        \"rpm\": 4000,\n        \"source\":
        \"https://ai.google.dev/pricing\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"gemini/gemini-1.5-flash-8b-exp-0924\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 1048576,\n        \"max_output_tokens\":
        8192,\n        \"max_images_per_prompt\": 3000,\n        \"max_videos_per_prompt\":
        10,\n        \"max_video_length\": 1,\n        \"max_audio_length_hours\":
        8.4,\n        \"max_audio_per_prompt\": 1,\n        \"max_pdf_size_mb\": 30,
        \n        \"input_cost_per_token\": 0,\n        \"input_cost_per_token_above_128k_tokens\":
        0,\n        \"output_cost_per_token\": 0,\n        \"output_cost_per_token_above_128k_tokens\":
        0,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_prompt_caching\": true,\n        \"tpm\": 4000000,\n
        \       \"rpm\": 4000,\n        \"source\": \"https://ai.google.dev/pricing\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini/gemini-exp-1114\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30, \n        \"input_cost_per_token\": 0,\n
        \       \"input_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_token\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"tpm\": 4000000,\n        \"rpm\": 1000,\n        \"source\":
        \"https://ai.google.dev/pricing\",\n        \"metadata\": {\n            \"notes\":
        \"Rate limits not documented for gemini-exp-1114. Assuming same as gemini-1.5-pro.\",\n
        \           \"supports_tool_choice\": true\n        }\n    },\n    \"gemini/gemini-exp-1206\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 2097152,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30, \n        \"input_cost_per_token\": 0,\n
        \       \"input_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_token\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"tpm\": 4000000,\n        \"rpm\": 1000,\n        \"source\":
        \"https://ai.google.dev/pricing\",\n        \"metadata\": {\n            \"notes\":
        \"Rate limits not documented for gemini-exp-1206. Assuming same as gemini-1.5-pro.\",\n
        \           \"supports_tool_choice\": true\n        }\n    },\n    \"gemini/gemini-1.5-flash-exp-0827\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30, \n        \"input_cost_per_token\": 0,\n
        \       \"input_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_token\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"tpm\": 4000000,\n
        \       \"rpm\": 2000,\n        \"source\": \"https://ai.google.dev/pricing\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini/gemini-1.5-flash-8b-exp-0827\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30, \n        \"input_cost_per_token\": 0,\n
        \       \"input_cost_per_token_above_128k_tokens\": 0,\n        \"output_cost_per_token\":
        0,\n        \"output_cost_per_token_above_128k_tokens\": 0,\n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_system_messages\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_response_schema\": true,\n        \"tpm\": 4000000,\n
        \       \"rpm\": 4000,\n        \"source\": \"https://ai.google.dev/pricing\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini/gemini-pro\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 32760,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.00000035, \n        \"input_cost_per_token_above_128k_tokens\":
        0.0000007, \n        \"output_cost_per_token\": 0.00000105, \n        \"output_cost_per_token_above_128k_tokens\":
        0.0000021, \n        \"litellm_provider\": \"gemini\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"rpd\":
        30000,\n        \"tpm\": 120000,\n        \"rpm\": 360,\n        \"source\":
        \"https://ai.google.dev/gemini-api/docs/models/gemini\",\n        \"supports_tool_choice\":
        true\n    },\n    \"gemini/gemini-1.5-pro\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 2097152,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 0.0000035, \n        \"input_cost_per_token_above_128k_tokens\":
        0.000007, \n        \"output_cost_per_token\": 0.0000105, \n        \"output_cost_per_token_above_128k_tokens\":
        0.000021, \n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true, \n        \"supports_response_schema\": true, \n        \"tpm\": 4000000,\n
        \       \"rpm\": 1000,\n        \"source\": \"https://ai.google.dev/pricing\"\n
        \   },\n    \"gemini/gemini-1.5-pro-002\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 2097152,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 0.0000035, \n        \"input_cost_per_token_above_128k_tokens\":
        0.000007, \n        \"output_cost_per_token\": 0.0000105, \n        \"output_cost_per_token_above_128k_tokens\":
        0.000021, \n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true, \n        \"supports_response_schema\": true, \n        \"supports_prompt_caching\":
        true,\n        \"tpm\": 4000000,\n        \"rpm\": 1000,\n        \"source\":
        \"https://ai.google.dev/pricing\",\n        \"deprecation_date\": \"2025-09-24\"\n
        \   },\n    \"gemini/gemini-1.5-pro-001\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 2097152,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 0.0000035, \n        \"input_cost_per_token_above_128k_tokens\":
        0.000007, \n        \"output_cost_per_token\": 0.0000105, \n        \"output_cost_per_token_above_128k_tokens\":
        0.000021, \n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true, \n        \"supports_response_schema\": true, \n        \"supports_prompt_caching\":
        true,\n        \"tpm\": 4000000,\n        \"rpm\": 1000,\n        \"source\":
        \"https://ai.google.dev/pricing\",\n        \"deprecation_date\": \"2025-05-24\"\n
        \   },\n    \"gemini/gemini-1.5-pro-exp-0801\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 2097152,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0000035,\n        \"input_cost_per_token_above_128k_tokens\":
        0.000007,\n        \"output_cost_per_token\": 0.0000105,\n        \"output_cost_per_token_above_128k_tokens\":
        0.000021,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true,\n        \"tpm\": 4000000,\n
        \       \"rpm\": 1000,\n        \"source\": \"https://ai.google.dev/pricing\"\n
        \   },\n    \"gemini/gemini-1.5-pro-exp-0827\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 2097152,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0,\n        \"input_cost_per_token_above_128k_tokens\":
        0,\n        \"output_cost_per_token\": 0,\n        \"output_cost_per_token_above_128k_tokens\":
        0,\n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true,\n        \"tpm\": 4000000,\n
        \       \"rpm\": 1000,\n        \"source\": \"https://ai.google.dev/pricing\"\n
        \   },\n    \"gemini/gemini-1.5-pro-latest\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 1048576,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 0.0000035, \n        \"input_cost_per_token_above_128k_tokens\":
        0.000007, \n        \"output_cost_per_token\": 0.00000105, \n        \"output_cost_per_token_above_128k_tokens\":
        0.000021, \n        \"litellm_provider\": \"gemini\",\n        \"mode\": \"chat\",\n
        \       \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true, \n        \"supports_response_schema\": true, \n        \"tpm\": 4000000,\n
        \       \"rpm\": 1000,\n        \"source\": \"https://ai.google.dev/pricing\"\n
        \   },\n    \"gemini/gemini-pro-vision\": {\n        \"max_tokens\": 2048,\n
        \       \"max_input_tokens\": 30720,\n        \"max_output_tokens\": 2048,\n
        \       \"input_cost_per_token\": 0.00000035, \n        \"input_cost_per_token_above_128k_tokens\":
        0.0000007, \n        \"output_cost_per_token\": 0.00000105, \n        \"output_cost_per_token_above_128k_tokens\":
        0.0000021, \n        \"litellm_provider\": \"gemini\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"rpd\": 30000,\n        \"tpm\": 120000,\n        \"rpm\":
        360,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini/gemini-gemma-2-27b-it\":
        {\n        \"max_tokens\": 8192,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        0.00000035, \n        \"output_cost_per_token\": 0.00000105, \n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"gemini/gemini-gemma-2-9b-it\":
        {\n        \"max_tokens\": 8192,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        0.00000035, \n        \"output_cost_per_token\": 0.00000105, \n        \"litellm_provider\":
        \"gemini\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"command-a-03-2025\":
        {\n        \"max_tokens\": 8000,\n        \"max_input_tokens\": 256000,\n
        \       \"max_output_tokens\": 8000,\n        \"input_cost_per_token\": 0.0000025,\n
        \       \"output_cost_per_token\": 0.00001,\n        \"litellm_provider\":
        \"cohere_chat\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"command-r\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000015,\n
        \       \"output_cost_per_token\": 0.0000006,\n        \"litellm_provider\":
        \"cohere_chat\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"command-r-08-2024\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000015,\n
        \       \"output_cost_per_token\": 0.0000006,\n        \"litellm_provider\":
        \"cohere_chat\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"command-r7b-12-2024\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000015,\n
        \       \"output_cost_per_token\": 0.0000000375,\n        \"litellm_provider\":
        \"cohere_chat\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"source\": \"https://docs.cohere.com/v2/docs/command-r7b\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"command-light\": {\n
        \       \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000003,\n        \"output_cost_per_token\":
        0.0000006,\n        \"litellm_provider\": \"cohere_chat\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"command-r-plus\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.0000025,\n
        \       \"output_cost_per_token\": 0.00001,\n        \"litellm_provider\":
        \"cohere_chat\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"command-r-plus-08-2024\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.0000025,\n
        \       \"output_cost_per_token\": 0.00001,\n        \"litellm_provider\":
        \"cohere_chat\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"command-nightly\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000001,\n        \"output_cost_per_token\":
        0.000002,\n        \"litellm_provider\": \"cohere\",\n        \"mode\": \"completion\"\n
        \   },\n     \"command\": {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\":
        4096,\n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.000001,\n        \"output_cost_per_token\": 0.000002,\n        \"litellm_provider\":
        \"cohere\",\n        \"mode\": \"completion\"\n    },\n    \"rerank-v3.5\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"max_query_tokens\": 2048,\n        \"input_cost_per_token\":
        0.0,\n        \"input_cost_per_query\": 0.002,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"cohere\",\n        \"mode\": \"rerank\"\n
        \   },\n    \"rerank-english-v3.0\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        4096,\n        \"max_output_tokens\": 4096,\n        \"max_query_tokens\":
        2048,\n        \"input_cost_per_token\": 0.0,\n        \"input_cost_per_query\":
        0.002,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"cohere\",\n        \"mode\": \"rerank\"\n    },\n    \"rerank-multilingual-v3.0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"max_query_tokens\": 2048,\n        \"input_cost_per_token\":
        0.0,\n        \"input_cost_per_query\": 0.002,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"cohere\",\n        \"mode\": \"rerank\"\n
        \   },\n    \"rerank-english-v2.0\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        4096,\n        \"max_output_tokens\": 4096,\n        \"max_query_tokens\":
        2048,\n        \"input_cost_per_token\": 0.0,\n        \"input_cost_per_query\":
        0.002,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"cohere\",\n        \"mode\": \"rerank\"\n    },\n    \"rerank-multilingual-v2.0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"max_query_tokens\": 2048,\n        \"input_cost_per_token\":
        0.0,\n        \"input_cost_per_query\": 0.002,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"cohere\",\n        \"mode\": \"rerank\"\n
        \   },\n    \"embed-english-light-v3.0\": {\n        \"max_tokens\": 1024,
        \n        \"max_input_tokens\": 1024,\n        \"input_cost_per_token\": 0.00000010,\n
        \       \"output_cost_per_token\": 0.00000,\n        \"litellm_provider\":
        \"cohere\",\n        \"mode\": \"embedding\"\n    },\n    \"embed-multilingual-v3.0\":
        {\n        \"max_tokens\": 1024, \n        \"max_input_tokens\": 1024,\n        \"input_cost_per_token\":
        0.00000010,\n        \"output_cost_per_token\": 0.00000,\n        \"litellm_provider\":
        \"cohere\",\n        \"supports_embedding_image_input\": true,\n        \"mode\":
        \"embedding\"\n    },\n    \"embed-english-v2.0\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 4096,\n        \"input_cost_per_token\":
        0.00000010,\n        \"output_cost_per_token\": 0.00000,\n        \"litellm_provider\":
        \"cohere\",\n        \"mode\": \"embedding\"\n    },\n    \"embed-english-light-v2.0\":
        {\n        \"max_tokens\": 1024, \n        \"max_input_tokens\": 1024,\n        \"input_cost_per_token\":
        0.00000010,\n        \"output_cost_per_token\": 0.00000,\n        \"litellm_provider\":
        \"cohere\",\n        \"mode\": \"embedding\"\n    },\n    \"embed-multilingual-v2.0\":
        {\n        \"max_tokens\": 768, \n        \"max_input_tokens\": 768,\n        \"input_cost_per_token\":
        0.00000010,\n        \"output_cost_per_token\": 0.00000,\n        \"litellm_provider\":
        \"cohere\",\n        \"mode\": \"embedding\"\n    },\n    \"embed-english-v3.0\":
        {\n        \"max_tokens\": 1024, \n        \"max_input_tokens\": 1024,\n        \"input_cost_per_token\":
        0.00000010,\n        \"input_cost_per_image\": 0.0001,\n        \"output_cost_per_token\":
        0.00000,\n        \"litellm_provider\": \"cohere\",\n        \"mode\": \"embedding\",\n
        \       \"supports_image_input\": true,\n        \"supports_embedding_image_input\":
        true,\n        \"metadata\": {\n            \"notes\": \"'supports_image_input'
        is a deprecated field. Use 'supports_embedding_image_input' instead.\"\n        }\n
        \   },\n    \"replicate/meta/llama-2-13b\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 4096,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0.0000005,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/meta/llama-2-13b-chat\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0.0000005,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/meta/llama-2-70b\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000065,\n        \"output_cost_per_token\":
        0.00000275,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/meta/llama-2-70b-chat\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000065,\n        \"output_cost_per_token\":
        0.00000275,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/meta/llama-2-7b\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000005,\n        \"output_cost_per_token\":
        0.00000025,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/meta/llama-2-7b-chat\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000005,\n        \"output_cost_per_token\":
        0.00000025,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/meta/llama-3-70b\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.00000065,\n        \"output_cost_per_token\":
        0.00000275,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/meta/llama-3-70b-instruct\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.00000065,\n        \"output_cost_per_token\":
        0.00000275,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/meta/llama-3-8b\":
        {\n        \"max_tokens\": 8086,\n        \"max_input_tokens\": 8086,\n        \"max_output_tokens\":
        8086,\n        \"input_cost_per_token\": 0.00000005,\n        \"output_cost_per_token\":
        0.00000025,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/meta/llama-3-8b-instruct\":
        {\n        \"max_tokens\": 8086,\n        \"max_input_tokens\": 8086,\n        \"max_output_tokens\":
        8086,\n        \"input_cost_per_token\": 0.00000005,\n        \"output_cost_per_token\":
        0.00000025,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/mistralai/mistral-7b-v0.1\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000005,\n        \"output_cost_per_token\":
        0.00000025,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/mistralai/mistral-7b-instruct-v0.2\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000005,\n        \"output_cost_per_token\":
        0.00000025,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"replicate/mistralai/mixtral-8x7b-instruct-v0.1\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000003,\n        \"output_cost_per_token\":
        0.000001,\n        \"litellm_provider\": \"replicate\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/deepseek/deepseek-r1\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 65336,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.00000055,\n        \"input_cost_per_token_cache_hit\":
        0.00000014,\n        \"output_cost_per_token\": 0.00000219,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true, \n        \"supports_assistant_prefill\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_prompt_caching\":
        true\n    },\n    \"openrouter/deepseek/deepseek-chat\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 65536,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.00000014,\n        \"output_cost_per_token\":
        0.00000028,\n        \"litellm_provider\": \"openrouter\",\n        \"supports_prompt_caching\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"openrouter/deepseek/deepseek-coder\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 66000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000014,\n        \"output_cost_per_token\":
        0.00000028,\n        \"litellm_provider\": \"openrouter\",\n        \"supports_prompt_caching\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"openrouter/microsoft/wizardlm-2-8x22b:nitro\": {\n        \"max_tokens\":
        65536,\n        \"input_cost_per_token\": 0.000001,\n        \"output_cost_per_token\":
        0.000001,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/google/gemini-pro-1.5\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1000000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.0000025,\n
        \       \"output_cost_per_token\": 0.0000075,\n        \"input_cost_per_image\":
        0.00265, \n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/google/gemini-2.0-flash-001\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 1048576,\n
        \       \"max_output_tokens\": 8192,\n        \"max_images_per_prompt\": 3000,\n
        \       \"max_videos_per_prompt\": 10,\n        \"max_video_length\": 1,\n
        \       \"max_audio_length_hours\": 8.4,\n        \"max_audio_per_prompt\":
        1,\n        \"max_pdf_size_mb\": 30,\n        \"input_cost_per_audio_token\":
        0.0000007,\n        \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0.0000004,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_audio_output\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/mistralai/mixtral-8x22b-instruct\": {\n        \"max_tokens\":
        65536,\n        \"input_cost_per_token\": 0.00000065,\n        \"output_cost_per_token\":
        0.00000065,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/cohere/command-r-plus\":
        {\n        \"max_tokens\": 128000,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/databricks/dbrx-instruct\": {\n        \"max_tokens\":
        32768,\n        \"input_cost_per_token\": 0.0000006,\n        \"output_cost_per_token\":
        0.0000006,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/anthropic/claude-3-haiku\":
        {\n        \"max_tokens\": 200000,\n        \"input_cost_per_token\": 0.00000025,\n
        \       \"output_cost_per_token\": 0.00000125,\n        \"input_cost_per_image\":
        0.0004, \n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/anthropic/claude-3-5-haiku\":
        {\n        \"max_tokens\": 200000,\n        \"input_cost_per_token\": 0.000001,\n
        \       \"output_cost_per_token\": 0.000005,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/anthropic/claude-3-haiku-20240307\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000025,\n
        \       \"output_cost_per_token\": 0.00000125,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        264,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/anthropic/claude-3-5-haiku-20241022\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.000001,\n
        \       \"output_cost_per_token\": 0.000005,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"tool_use_system_prompt_tokens\": 264,\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/anthropic/claude-3.5-sonnet\": {\n        \"supports_computer_use\":
        true,\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/anthropic/claude-3.5-sonnet:beta\": {\n        \"supports_computer_use\":
        true,\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/anthropic/claude-3.7-sonnet\":
        {\n        \"supports_computer_use\": true,\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000015,\n        \"input_cost_per_image\": 0.0048,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_reasoning\":
        true,\n        \"tool_use_system_prompt_tokens\": 159,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/anthropic/claude-3.7-sonnet:beta\":
        {\n        \"supports_computer_use\": true,\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000015,\n        \"input_cost_per_image\": 0.0048,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_reasoning\":
        true,\n        \"tool_use_system_prompt_tokens\": 159,\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/anthropic/claude-3-sonnet\": {\n        \"max_tokens\":
        200000,\n        \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000015,\n        \"input_cost_per_image\": 0.0048,  \n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/mistralai/mistral-large\": {\n        \"max_tokens\":
        32000,\n        \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"mistralai/mistral-small-3.1-24b-instruct\":
        {\n        \"max_tokens\": 32000,\n        \"input_cost_per_token\": 0.0000001,\n
        \       \"output_cost_per_token\": 0.0000003,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/cognitivecomputations/dolphin-mixtral-8x7b\":
        {\n        \"max_tokens\": 32769,\n        \"input_cost_per_token\": 0.0000005,\n
        \       \"output_cost_per_token\": 0.0000005,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/google/gemini-pro-vision\": {\n        \"max_tokens\":
        45875,\n        \"input_cost_per_token\": 0.000000125,\n        \"output_cost_per_token\":
        0.000000375,\n        \"input_cost_per_image\": 0.0025,  \n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/fireworks/firellava-13b\": {\n        \"max_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000002,\n        \"output_cost_per_token\":
        0.0000002,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/meta-llama/llama-3-8b-instruct:free\":
        {\n        \"max_tokens\": 8192,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"openrouter\",\n
        \       \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n    },\n
        \   \"openrouter/meta-llama/llama-3-8b-instruct:extended\": {\n        \"max_tokens\":
        16384,\n        \"input_cost_per_token\": 0.000000225,\n        \"output_cost_per_token\":
        0.00000225,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/meta-llama/llama-3-70b-instruct:nitro\":
        {\n        \"max_tokens\": 8192,\n        \"input_cost_per_token\": 0.0000009,\n
        \       \"output_cost_per_token\": 0.0000009,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/meta-llama/llama-3-70b-instruct\": {\n        \"max_tokens\":
        8192,\n        \"input_cost_per_token\": 0.00000059,\n        \"output_cost_per_token\":
        0.00000079,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/o1\":
        {\n        \"max_tokens\": 100000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 100000,\n        \"input_cost_per_token\":
        0.000015,\n        \"output_cost_per_token\": 0.00006,\n        \"cache_read_input_token_cost\":
        0.0000075,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_system_messages\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/o1-mini\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 65536,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000012,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        false,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/o1-mini-2024-09-12\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 65536,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000012,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        false,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/o1-preview\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 0.000015,\n
        \       \"output_cost_per_token\": 0.000060,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        false,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/o1-preview-2024-09-12\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 0.000015,\n
        \       \"output_cost_per_token\": 0.000060,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        false,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/o3-mini\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 65536,\n        \"input_cost_per_token\": 0.0000011,\n
        \       \"output_cost_per_token\": 0.0000044,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_vision\": false,\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/openai/o3-mini-high\": {\n        \"max_tokens\":
        65536,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        65536,\n        \"input_cost_per_token\": 0.0000011,\n        \"output_cost_per_token\":
        0.0000044,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        false,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/gpt-4o\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.0000025,\n
        \       \"output_cost_per_token\": 0.000010,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/gpt-4o-2024-05-13\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000005,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/gpt-4-vision-preview\":
        {\n        \"max_tokens\": 130000,\n        \"input_cost_per_token\": 0.00001,\n
        \       \"output_cost_per_token\": 0.00003,\n        \"input_cost_per_image\":
        0.01445, \n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/gpt-3.5-turbo\":
        {\n        \"max_tokens\": 4095,\n        \"input_cost_per_token\": 0.0000015,\n
        \       \"output_cost_per_token\": 0.000002,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/openai/gpt-3.5-turbo-16k\": {\n        \"max_tokens\":
        16383,\n        \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000004,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/openai/gpt-4\":
        {\n        \"max_tokens\": 8192,\n        \"input_cost_per_token\": 0.00003,\n
        \       \"output_cost_per_token\": 0.00006,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/anthropic/claude-instant-v1\": {\n        \"max_tokens\":
        100000,\n        \"max_output_tokens\": 8191,\n        \"input_cost_per_token\":
        0.00000163,\n        \"output_cost_per_token\": 0.00000551,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/anthropic/claude-2\": {\n        \"max_tokens\":
        100000,\n        \"max_output_tokens\": 8191,\n        \"input_cost_per_token\":
        0.00001102,\n        \"output_cost_per_token\": 0.00003268,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/anthropic/claude-3-opus\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000015,\n        \"output_cost_per_token\":
        0.000075,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"tool_use_system_prompt_tokens\": 395,\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/google/palm-2-chat-bison\": {\n        \"max_tokens\":
        25804,\n        \"input_cost_per_token\": 0.0000005,\n        \"output_cost_per_token\":
        0.0000005,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/google/palm-2-codechat-bison\":
        {\n        \"max_tokens\": 20070,\n        \"input_cost_per_token\": 0.0000005,\n
        \       \"output_cost_per_token\": 0.0000005,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/meta-llama/llama-2-13b-chat\": {\n        \"max_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000002,\n        \"output_cost_per_token\":
        0.0000002,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/meta-llama/llama-2-70b-chat\":
        {\n        \"max_tokens\": 4096,\n        \"input_cost_per_token\": 0.0000015,\n
        \       \"output_cost_per_token\": 0.0000015,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/meta-llama/codellama-34b-instruct\": {\n        \"max_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0000005,\n        \"output_cost_per_token\":
        0.0000005,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/nousresearch/nous-hermes-llama2-13b\":
        {\n        \"max_tokens\": 4096,\n        \"input_cost_per_token\": 0.0000002,\n
        \       \"output_cost_per_token\": 0.0000002,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/mancer/weaver\": {\n        \"max_tokens\":
        8000,\n        \"input_cost_per_token\": 0.000005625,\n        \"output_cost_per_token\":
        0.000005625,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/gryphe/mythomax-l2-13b\":
        {\n        \"max_tokens\": 8192,\n        \"input_cost_per_token\": 0.000001875,\n
        \       \"output_cost_per_token\": 0.000001875,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/jondurbin/airoboros-l2-70b-2.1\": {\n        \"max_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000013875,\n        \"output_cost_per_token\":
        0.000013875,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/undi95/remm-slerp-l2-13b\":
        {\n        \"max_tokens\": 6144,\n        \"input_cost_per_token\": 0.000001875,\n
        \       \"output_cost_per_token\": 0.000001875,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/pygmalionai/mythalion-13b\": {\n        \"max_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000001875,\n        \"output_cost_per_token\":
        0.000001875,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"openrouter/mistralai/mistral-7b-instruct\":
        {\n        \"max_tokens\": 8192,\n        \"input_cost_per_token\": 0.00000013,\n
        \       \"output_cost_per_token\": 0.00000013,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"openrouter/mistralai/mistral-7b-instruct:free\": {\n        \"max_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"openrouter\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"openrouter/qwen/qwen-2.5-coder-32b-instruct\":
        {\n        \"max_tokens\": 33792,\n        \"max_input_tokens\": 33792,\n
        \       \"max_output_tokens\": 33792,\n        \"input_cost_per_token\": 0.00000018,\n
        \       \"output_cost_per_token\": 0.00000018,\n        \"litellm_provider\":
        \"openrouter\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"j2-ultra\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        0.000015,\n        \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"ai21\",\n        \"mode\": \"completion\"\n    },\n    \"jamba-1.5-mini@001\":
        {\n        \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n
        \       \"max_output_tokens\": 256000,\n        \"input_cost_per_token\":
        0.0000002,\n        \"output_cost_per_token\": 0.0000004,\n        \"litellm_provider\":
        \"ai21\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"jamba-1.5-large@001\": {\n        \"max_tokens\": 256000,\n
        \       \"max_input_tokens\": 256000,\n        \"max_output_tokens\": 256000,\n
        \       \"input_cost_per_token\": 0.000002,\n        \"output_cost_per_token\":
        0.000008,\n        \"litellm_provider\": \"ai21\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"jamba-1.5\": {\n        \"max_tokens\":
        256000,\n        \"max_input_tokens\": 256000,\n        \"max_output_tokens\":
        256000,\n        \"input_cost_per_token\": 0.0000002,\n        \"output_cost_per_token\":
        0.0000004,\n        \"litellm_provider\": \"ai21\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"jamba-1.5-mini\": {\n
        \       \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n        \"max_output_tokens\":
        256000,\n        \"input_cost_per_token\": 0.0000002,\n        \"output_cost_per_token\":
        0.0000004,\n        \"litellm_provider\": \"ai21\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"jamba-1.5-large\": {\n
        \       \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n        \"max_output_tokens\":
        256000,\n        \"input_cost_per_token\": 0.000002,\n        \"output_cost_per_token\":
        0.000008,\n        \"litellm_provider\": \"ai21\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"jamba-large-1.6\": {\n
        \       \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n        \"max_output_tokens\":
        256000,\n        \"input_cost_per_token\": 0.000002,\n        \"output_cost_per_token\":
        0.000008,\n        \"litellm_provider\": \"ai21\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"jamba-mini-1.6\": {\n
        \       \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n        \"max_output_tokens\":
        256000,\n        \"input_cost_per_token\": 0.0000002,\n        \"output_cost_per_token\":
        0.0000004,\n        \"litellm_provider\": \"ai21\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"j2-mid\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.00001,\n        \"output_cost_per_token\":
        0.00001,\n        \"litellm_provider\": \"ai21\",\n        \"mode\": \"completion\"\n
        \   },\n    \"j2-light\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        0.000003,\n        \"output_cost_per_token\": 0.000003,\n        \"litellm_provider\":
        \"ai21\",\n        \"mode\": \"completion\"\n    },\n    \"dolphin\": {\n
        \       \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.0000005,\n        \"output_cost_per_token\":
        0.0000005,\n        \"litellm_provider\": \"nlp_cloud\",\n        \"mode\":
        \"completion\"\n    },\n    \"chatdolphin\": {\n        \"max_tokens\": 16384,\n
        \       \"max_input_tokens\": 16384,\n        \"max_output_tokens\": 16384,\n
        \       \"input_cost_per_token\": 0.0000005,\n        \"output_cost_per_token\":
        0.0000005,\n        \"litellm_provider\": \"nlp_cloud\",\n        \"mode\":
        \"chat\"\n    },\n    \"luminous-base\": {\n        \"max_tokens\": 2048,
        \n        \"input_cost_per_token\": 0.00003,\n        \"output_cost_per_token\":
        0.000033,\n        \"litellm_provider\": \"aleph_alpha\",\n        \"mode\":
        \"completion\"\n    },\n    \"luminous-base-control\": {\n        \"max_tokens\":
        2048, \n        \"input_cost_per_token\": 0.0000375,\n        \"output_cost_per_token\":
        0.00004125,\n        \"litellm_provider\": \"aleph_alpha\",\n        \"mode\":
        \"chat\"\n    },\n    \"luminous-extended\": {\n        \"max_tokens\": 2048,
        \n        \"input_cost_per_token\": 0.000045,\n        \"output_cost_per_token\":
        0.0000495,\n        \"litellm_provider\": \"aleph_alpha\",\n        \"mode\":
        \"completion\"\n    },\n    \"luminous-extended-control\": {\n        \"max_tokens\":
        2048, \n        \"input_cost_per_token\": 0.00005625,\n        \"output_cost_per_token\":
        0.000061875,\n        \"litellm_provider\": \"aleph_alpha\",\n        \"mode\":
        \"chat\"\n    },\n    \"luminous-supreme\": {\n        \"max_tokens\": 2048,
        \n        \"input_cost_per_token\": 0.000175,\n        \"output_cost_per_token\":
        0.0001925,\n        \"litellm_provider\": \"aleph_alpha\",\n        \"mode\":
        \"completion\"\n    },\n    \"luminous-supreme-control\": {\n        \"max_tokens\":
        2048, \n        \"input_cost_per_token\": 0.00021875,\n        \"output_cost_per_token\":
        0.000240625,\n        \"litellm_provider\": \"aleph_alpha\",\n        \"mode\":
        \"chat\"\n    },\n    \"ai21.j2-mid-v1\": {\n        \"max_tokens\": 8191,
        \n        \"max_input_tokens\": 8191, \n        \"max_output_tokens\": 8191,
        \n        \"input_cost_per_token\": 0.0000125,\n        \"output_cost_per_token\":
        0.0000125,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\"\n    },\n    \"ai21.j2-ultra-v1\": {\n        \"max_tokens\": 8191,
        \n        \"max_input_tokens\": 8191, \n        \"max_output_tokens\": 8191,
        \n        \"input_cost_per_token\": 0.0000188,\n        \"output_cost_per_token\":
        0.0000188,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\"\n    },\n    \"ai21.jamba-instruct-v1:0\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 70000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000005,\n        \"output_cost_per_token\":
        0.0000007,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_system_messages\": true\n    },\n    \"ai21.jamba-1-5-large-v1:0\":
        {\n        \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n
        \       \"max_output_tokens\": 256000,\n        \"input_cost_per_token\":
        0.000002,\n        \"output_cost_per_token\": 0.000008,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"ai21.jamba-1-5-mini-v1:0\":
        {\n        \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n
        \       \"max_output_tokens\": 256000,\n        \"input_cost_per_token\":
        0.0000002,\n        \"output_cost_per_token\": 0.0000004,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"amazon.rerank-v1:0\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 32000,\n
        \       \"max_output_tokens\": 32000,\n        \"max_query_tokens\": 32000,\n
        \       \"max_document_chunks_per_query\": 100,\n        \"max_tokens_per_document_chunk\":
        512,\n        \"input_cost_per_token\": 0.0,\n        \"input_cost_per_query\":
        0.001,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"rerank\"\n    },\n    \"amazon.titan-text-lite-v1\":
        {\n        \"max_tokens\": 4000, \n        \"max_input_tokens\": 42000,\n
        \       \"max_output_tokens\": 4000, \n        \"input_cost_per_token\": 0.0000003,\n
        \       \"output_cost_per_token\": 0.0000004,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"amazon.titan-text-express-v1\":
        {\n        \"max_tokens\": 8000, \n        \"max_input_tokens\": 42000,\n
        \       \"max_output_tokens\": 8000, \n        \"input_cost_per_token\": 0.0000013,\n
        \       \"output_cost_per_token\": 0.0000017,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"amazon.titan-text-premier-v1:0\":
        {\n        \"max_tokens\": 32000, \n        \"max_input_tokens\": 42000,\n
        \       \"max_output_tokens\": 32000, \n        \"input_cost_per_token\":
        0.0000005,\n        \"output_cost_per_token\": 0.0000015,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"amazon.titan-embed-text-v1\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"output_vector_size\": 1536,\n        \"input_cost_per_token\": 0.0000001,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"bedrock\",
        \n        \"mode\": \"embedding\"\n    },\n    \"amazon.titan-embed-text-v2:0\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"output_vector_size\": 1024,\n        \"input_cost_per_token\": 0.0000002,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"bedrock\",
        \n        \"mode\": \"embedding\"\n    },\n    \"amazon.titan-embed-image-v1\":
        {\n        \"max_tokens\": 128, \n        \"max_input_tokens\": 128, \n        \"output_vector_size\":
        1024,\n        \"input_cost_per_token\": 0.0000008,\n        \"input_cost_per_image\":
        0.00006,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"bedrock\", \n        \"supports_image_input\": true,\n        \"supports_embedding_image_input\":
        true,\n        \"mode\": \"embedding\",\n        \"source\": \"https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1#/providers?model=amazon.titan-image-generator-v1\",\n
        \       \"metadata\": {\n            \"notes\": \"'supports_image_input' is
        a deprecated field. Use 'supports_embedding_image_input' instead.\"\n        }\n
        \   },\n    \"mistral.mistral-7b-instruct-v0:2\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000015,\n        \"output_cost_per_token\":
        0.0000002,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"mistral.mixtral-8x7b-instruct-v0:1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000045,\n        \"output_cost_per_token\":
        0.0000007,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"mistral.mistral-large-2402-v1:0\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"mistral.mistral-large-2407-v1:0\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000009,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"mistral.mistral-small-2402-v1:0\": {\n        \"max_tokens\":
        8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000001,\n        \"output_cost_per_token\":
        0.000003,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-west-2/mistral.mixtral-8x7b-instruct-v0:1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000045,\n        \"output_cost_per_token\":
        0.0000007,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"bedrock/us-east-1/mistral.mixtral-8x7b-instruct-v0:1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000045,\n        \"output_cost_per_token\":
        0.0000007,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"bedrock/eu-west-3/mistral.mixtral-8x7b-instruct-v0:1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000059,\n        \"output_cost_per_token\":
        0.00000091,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"bedrock/us-west-2/mistral.mistral-7b-instruct-v0:2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000015,\n        \"output_cost_per_token\":
        0.0000002,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"bedrock/us-east-1/mistral.mistral-7b-instruct-v0:2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000015,\n        \"output_cost_per_token\":
        0.0000002,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"bedrock/eu-west-3/mistral.mistral-7b-instruct-v0:2\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.0000002,\n        \"output_cost_per_token\":
        0.00000026,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"bedrock/us-east-1/mistral.mistral-large-2402-v1:0\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-west-2/mistral.mistral-large-2402-v1:0\": {\n
        \       \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/eu-west-3/mistral.mistral-large-2402-v1:0\": {\n
        \       \"max_tokens\": 8191,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.0000104,\n        \"output_cost_per_token\":
        0.0000312,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"amazon.nova-micro-v1:0\": {\n        \"max_tokens\": 4096,
        \n        \"max_input_tokens\": 300000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.000000035,\n        \"output_cost_per_token\":
        0.00000014,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"us.amazon.nova-micro-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 300000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000000035,\n
        \       \"output_cost_per_token\": 0.00000014,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"eu.amazon.nova-micro-v1:0\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 300000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000000046,\n        \"output_cost_per_token\":
        0.000000184,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"amazon.nova-lite-v1:0\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000006,\n
        \       \"output_cost_per_token\": 0.00000024,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"us.amazon.nova-lite-v1:0\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000006,\n        \"output_cost_per_token\":
        0.00000024,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"eu.amazon.nova-lite-v1:0\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000000078,\n
        \       \"output_cost_per_token\": 0.000000312,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"amazon.nova-pro-v1:0\": {\n        \"max_tokens\": 4096,
        \n        \"max_input_tokens\": 300000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.0000008,\n        \"output_cost_per_token\":
        0.0000032,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true\n    },\n    \"us.amazon.nova-pro-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 300000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.0000008,\n
        \       \"output_cost_per_token\": 0.0000032,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true\n    },\n    \"1024-x-1024/50-steps/bedrock/amazon.nova-canvas-v1:0\":
        {\n      \"max_input_tokens\": 2600,\n      \"output_cost_per_image\": 0.06,\n
        \     \"litellm_provider\": \"bedrock\",\n      \"mode\": \"image_generation\"\n
        \   },\n    \"eu.amazon.nova-pro-v1:0\": {\n        \"max_tokens\": 4096,
        \n        \"max_input_tokens\": 300000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.00000105,\n        \"output_cost_per_token\":
        0.0000042,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://aws.amazon.com/bedrock/pricing/\"\n
        \   },\n    \"us.amazon.nova-premier-v1:0\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 1000000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.0000025,\n        \"output_cost_per_token\":
        0.0000125,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_prompt_caching\":
        false,\n        \"supports_response_schema\": true\n    },\n    \"anthropic.claude-3-sonnet-20240229-v1:0\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/invoke/anthropic.claude-3-5-sonnet-20240620-v1:0\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true,\n        \"metadata\": {\n
        \           \"notes\": \"Anthropic via Invoke route does not currently support
        pdf input.\"\n        }\n    },\n    \"anthropic.claude-3-5-sonnet-20240620-v1:0\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"anthropic.claude-opus-4-20250514-v1:0\": {\n        \"max_tokens\":
        32000,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        32000,\n        \"input_cost_per_token\": 15e-6,\n        \"output_cost_per_token\":
        75e-6,\n        \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        1e-2, \n            \"search_context_size_medium\": 1e-2,\n            \"search_context_size_high\":
        1e-2\n        },\n        \"cache_creation_input_token_cost\": 18.75e-6,\n
        \       \"cache_read_input_token_cost\": 1.5e-6,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"anthropic.claude-sonnet-4-20250514-v1:0\":
        {\n        \"max_tokens\": 64000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 64000,\n        \"input_cost_per_token\": 3e-6,\n
        \       \"output_cost_per_token\": 15e-6,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 1e-2, \n            \"search_context_size_medium\":
        1e-2,\n            \"search_context_size_high\": 1e-2\n        },\n        \"cache_creation_input_token_cost\":
        3.75e-6,\n        \"cache_read_input_token_cost\": 0.3e-6,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"anthropic.claude-3-7-sonnet-20250219-v1:0\":
        {\n        \"supports_computer_use\": true,\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000015,\n        \"cache_creation_input_token_cost\": 0.00000375,\n        \"cache_read_input_token_cost\":
        0.0000003,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_prompt_caching\":
        true, \n        \"supports_response_schema\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_reasoning\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"anthropic.claude-3-5-sonnet-20241022-v2:0\": {\n        \"supports_computer_use\":
        true,\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"cache_creation_input_token_cost\":
        0.00000375,\n        \"cache_read_input_token_cost\": 0.0000003,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_prompt_caching\":
        true, \n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"anthropic.claude-3-haiku-20240307-v1:0\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000025,\n        \"output_cost_per_token\":
        0.00000125,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"anthropic.claude-3-5-haiku-20241022-v1:0\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.0000008,\n
        \       \"output_cost_per_token\": 0.000004,\n        \"cache_creation_input_token_cost\":
        0.000001,\n        \"cache_read_input_token_cost\": 0.00000008,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_assistant_prefill\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"anthropic.claude-3-opus-20240229-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000015,\n
        \       \"output_cost_per_token\": 0.000075,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"us.anthropic.claude-3-sonnet-20240229-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"us.anthropic.claude-3-5-sonnet-20240620-v1:0\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000015,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"us.anthropic.claude-3-5-sonnet-20241022-v2:0\":
        {\n        \"supports_computer_use\": true,\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000015,\n        \"cache_creation_input_token_cost\": 0.00000375,\n        \"cache_read_input_token_cost\":
        0.0000003,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\":
        {\n        \"supports_computer_use\": true,\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 200000,\n        \"max_output_tokens\": 8192,\n
        \       \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000015,\n        \"cache_creation_input_token_cost\": 0.00000375,\n        \"cache_read_input_token_cost\":
        0.0000003,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_vision\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_prompt_caching\":
        true, \n        \"supports_response_schema\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true\n    },\n    \"us.anthropic.claude-opus-4-20250514-v1:0\": {\n        \"max_tokens\":
        32000,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        32000,\n        \"input_cost_per_token\": 15e-6,\n        \"output_cost_per_token\":
        75e-6,\n        \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        1e-2, \n            \"search_context_size_medium\": 1e-2,\n            \"search_context_size_high\":
        1e-2\n        },\n        \"cache_creation_input_token_cost\": 18.75e-6,\n
        \       \"cache_read_input_token_cost\": 1.5e-6,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"us.anthropic.claude-sonnet-4-20250514-v1:0\":
        {\n        \"max_tokens\": 64000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 64000,\n        \"input_cost_per_token\": 3e-6,\n
        \       \"output_cost_per_token\": 15e-6,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 1e-2, \n            \"search_context_size_medium\":
        1e-2,\n            \"search_context_size_high\": 1e-2\n        },\n        \"cache_creation_input_token_cost\":
        3.75e-6,\n        \"cache_read_input_token_cost\": 0.3e-6,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"us.anthropic.claude-3-haiku-20240307-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000025,\n
        \       \"output_cost_per_token\": 0.00000125,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"us.anthropic.claude-3-5-haiku-20241022-v1:0\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0000008,\n        \"output_cost_per_token\":
        0.000004,\n        \"cache_creation_input_token_cost\": 0.000001,\n        \"cache_read_input_token_cost\":
        0.00000008,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"us.anthropic.claude-3-opus-20240229-v1:0\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000015,\n        \"output_cost_per_token\":
        0.000075,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"eu.anthropic.claude-3-sonnet-20240229-v1:0\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000003,\n        \"output_cost_per_token\":
        0.000015,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"eu.anthropic.claude-3-5-sonnet-20240620-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"eu.anthropic.claude-3-5-sonnet-20241022-v2:0\": {\n        \"supports_computer_use\":
        true,\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_prompt_caching\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"eu.anthropic.claude-3-7-sonnet-20250219-v1:0\": {\n        \"supports_computer_use\":
        true,\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.000003,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_assistant_prefill\":
        true,\n        \"supports_prompt_caching\": true, \n        \"supports_response_schema\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"eu.anthropic.claude-3-haiku-20240307-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000025,\n
        \       \"output_cost_per_token\": 0.00000125,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_pdf_input\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"eu.anthropic.claude-opus-4-20250514-v1:0\": {\n        \"max_tokens\":
        32000,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        32000,\n        \"input_cost_per_token\": 15e-6,\n        \"output_cost_per_token\":
        75e-6,\n        \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        1e-2, \n            \"search_context_size_medium\": 1e-2,\n            \"search_context_size_high\":
        1e-2\n        },\n        \"cache_creation_input_token_cost\": 18.75e-6,\n
        \       \"cache_read_input_token_cost\": 1.5e-6,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"eu.anthropic.claude-sonnet-4-20250514-v1:0\":
        {\n        \"max_tokens\": 64000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 64000,\n        \"input_cost_per_token\": 3e-6,\n
        \       \"output_cost_per_token\": 15e-6,\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 1e-2, \n            \"search_context_size_medium\":
        1e-2,\n            \"search_context_size_high\": 1e-2\n        },\n        \"cache_creation_input_token_cost\":
        3.75e-6,\n        \"cache_read_input_token_cost\": 0.3e-6,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"tool_use_system_prompt_tokens\":
        159,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true,\n        \"supports_reasoning\":
        true,\n        \"supports_computer_use\": true\n    },\n    \"eu.anthropic.claude-3-5-haiku-20241022-v1:0\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.00000025,\n
        \       \"output_cost_per_token\": 0.00000125,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_assistant_prefill\": true,\n        \"supports_pdf_input\":
        true,\n        \"supports_prompt_caching\": true,\n        \"supports_response_schema\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"eu.anthropic.claude-3-opus-20240229-v1:0\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000015,\n
        \       \"output_cost_per_token\": 0.000075,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"supports_tool_choice\": true\n    },\n    \"anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.000008,\n
        \       \"output_cost_per_token\": 0.000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-east-1/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.000008,\n
        \       \"output_cost_per_token\": 0.000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-west-2/anthropic.claude-v1\": {\n        \"max_tokens\":
        8191, \n        \"max_input_tokens\": 100000,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/ap-northeast-1/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.000008,\n
        \       \"output_cost_per_token\": 0.000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0455,\n
        \       \"output_cost_per_second\": 0.0455,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.02527,\n
        \       \"output_cost_per_second\": 0.02527,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-central-1/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_token\": 0.000008,\n
        \       \"output_cost_per_token\": 0.000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-central-1/1-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.0415,\n        \"output_cost_per_second\": 0.0415,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-central-1/6-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.02305,\n        \"output_cost_per_second\": 0.02305,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-east-1/1-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.0175,\n        \"output_cost_per_second\": 0.0175,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-east-1/6-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.00972,\n        \"output_cost_per_second\": 0.00972,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-west-2/1-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.0175,\n        \"output_cost_per_second\": 0.0175,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-west-2/6-month-commitment/anthropic.claude-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.00972,\n        \"output_cost_per_second\": 0.00972,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_token\": 0.000008,\n
        \       \"output_cost_per_token\": 0.000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-east-1/anthropic.claude-v2\": {\n        \"max_tokens\":
        8191, \n        \"max_input_tokens\": 100000,\n        \"max_output_tokens\":
        8191, \n        \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/us-west-2/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_token\": 0.000008,\n
        \       \"output_cost_per_token\": 0.000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/ap-northeast-1/anthropic.claude-v2\": {\n        \"max_tokens\":
        8191, \n        \"max_input_tokens\": 100000,\n        \"max_output_tokens\":
        8191, \n        \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.0455,\n        \"output_cost_per_second\": 0.0455,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.02527,\n        \"output_cost_per_second\": 0.02527,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/eu-central-1/anthropic.claude-v2\": {\n        \"max_tokens\":
        8191, \n        \"max_input_tokens\": 100000,\n        \"max_output_tokens\":
        8191, \n        \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.0415,\n        \"output_cost_per_second\": 0.0415,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.02305,\n        \"output_cost_per_second\": 0.02305,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-east-1/1-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.0175,\n        \"output_cost_per_second\": 0.0175,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-east-1/6-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.00972,\n        \"output_cost_per_second\": 0.00972,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-west-2/1-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.0175,\n        \"output_cost_per_second\": 0.0175,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-west-2/6-month-commitment/anthropic.claude-v2\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000,\n
        \       \"max_output_tokens\": 8191, \n        \"input_cost_per_second\":
        0.00972,\n        \"output_cost_per_second\": 0.00972,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"anthropic.claude-v2:1\": {\n        \"max_tokens\": 8191,
        \n        \"max_input_tokens\": 100000, \n        \"max_output_tokens\": 8191,\n
        \       \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/us-east-1/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.000008,\n
        \       \"output_cost_per_token\": 0.000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-west-2/anthropic.claude-v2:1\": {\n        \"max_tokens\":
        8191, \n        \"max_input_tokens\": 100000, \n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/ap-northeast-1/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.000008,\n
        \       \"output_cost_per_token\": 0.000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0455,\n
        \       \"output_cost_per_second\": 0.0455,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.02527,\n
        \       \"output_cost_per_second\": 0.02527,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/eu-central-1/anthropic.claude-v2:1\": {\n        \"max_tokens\":
        8191, \n        \"max_input_tokens\": 100000, \n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.000008,\n        \"output_cost_per_token\":
        0.000024,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/eu-central-1/1-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0415,\n
        \       \"output_cost_per_second\": 0.0415,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/eu-central-1/6-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.02305,\n
        \       \"output_cost_per_second\": 0.02305,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-east-1/1-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0175,\n
        \       \"output_cost_per_second\": 0.0175,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-east-1/6-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.00972,\n
        \       \"output_cost_per_second\": 0.00972,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-west-2/1-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.0175,\n
        \       \"output_cost_per_second\": 0.0175,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-west-2/6-month-commitment/anthropic.claude-v2:1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.00972,\n
        \       \"output_cost_per_second\": 0.00972,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"anthropic.claude-instant-v1\": {\n        \"max_tokens\":
        8191, \n        \"max_input_tokens\": 100000, \n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.0000008,\n        \"output_cost_per_token\":
        0.0000024,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"bedrock/us-east-1/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.0000008,\n
        \       \"output_cost_per_token\": 0.0000024,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-east-1/1-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.011,\n
        \       \"output_cost_per_second\": 0.011,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-east-1/6-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.00611,\n
        \       \"output_cost_per_second\": 0.00611,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-west-2/1-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.011,\n
        \       \"output_cost_per_second\": 0.011,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-west-2/6-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.00611,\n
        \       \"output_cost_per_second\": 0.00611,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/us-west-2/anthropic.claude-instant-v1\": {\n        \"max_tokens\":
        8191, \n        \"max_input_tokens\": 100000, \n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.0000008,\n        \"output_cost_per_token\":
        0.0000024,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"bedrock/ap-northeast-1/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_token\": 0.00000223,\n
        \       \"output_cost_per_token\": 0.00000755,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/ap-northeast-1/1-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.01475,\n
        \       \"output_cost_per_second\": 0.01475,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/ap-northeast-1/6-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.008194,\n
        \       \"output_cost_per_second\": 0.008194,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/eu-central-1/anthropic.claude-instant-v1\": {\n
        \       \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000248,\n        \"output_cost_per_token\":
        0.00000838,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"bedrock/eu-central-1/1-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.01635,\n
        \       \"output_cost_per_second\": 0.01635,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"bedrock/eu-central-1/6-month-commitment/anthropic.claude-instant-v1\":
        {\n        \"max_tokens\": 8191, \n        \"max_input_tokens\": 100000, \n
        \       \"max_output_tokens\": 8191,\n        \"input_cost_per_second\": 0.009083,\n
        \       \"output_cost_per_second\": 0.009083,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"cohere.rerank-v3-5:0\": {\n        \"max_tokens\": 32000,\n
        \       \"max_input_tokens\": 32000,\n        \"max_output_tokens\": 32000,\n
        \       \"max_query_tokens\": 32000,\n        \"max_document_chunks_per_query\":
        100,\n        \"max_tokens_per_document_chunk\": 512,\n        \"input_cost_per_token\":
        0.0,\n        \"input_cost_per_query\": 0.002,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"rerank\"\n
        \   },\n    \"cohere.command-text-v14\": {\n        \"max_tokens\": 4096,
        \n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\": 4096,
        \n        \"input_cost_per_token\": 0.0000015,\n        \"output_cost_per_token\":
        0.0000020,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"bedrock/*/1-month-commitment/cohere.command-text-v14\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_second\": 0.011,\n        \"output_cost_per_second\":
        0.011,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/*/6-month-commitment/cohere.command-text-v14\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_second\": 0.0066027,\n        \"output_cost_per_second\":
        0.0066027,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"cohere.command-light-text-v14\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.0000003,\n        \"output_cost_per_token\":
        0.0000006,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"bedrock/*/1-month-commitment/cohere.command-light-text-v14\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_second\": 0.001902,\n        \"output_cost_per_second\":
        0.001902,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"bedrock/*/6-month-commitment/cohere.command-light-text-v14\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_second\": 0.0011416,\n        \"output_cost_per_second\":
        0.0011416,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"cohere.command-r-plus-v1:0\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.0000030,\n
        \       \"output_cost_per_token\": 0.000015,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_tool_choice\":
        true\n    },\n    \"cohere.command-r-v1:0\": {\n        \"max_tokens\": 4096,
        \n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.0000005,\n        \"output_cost_per_token\":
        0.0000015,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"cohere.embed-english-v3\":
        {\n        \"max_tokens\": 512, \n        \"max_input_tokens\": 512, \n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"bedrock\",                \n        \"mode\": \"embedding\",\n        \"supports_embedding_image_input\":
        true\n    },\n    \"cohere.embed-multilingual-v3\": {\n        \"max_tokens\":
        512, \n        \"max_input_tokens\": 512, \n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"embedding\",\n        \"supports_embedding_image_input\":
        true\n    },\n    \"us.deepseek.r1-v1:0\": {\n        \"max_tokens\": 4096,
        \n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 4096,\n
        \       \"input_cost_per_token\": 0.00000135,\n        \"output_cost_per_token\":
        0.0000054,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_reasoning\": true,\n        \"supports_function_calling\":
        false, \n        \"supports_tool_choice\": false\n\n    },\n    \"meta.llama3-3-70b-instruct-v1:0\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000072,\n
        \       \"output_cost_per_token\": 0.00000072,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true, \n        \"supports_tool_choice\": false\n    },\n    \"meta.llama2-13b-chat-v1\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096, \n
        \       \"max_output_tokens\": 4096, \n        \"input_cost_per_token\": 0.00000075,\n
        \       \"output_cost_per_token\": 0.000001,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"meta.llama2-70b-chat-v1\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096, \n
        \       \"max_output_tokens\": 4096, \n        \"input_cost_per_token\": 0.00000195,\n
        \       \"output_cost_per_token\": 0.00000256,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"meta.llama3-8b-instruct-v1:0\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.0000003,\n
        \       \"output_cost_per_token\": 0.0000006,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-east-1/meta.llama3-8b-instruct-v1:0\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.0000003,\n
        \       \"output_cost_per_token\": 0.0000006,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-west-1/meta.llama3-8b-instruct-v1:0\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.0000003,\n
        \       \"output_cost_per_token\": 0.0000006,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/ap-south-1/meta.llama3-8b-instruct-v1:0\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.00000036,\n
        \       \"output_cost_per_token\": 0.00000072,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/ca-central-1/meta.llama3-8b-instruct-v1:0\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.00000035,\n
        \       \"output_cost_per_token\": 0.00000069,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-west-1/meta.llama3-8b-instruct-v1:0\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.00000032,\n
        \       \"output_cost_per_token\": 0.00000065,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-west-2/meta.llama3-8b-instruct-v1:0\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.00000039,\n
        \       \"output_cost_per_token\": 0.00000078,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/sa-east-1/meta.llama3-8b-instruct-v1:0\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.0000005,\n
        \       \"output_cost_per_token\": 0.00000101,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"meta.llama3-70b-instruct-v1:0\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.00000265,\n
        \       \"output_cost_per_token\": 0.0000035,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-east-1/meta.llama3-70b-instruct-v1:0\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.00000265,\n
        \       \"output_cost_per_token\": 0.0000035,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/us-west-1/meta.llama3-70b-instruct-v1:0\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.00000265,\n
        \       \"output_cost_per_token\": 0.0000035,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/ap-south-1/meta.llama3-70b-instruct-v1:0\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.00000318,\n
        \       \"output_cost_per_token\": 0.0000042,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/ca-central-1/meta.llama3-70b-instruct-v1:0\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.00000305,\n
        \       \"output_cost_per_token\": 0.00000403,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-west-1/meta.llama3-70b-instruct-v1:0\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.00000286,\n
        \       \"output_cost_per_token\": 0.00000378,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/eu-west-2/meta.llama3-70b-instruct-v1:0\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.00000345,\n
        \       \"output_cost_per_token\": 0.00000455,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"bedrock/sa-east-1/meta.llama3-70b-instruct-v1:0\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.00000445,\n
        \       \"output_cost_per_token\": 0.00000588,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\"\n    },\n    \"meta.llama3-1-8b-instruct-v1:0\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 2048,\n        \"input_cost_per_token\": 0.00000022,\n
        \       \"output_cost_per_token\": 0.00000022,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true, \n        \"supports_tool_choice\": false\n    },\n    \"us.meta.llama3-1-8b-instruct-v1:0\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 2048,\n        \"input_cost_per_token\": 0.00000022,\n
        \       \"output_cost_per_token\": 0.00000022,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true, \n        \"supports_tool_choice\": false\n    },\n    \"meta.llama3-1-70b-instruct-v1:0\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 2048,\n        \"input_cost_per_token\": 0.00000099,\n
        \       \"output_cost_per_token\": 0.00000099,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true, \n        \"supports_tool_choice\": false\n    },\n    \"us.meta.llama3-1-70b-instruct-v1:0\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 2048,\n        \"input_cost_per_token\": 0.00000099,\n
        \       \"output_cost_per_token\": 0.00000099,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true, \n        \"supports_tool_choice\": false\n    },\n    \"meta.llama3-1-405b-instruct-v1:0\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000532,\n
        \       \"output_cost_per_token\": 0.000016,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true, \n        \"supports_tool_choice\": false\n    },\n    \"us.meta.llama3-1-405b-instruct-v1:0\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000532,\n
        \       \"output_cost_per_token\": 0.000016,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true, \n        \"supports_tool_choice\": false\n    },\n    \"meta.llama3-2-1b-instruct-v1:0\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.0000001,\n
        \       \"output_cost_per_token\": 0.0000001,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true, \n        \"supports_tool_choice\": false\n    },\n    \"us.meta.llama3-2-1b-instruct-v1:0\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.0000001,\n
        \       \"output_cost_per_token\": 0.0000001,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true, \n        \"supports_tool_choice\": false\n    },\n    \"eu.meta.llama3-2-1b-instruct-v1:0\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000013,\n
        \       \"output_cost_per_token\": 0.00000013,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true, \n        \"supports_tool_choice\": false\n    },\n    \"meta.llama3-2-3b-instruct-v1:0\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000015,\n
        \       \"output_cost_per_token\": 0.00000015,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true, \n        \"supports_tool_choice\": false\n    },\n    \"us.meta.llama3-2-3b-instruct-v1:0\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000015,\n
        \       \"output_cost_per_token\": 0.00000015,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true, \n        \"supports_tool_choice\": false\n    },\n    \"eu.meta.llama3-2-3b-instruct-v1:0\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000019,\n
        \       \"output_cost_per_token\": 0.00000019,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true, \n        \"supports_tool_choice\": false\n    },\n    \"meta.llama3-2-11b-instruct-v1:0\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000035,\n
        \       \"output_cost_per_token\": 0.00000035,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true, \n        \"supports_tool_choice\": false,\n        \"supports_vision\":
        true\n    },\n    \"us.meta.llama3-2-11b-instruct-v1:0\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000035,\n        \"output_cost_per_token\":
        0.00000035,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true, \n        \"supports_tool_choice\":
        false,\n        \"supports_vision\": true\n    },\n    \"meta.llama3-2-90b-instruct-v1:0\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.000002,\n
        \       \"output_cost_per_token\": 0.000002,\n        \"litellm_provider\":
        \"bedrock\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true, \n        \"supports_tool_choice\": false,\n        \"supports_vision\":
        true\n    },\n    \"us.meta.llama3-2-90b-instruct-v1:0\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000002,\n        \"output_cost_per_token\":
        0.000002,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true, \n        \"supports_tool_choice\":
        false,\n        \"supports_vision\": true\n    },\n    \"us.meta.llama3-3-70b-instruct-v1:0\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000072,\n
        \       \"output_cost_per_token\": 0.00000072,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true, \n        \"supports_tool_choice\": false\n    },\n    \"meta.llama4-maverick-17b-instruct-v1:0\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00024e-3,\n
        \       \"input_cost_per_token_batches\": 0.00012e-3,\n        \"output_cost_per_token\":
        0.00097e-3,\n        \"output_cost_per_token_batches\": 0.000485e-3,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true, \n        \"supports_tool_choice\": false,\n        \"supported_modalities\":
        [\"text\", \"image\"],\n        \"supported_output_modalities\": [\"text\",
        \"code\"]\n    },\n    \"us.meta.llama4-maverick-17b-instruct-v1:0\": {\n
        \       \"max_tokens\": 4096, \n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00024e-3,\n        \"input_cost_per_token_batches\":
        0.00012e-3,\n        \"output_cost_per_token\": 0.00097e-3,\n        \"output_cost_per_token_batches\":
        0.000485e-3,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true, \n        \"supports_tool_choice\":
        false,\n        \"supported_modalities\": [\"text\", \"image\"],\n        \"supported_output_modalities\":
        [\"text\", \"code\"]\n    },\n    \"meta.llama4-scout-17b-instruct-v1:0\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00017e-3,\n
        \       \"input_cost_per_token_batches\": 0.000085e-3,\n        \"output_cost_per_token\":
        0.00066e-3,\n        \"output_cost_per_token_batches\": 0.00033e-3,\n        \"litellm_provider\":
        \"bedrock_converse\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true, \n        \"supports_tool_choice\": false,\n        \"supported_modalities\":
        [\"text\", \"image\"],\n        \"supported_output_modalities\": [\"text\",
        \"code\"]\n    },\n    \"us.meta.llama4-scout-17b-instruct-v1:0\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00017e-3,\n        \"input_cost_per_token_batches\":
        0.000085e-3,\n        \"output_cost_per_token\": 0.00066e-3,\n        \"output_cost_per_token_batches\":
        0.00033e-3,\n        \"litellm_provider\": \"bedrock_converse\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true, \n        \"supports_tool_choice\":
        false,\n        \"supported_modalities\": [\"text\", \"image\"],\n        \"supported_output_modalities\":
        [\"text\", \"code\"]\n    },\n    \"512-x-512/50-steps/stability.stable-diffusion-xl-v0\":
        {\n        \"max_tokens\": 77, \n        \"max_input_tokens\": 77, \n        \"output_cost_per_image\":
        0.018,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"512-x-512/max-steps/stability.stable-diffusion-xl-v0\": {\n
        \       \"max_tokens\": 77, \n        \"max_input_tokens\": 77, \n        \"output_cost_per_image\":
        0.036,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"max-x-max/50-steps/stability.stable-diffusion-xl-v0\": {\n        \"max_tokens\":
        77, \n        \"max_input_tokens\": 77, \n        \"output_cost_per_image\":
        0.036,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"max-x-max/max-steps/stability.stable-diffusion-xl-v0\": {\n
        \       \"max_tokens\": 77, \n        \"max_input_tokens\": 77, \n        \"output_cost_per_image\":
        0.072,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"1024-x-1024/50-steps/stability.stable-diffusion-xl-v1\": {\n
        \       \"max_tokens\": 77, \n        \"max_input_tokens\": 77, \n        \"output_cost_per_image\":
        0.04,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"1024-x-1024/max-steps/stability.stable-diffusion-xl-v1\": {\n
        \       \"max_tokens\": 77, \n        \"max_input_tokens\": 77, \n        \"output_cost_per_image\":
        0.08,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"stability.sd3-large-v1:0\": {\n        \"max_tokens\": 77, \n
        \       \"max_input_tokens\": 77, \n        \"output_cost_per_image\": 0.08,\n
        \       \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"stability.sd3-5-large-v1:0\": {\n        \"max_tokens\": 77,\n
        \       \"max_input_tokens\": 77,\n        \"output_cost_per_image\": 0.08,\n
        \       \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"stability.stable-image-core-v1:0\": {\n        \"max_tokens\":
        77,\n        \"max_input_tokens\": 77,\n        \"output_cost_per_image\":
        0.04,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"stability.stable-image-core-v1:1\": {\n        \"max_tokens\":
        77,\n        \"max_input_tokens\": 77,\n        \"output_cost_per_image\":
        0.04,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"stability.stable-image-ultra-v1:0\": {\n        \"max_tokens\":
        77, \n        \"max_input_tokens\": 77, \n        \"output_cost_per_image\":
        0.14,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"stability.stable-image-ultra-v1:1\": {\n        \"max_tokens\":
        77,\n        \"max_input_tokens\": 77,\n        \"output_cost_per_image\":
        0.14,\n        \"litellm_provider\": \"bedrock\",\n        \"mode\": \"image_generation\"\n
        \   },\n    \"sagemaker/meta-textgeneration-llama-2-7b\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 4096, \n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.000,\n        \"output_cost_per_token\":
        0.000,\n        \"litellm_provider\": \"sagemaker\",\n        \"mode\": \"completion\"\n
        \   },\n    \"sagemaker/meta-textgeneration-llama-2-7b-f\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 4096, \n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.000,\n        \"output_cost_per_token\":
        0.000,\n        \"litellm_provider\": \"sagemaker\",\n        \"mode\": \"chat\"\n
        \   },\n    \"sagemaker/meta-textgeneration-llama-2-13b\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 4096, \n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.000,\n        \"output_cost_per_token\":
        0.000,\n        \"litellm_provider\": \"sagemaker\",\n        \"mode\": \"completion\"\n
        \   },\n    \"sagemaker/meta-textgeneration-llama-2-13b-f\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 4096, \n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.000,\n        \"output_cost_per_token\":
        0.000,\n        \"litellm_provider\": \"sagemaker\",\n        \"mode\": \"chat\"\n
        \   },\n    \"sagemaker/meta-textgeneration-llama-2-70b\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 4096, \n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.000,\n        \"output_cost_per_token\":
        0.000,\n        \"litellm_provider\": \"sagemaker\",\n        \"mode\": \"completion\"\n
        \   },\n    \"sagemaker/meta-textgeneration-llama-2-70b-b-f\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 4096, \n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.000,\n        \"output_cost_per_token\":
        0.000,\n        \"litellm_provider\": \"sagemaker\",\n        \"mode\": \"chat\"\n
        \   },\n    \"together-ai-up-to-4b\": {\n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0.0000001,\n        \"litellm_provider\":
        \"together_ai\",\n        \"mode\": \"chat\"\n    },\n    \"together-ai-4.1b-8b\":
        {\n        \"input_cost_per_token\": 0.0000002,\n        \"output_cost_per_token\":
        0.0000002,\n        \"litellm_provider\": \"together_ai\",\n        \"mode\":
        \"chat\"\n    },\n    \"together-ai-8.1b-21b\": {\n        \"max_tokens\":
        1000,\n        \"input_cost_per_token\": 0.0000003,\n        \"output_cost_per_token\":
        0.0000003,\n        \"litellm_provider\": \"together_ai\",\n        \"mode\":
        \"chat\"\n    },\n    \"together-ai-21.1b-41b\": {\n        \"input_cost_per_token\":
        0.0000008,\n        \"output_cost_per_token\": 0.0000008,\n        \"litellm_provider\":
        \"together_ai\",\n        \"mode\": \"chat\"\n    },\n    \"together-ai-41.1b-80b\":
        {\n        \"input_cost_per_token\": 0.0000009,\n        \"output_cost_per_token\":
        0.0000009,\n        \"litellm_provider\": \"together_ai\",\n        \"mode\":
        \"chat\"\n    },\n    \"together-ai-81.1b-110b\": {\n        \"input_cost_per_token\":
        0.0000018,\n        \"output_cost_per_token\": 0.0000018,\n        \"litellm_provider\":
        \"together_ai\",\n        \"mode\": \"chat\"\n    },\n    \"together-ai-embedding-up-to-150m\":
        {\n        \"input_cost_per_token\": 0.000000008,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"together_ai\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"together-ai-embedding-151m-to-350m\": {\n        \"input_cost_per_token\":
        0.000000016,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"together_ai\",\n        \"mode\": \"embedding\"\n    },\n    \"together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\":
        {\n        \"input_cost_per_token\": 0.00000018,\n        \"output_cost_per_token\":
        0.00000018,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\":
        {\n        \"input_cost_per_token\": 0.00000088,\n        \"output_cost_per_token\":
        0.00000088,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\":
        {\n        \"input_cost_per_token\": 0.0000035,\n        \"output_cost_per_token\":
        0.0000035,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo\":
        {\n        \"input_cost_per_token\": 0.00000088,\n        \"output_cost_per_token\":
        0.00000088,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\":
        {\n        \"input_cost_per_token\": 0,\n        \"output_cost_per_token\":
        0,\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"together_ai/mistralai/Mixtral-8x7B-Instruct-v0.1\": {\n        \"input_cost_per_token\":
        0.0000006,\n        \"output_cost_per_token\": 0.0000006,\n        \"litellm_provider\":
        \"together_ai\",\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"mode\": \"chat\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"together_ai/mistralai/Mistral-7B-Instruct-v0.1\":
        {\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"together_ai/togethercomputer/CodeLlama-34b-Instruct\": {\n        \"litellm_provider\":
        \"together_ai\",\n        \"supports_function_calling\": true,\n        \"supports_parallel_function_calling\":
        true,\n        \"mode\": \"chat\",\n        \"supports_tool_choice\": true\n
        \   },\n    \"together_ai/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\":
        {\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"together_ai/meta-llama/Llama-4-Scout-17B-16E-Instruct\":
        {\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"together_ai/meta-llama/Llama-3.2-3B-Instruct-Turbo\":
        {\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"together_ai/Qwen/Qwen2.5-7B-Instruct-Turbo\":
        {\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"together_ai/Qwen/Qwen2.5-72B-Instruct-Turbo\":
        {\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"together_ai/deepseek-ai/DeepSeek-V3\":
        {\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"together_ai/mistralai/Mistral-Small-24B-Instruct-2501\":
        {\n        \"litellm_provider\": \"together_ai\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"ollama/codegemma\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"ollama\",\n
        \       \"mode\": \"completion\"\n    },\n    \"ollama/codegeex4\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"chat\",
        \n        \"supports_function_calling\": false\n    },\n    \"ollama/deepseek-coder-v2-instruct\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"ollama\",\n
        \       \"mode\": \"chat\", \n        \"supports_function_calling\": true\n
        \   },\n    \"ollama/deepseek-coder-v2-base\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"completion\",
        \n        \"supports_function_calling\": true\n    },\n    \"ollama/deepseek-coder-v2-lite-instruct\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"ollama\",\n
        \       \"mode\": \"chat\", \n        \"supports_function_calling\": true\n
        \   },\n    \"ollama/deepseek-coder-v2-lite-base\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"completion\",
        \n        \"supports_function_calling\": true\n    },\n    \"ollama/internlm2_5-20b-chat\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"ollama\",\n
        \       \"mode\": \"chat\", \n        \"supports_function_calling\": true\n
        \   },\n    \"ollama/llama2\": {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\":
        4096, \n        \"max_output_tokens\": 4096, \n        \"input_cost_per_token\":
        0.0,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"ollama\",\n        \"mode\": \"chat\"\n    },\n    \"ollama/llama2:7b\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096, \n
        \       \"max_output_tokens\": 4096, \n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"ollama\",\n
        \       \"mode\": \"chat\"\n    },\n    \"ollama/llama2:13b\": {\n        \"max_tokens\":
        4096, \n        \"max_input_tokens\": 4096, \n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"chat\"\n
        \   },\n    \"ollama/llama2:70b\": {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\":
        4096, \n        \"max_output_tokens\": 4096, \n        \"input_cost_per_token\":
        0.0,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"ollama\",\n        \"mode\": \"chat\"\n    },\n    \"ollama/llama2-uncensored\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096, \n
        \       \"max_output_tokens\": 4096, \n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"ollama\",\n
        \       \"mode\": \"completion\"\n    },\n    \"ollama/llama3\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"chat\"\n
        \   },\n    \"ollama/llama3:8b\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        0.0,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"ollama\",\n        \"mode\": \"chat\"\n    },\n    \"ollama/llama3:70b\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"chat\"\n
        \   },\n    \"ollama/llama3.1\": {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 8192,\n        \"input_cost_per_token\":
        0.0,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"ollama\",\n        \"mode\": \"chat\", \n        \"supports_function_calling\":
        true\n    },\n    \"ollama/mistral-large-instruct-2407\": {\n        \"max_tokens\":
        65536,\n        \"max_input_tokens\": 65536,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"ollama/mistral\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"completion\",\n
        \       \"supports_function_calling\": true\n    },\n    \"ollama/mistral-7B-Instruct-v0.1\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"ollama/mistral-7B-Instruct-v0.2\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"ollama\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true\n
        \   },\n    \"ollama/mixtral-8x7B-Instruct-v0.1\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"chat\",\n
        \       \"supports_function_calling\": true\n    },\n    \"ollama/mixtral-8x22B-Instruct-v0.1\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 65536,\n
        \       \"max_output_tokens\": 65536,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"ollama\",\n
        \       \"mode\": \"chat\",\n        \"supports_function_calling\": true\n
        \   },\n    \"ollama/codellama\": {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\":
        4096, \n        \"max_output_tokens\": 4096,\n        \"input_cost_per_token\":
        0.0,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"ollama\",\n        \"mode\": \"completion\"\n    },\n    \"ollama/orca-mini\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096, \n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.0,\n
        \       \"output_cost_per_token\": 0.0,\n        \"litellm_provider\": \"ollama\",\n
        \       \"mode\": \"completion\"\n    },\n    \"ollama/vicuna\": {\n        \"max_tokens\":
        2048,\n        \"max_input_tokens\": 2048,\n        \"max_output_tokens\":
        2048,\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"ollama\",\n        \"mode\": \"completion\"\n
        \   },\n    \"deepinfra/lizpreciatior/lzlv_70b_fp16_hf\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000070,\n        \"output_cost_per_token\":
        0.00000090,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/Gryphe/MythoMax-L2-13b\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000022,\n        \"output_cost_per_token\":
        0.00000022,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/mistralai/Mistral-7B-Instruct-v0.1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000013,\n        \"output_cost_per_token\":
        0.00000013,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/meta-llama/Llama-2-70b-chat-hf\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000070,\n        \"output_cost_per_token\":
        0.00000090,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/cognitivecomputations/dolphin-2.6-mixtral-8x7b\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000027,\n        \"output_cost_per_token\":
        0.00000027,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/codellama/CodeLlama-34b-Instruct-hf\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000060,\n        \"output_cost_per_token\":
        0.00000060,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/deepinfra/mixtral\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 32000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000027,\n        \"output_cost_per_token\":
        0.00000027,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"completion\"\n    },\n    \"deepinfra/Phind/Phind-CodeLlama-34B-v2\": {\n
        \       \"max_tokens\": 4096,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000060,\n        \"output_cost_per_token\":
        0.00000060,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/mistralai/Mixtral-8x7B-Instruct-v0.1\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000027,\n        \"output_cost_per_token\":
        0.00000027,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/deepinfra/airoboros-70b\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000070,\n        \"output_cost_per_token\":
        0.00000090,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/01-ai/Yi-34B-Chat\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000060,\n        \"output_cost_per_token\":
        0.00000060,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/01-ai/Yi-6B-200K\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 4096,\n        \"input_cost_per_token\": 0.00000013,\n
        \       \"output_cost_per_token\": 0.00000013,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"completion\"\n    },\n    \"deepinfra/jondurbin/airoboros-l2-70b-gpt4-1.4.1\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000070,\n        \"output_cost_per_token\":
        0.00000090,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/meta-llama/Llama-2-13b-chat-hf\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000022,\n        \"output_cost_per_token\":
        0.00000022,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/amazon/MistralLite\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        8191,\n        \"input_cost_per_token\": 0.00000020,\n        \"output_cost_per_token\":
        0.00000020,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/meta-llama/Llama-2-7b-chat-hf\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000013,\n        \"output_cost_per_token\":
        0.00000013,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/meta-llama/Meta-Llama-3-8B-Instruct\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 8191,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000008,\n        \"output_cost_per_token\":
        0.00000008,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/meta-llama/Meta-Llama-3-70B-Instruct\":
        {\n        \"max_tokens\": 8191,\n        \"max_input_tokens\": 8191,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000059,\n        \"output_cost_per_token\":
        0.00000079,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"deepinfra/meta-llama/Meta-Llama-3.1-405B-Instruct\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 0.0000009,\n
        \       \"output_cost_per_token\": 0.0000009,\n        \"litellm_provider\":
        \"deepinfra\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_parallel_function_calling\": true,\n        \"supports_tool_choice\":
        true\n    },\n    \"deepinfra/01-ai/Yi-34B-200K\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000060,\n        \"output_cost_per_token\":
        0.00000060,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"completion\"\n    },\n    \"deepinfra/openchat/openchat_3.5\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000013,\n        \"output_cost_per_token\":
        0.00000013,\n        \"litellm_provider\": \"deepinfra\",\n        \"mode\":
        \"chat\",\n        \"supports_tool_choice\": true\n    },\n    \"perplexity/codellama-34b-instruct\":
        { \n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.00000035,
        \n        \"output_cost_per_token\": 0.00000140,  \n        \"litellm_provider\":
        \"perplexity\", \n        \"mode\": \"chat\" \n    },\n    \"perplexity/codellama-70b-instruct\":
        { \n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.00000070,
        \n        \"output_cost_per_token\": 0.00000280,  \n        \"litellm_provider\":
        \"perplexity\", \n        \"mode\": \"chat\" \n    },\n    \"perplexity/llama-3.1-70b-instruct\":
        { \n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        0.000001, \n        \"output_cost_per_token\": 0.000001,\n        \"litellm_provider\":
        \"perplexity\", \n        \"mode\": \"chat\" \n    },\n    \"perplexity/llama-3.1-8b-instruct\":
        { \n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        0.0000002, \n        \"output_cost_per_token\": 0.0000002,  \n        \"litellm_provider\":
        \"perplexity\", \n        \"mode\": \"chat\" \n    },\n    \"perplexity/llama-3.1-sonar-huge-128k-online\":
        { \n        \"max_tokens\": 127072,\n        \"max_input_tokens\": 127072,\n
        \       \"max_output_tokens\": 127072,\n        \"input_cost_per_token\":
        0.000005, \n        \"output_cost_per_token\": 0.000005,\n        \"litellm_provider\":
        \"perplexity\", \n        \"mode\": \"chat\",\n        \"deprecation_date\":
        \"2025-02-22\"\n    },\n    \"perplexity/llama-3.1-sonar-large-128k-online\":
        { \n        \"max_tokens\": 127072,\n        \"max_input_tokens\": 127072,\n
        \       \"max_output_tokens\": 127072,\n        \"input_cost_per_token\":
        0.000001, \n        \"output_cost_per_token\": 0.000001,\n        \"litellm_provider\":
        \"perplexity\", \n        \"mode\": \"chat\",\n        \"deprecation_date\":
        \"2025-02-22\"\n    },\n    \"perplexity/llama-3.1-sonar-large-128k-chat\":
        { \n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        0.000001, \n        \"output_cost_per_token\": 0.000001,\n        \"litellm_provider\":
        \"perplexity\", \n        \"mode\": \"chat\",\n        \"deprecation_date\":
        \"2025-02-22\"\n    },\n    \"perplexity/llama-3.1-sonar-small-128k-chat\":
        { \n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        0.0000002, \n        \"output_cost_per_token\": 0.0000002,  \n        \"litellm_provider\":
        \"perplexity\", \n        \"mode\": \"chat\",\n        \"deprecation_date\":
        \"2025-02-22\"\n    },\n    \"perplexity/llama-3.1-sonar-small-128k-online\":
        { \n        \"max_tokens\": 127072,\n        \"max_input_tokens\": 127072,\n
        \       \"max_output_tokens\": 127072,\n        \"input_cost_per_token\":
        0.0000002, \n        \"output_cost_per_token\": 0.0000002,  \n        \"litellm_provider\":
        \"perplexity\", \n        \"mode\": \"chat\" ,\n        \"deprecation_date\":
        \"2025-02-22\"\n    },\n    \"perplexity/pplx-7b-chat\": { \n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.00000007, \n        \"output_cost_per_token\":
        0.00000028, \n        \"litellm_provider\": \"perplexity\", \n        \"mode\":
        \"chat\" \n    },\n    \"perplexity/pplx-70b-chat\": {  \n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000070, \n        \"output_cost_per_token\":
        0.00000280, \n        \"litellm_provider\": \"perplexity\", \n        \"mode\":
        \"chat\" \n    },\n    \"perplexity/pplx-7b-online\": { \n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000000, \n        \"output_cost_per_token\":
        0.00000028, \n        \"input_cost_per_request\": 0.005,\n        \"litellm_provider\":
        \"perplexity\", \n        \"mode\": \"chat\" \n    },\n    \"perplexity/pplx-70b-online\":
        { \n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.0000000, \n        \"output_cost_per_token\":
        0.00000280, \n        \"input_cost_per_request\": 0.005,\n        \"litellm_provider\":
        \"perplexity\", \n        \"mode\": \"chat\" \n    },\n    \"perplexity/llama-2-70b-chat\":
        { \n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.00000070, \n        \"output_cost_per_token\":
        0.00000280,\n        \"litellm_provider\": \"perplexity\", \n        \"mode\":
        \"chat\" \n    },\n    \"perplexity/mistral-7b-instruct\": { \n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.00000007,\n        \"output_cost_per_token\":
        0.00000028,\n        \"litellm_provider\": \"perplexity\", \n        \"mode\":
        \"chat\" \n    },\n    \"perplexity/mixtral-8x7b-instruct\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000007,\n        \"output_cost_per_token\":
        0.00000028,\n        \"litellm_provider\": \"perplexity\",\n        \"mode\":
        \"chat\"\n    },\n    \"perplexity/sonar-small-chat\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.00000007,\n        \"output_cost_per_token\":
        0.00000028,\n        \"litellm_provider\": \"perplexity\",\n        \"mode\":
        \"chat\"\n    },\n    \"perplexity/sonar-small-online\": {\n        \"max_tokens\":
        12000,\n        \"max_input_tokens\": 12000,\n        \"max_output_tokens\":
        12000,\n        \"input_cost_per_token\": 0,\n        \"output_cost_per_token\":
        0.00000028,\n        \"input_cost_per_request\": 0.005,\n        \"litellm_provider\":
        \"perplexity\",\n        \"mode\": \"chat\"\n    },\n    \"perplexity/sonar-medium-chat\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.0000006,\n
        \       \"output_cost_per_token\": 0.0000018,\n        \"litellm_provider\":
        \"perplexity\",\n        \"mode\": \"chat\"\n    },\n    \"perplexity/sonar-medium-online\":
        {\n        \"max_tokens\": 12000,\n        \"max_input_tokens\": 12000,\n
        \       \"max_output_tokens\": 12000,\n        \"input_cost_per_token\": 0,\n
        \       \"output_cost_per_token\": 0.0000018,\n        \"input_cost_per_request\":
        0.005,\n        \"litellm_provider\": \"perplexity\",\n        \"mode\": \"chat\"\n
        \   },\n    \"perplexity/sonar\": {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\":
        128000,\n        \"input_cost_per_token\": 1e-6,\n        \"output_cost_per_token\":
        1e-6,\n        \"litellm_provider\": \"perplexity\",\n        \"mode\": \"chat\",\n
        \       \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        5e-3,\n            \"search_context_size_medium\": 8e-3,\n            \"search_context_size_high\":
        12e-3\n        },\n        \"supports_web_search\": true\n    },\n    \"perplexity/sonar-pro\":
        {\n        \"max_tokens\": 8000,\n        \"max_input_tokens\": 200000,\n
        \       \"max_output_tokens\": 8000,\n        \"input_cost_per_token\": 3e-6,\n
        \       \"output_cost_per_token\": 15e-6,\n        \"litellm_provider\": \"perplexity\",\n
        \       \"mode\": \"chat\",\n        \"search_context_cost_per_query\": {\n
        \           \"search_context_size_low\": 6e-3,\n            \"search_context_size_medium\":
        10e-3,\n            \"search_context_size_high\": 14e-3\n        },\n        \"supports_web_search\":
        true\n    },\n    \"perplexity/sonar-reasoning\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"input_cost_per_token\":
        1e-6,\n        \"output_cost_per_token\": 5e-6,\n        \"litellm_provider\":
        \"perplexity\",\n        \"mode\": \"chat\",\n        \"search_context_cost_per_query\":
        {\n            \"search_context_size_low\": 5e-3,\n            \"search_context_size_medium\":
        8e-3,\n            \"search_context_size_high\": 14e-3\n        },\n        \"supports_web_search\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"perplexity/sonar-reasoning-pro\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"input_cost_per_token\": 2e-6,\n        \"output_cost_per_token\":
        8e-6,\n        \"litellm_provider\": \"perplexity\",\n        \"mode\": \"chat\",\n
        \       \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        6e-3,\n            \"search_context_size_medium\": 10e-3,\n            \"search_context_size_high\":
        14e-3\n        },\n        \"supports_web_search\": true,\n        \"supports_reasoning\":
        true\n    },\n    \"perplexity/sonar-deep-research\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"input_cost_per_token\":
        2e-6,\n        \"output_cost_per_token\": 8e-6,\n        \"output_cost_per_reasoning_token\":
        3e-6,\n        \"litellm_provider\": \"perplexity\",\n        \"mode\": \"chat\",\n
        \       \"search_context_cost_per_query\": {\n            \"search_context_size_low\":
        5e-3,\n            \"search_context_size_medium\": 5e-3,\n            \"search_context_size_high\":
        5e-3\n        },\n        \"supports_reasoning\": true,\n        \"supports_web_search\":
        true\n    },\n    \"fireworks_ai/accounts/fireworks/models/llama-v3p2-1b-instruct\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.0000001,
        \n        \"output_cost_per_token\": 0.0000001,\n        \"litellm_provider\":
        \"fireworks_ai\", \n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://fireworks.ai/pricing\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"fireworks_ai/accounts/fireworks/models/llama-v3p2-3b-instruct\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.0000001,
        \n        \"output_cost_per_token\": 0.0000001,\n        \"litellm_provider\":
        \"fireworks_ai\", \n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://fireworks.ai/pricing\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"fireworks_ai/accounts/fireworks/models/llama-v3p1-8b-instruct\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.0000001,
        \n        \"output_cost_per_token\": 0.0000001,\n        \"litellm_provider\":
        \"fireworks_ai\", \n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://fireworks.ai/pricing\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"fireworks_ai/accounts/fireworks/models/llama-v3p2-11b-vision-instruct\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.0000002,
        \n        \"output_cost_per_token\": 0.0000002,\n        \"litellm_provider\":
        \"fireworks_ai\", \n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://fireworks.ai/pricing\",\n        \"supports_tool_choice\":
        true\n    },\n    \"accounts/fireworks/models/llama-v3p2-90b-vision-instruct\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.0000009,
        \n        \"output_cost_per_token\": 0.0000009,\n        \"litellm_provider\":
        \"fireworks_ai\", \n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_vision\": true,\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://fireworks.ai/pricing\"\n    },\n    \"fireworks_ai/accounts/fireworks/models/firefunction-v2\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.0000009, \n        \"output_cost_per_token\":
        0.0000009,\n        \"litellm_provider\": \"fireworks_ai\", \n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://fireworks.ai/pricing\",\n        \"supports_tool_choice\":
        true\n    },\n    \"fireworks_ai/accounts/fireworks/models/mixtral-8x22b-instruct-hf\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 65536,\n
        \       \"max_output_tokens\": 65536,\n        \"input_cost_per_token\": 0.0000012,
        \n        \"output_cost_per_token\": 0.0000012,\n        \"litellm_provider\":
        \"fireworks_ai\", \n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://fireworks.ai/pricing\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"fireworks_ai/accounts/fireworks/models/qwen2-72b-instruct\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768,\n        \"input_cost_per_token\": 0.0000009,
        \n        \"output_cost_per_token\": 0.0000009,\n        \"litellm_provider\":
        \"fireworks_ai\", \n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://fireworks.ai/pricing\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"fireworks_ai/accounts/fireworks/models/qwen2p5-coder-32b-instruct\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.0000009, \n        \"output_cost_per_token\":
        0.0000009,\n        \"litellm_provider\": \"fireworks_ai\", \n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://fireworks.ai/pricing\",\n        \"supports_tool_choice\":
        true\n    },\n    \"fireworks_ai/accounts/fireworks/models/yi-large\": {\n
        \       \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        32768,\n        \"input_cost_per_token\": 0.000003, \n        \"output_cost_per_token\":
        0.000003,\n        \"litellm_provider\": \"fireworks_ai\", \n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://fireworks.ai/pricing\",\n        \"supports_tool_choice\":
        true\n    },\n    \"fireworks_ai/accounts/fireworks/models/deepseek-coder-v2-instruct\":
        {\n        \"max_tokens\": 65536,\n        \"max_input_tokens\": 65536,\n
        \       \"max_output_tokens\": 65536,\n        \"input_cost_per_token\": 0.0000012,
        \n        \"output_cost_per_token\": 0.0000012,\n        \"litellm_provider\":
        \"fireworks_ai\", \n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://fireworks.ai/pricing\",\n
        \       \"supports_tool_choice\": true\n    },\n    \"fireworks_ai/accounts/fireworks/models/deepseek-v3\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 8192,\n        \"input_cost_per_token\": 0.0000009,\n
        \       \"output_cost_per_token\": 0.0000009,\n        \"litellm_provider\":
        \"fireworks_ai\",\n        \"mode\": \"chat\",\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://fireworks.ai/pricing\",\n        \"supports_tool_choice\":
        true\n    },\n    \"fireworks_ai/accounts/fireworks/models/deepseek-r1\":
        {\n        \"max_tokens\": 20480,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 20480,\n        \"input_cost_per_token\": 3e-6,\n
        \       \"output_cost_per_token\": 8e-6,\n        \"litellm_provider\": \"fireworks_ai\",\n
        \       \"mode\": \"chat\",\n        \"supports_response_schema\": true,\n
        \       \"source\": \"https://fireworks.ai/pricing\",\n        \"supports_tool_choice\":
        true\n    },\n    \"fireworks_ai/accounts/fireworks/models/deepseek-r1-basic\":
        {\n        \"max_tokens\": 20480,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 20480,\n        \"input_cost_per_token\": 0.55e-6,\n
        \       \"output_cost_per_token\": 2.19e-6,\n        \"litellm_provider\":
        \"fireworks_ai\",\n        \"mode\": \"chat\",\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://fireworks.ai/pricing\",\n        \"supports_tool_choice\":
        true\n    },\n    \"fireworks_ai/accounts/fireworks/models/llama-v3p1-405b-instruct\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 3e-6,\n
        \       \"output_cost_per_token\": 3e-6,\n        \"litellm_provider\": \"fireworks_ai\",\n
        \       \"mode\": \"chat\",\n        \"supports_response_schema\": true,\n
        \       \"source\": \"https://fireworks.ai/pricing\",\n        \"supports_tool_choice\":
        true\n    },\n    \"fireworks_ai/accounts/fireworks/models/llama4-maverick-instruct-basic\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        0.22e-6,\n        \"output_cost_per_token\": 0.88e-6,\n        \"litellm_provider\":
        \"fireworks_ai\",\n        \"mode\": \"chat\",\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://fireworks.ai/pricing\",\n        \"supports_tool_choice\":
        true\n    },\n    \"fireworks_ai/accounts/fireworks/models/llama4-scout-instruct-basic\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072,\n        \"input_cost_per_token\":
        0.15e-6,\n        \"output_cost_per_token\": 0.60e-6,\n        \"litellm_provider\":
        \"fireworks_ai\",\n        \"mode\": \"chat\",\n        \"supports_response_schema\":
        true,\n        \"source\": \"https://fireworks.ai/pricing\",\n        \"supports_tool_choice\":
        true\n    },\n    \"fireworks_ai/nomic-ai/nomic-embed-text-v1.5\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"input_cost_per_token\":
        0.000000008,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"fireworks_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://fireworks.ai/pricing\"\n    },\n    \"fireworks_ai/nomic-ai/nomic-embed-text-v1\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"input_cost_per_token\":
        0.000000008,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"fireworks_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://fireworks.ai/pricing\"\n    },\n    \"fireworks_ai/WhereIsAI/UAE-Large-V1\":
        {\n        \"max_tokens\": 512,\n        \"max_input_tokens\": 512,\n        \"input_cost_per_token\":
        0.000000016,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"fireworks_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://fireworks.ai/pricing\"\n    },\n    \"fireworks_ai/thenlper/gte-large\":
        {\n        \"max_tokens\": 512,\n        \"max_input_tokens\": 512,\n        \"input_cost_per_token\":
        0.000000016,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"fireworks_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://fireworks.ai/pricing\"\n    },\n    \"fireworks_ai/thenlper/gte-base\":
        {\n        \"max_tokens\": 512,\n        \"max_input_tokens\": 512,\n        \"input_cost_per_token\":
        0.000000008,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"fireworks_ai-embedding-models\",\n        \"mode\": \"embedding\",\n        \"source\":
        \"https://fireworks.ai/pricing\"\n    },\n    \"fireworks-ai-up-to-4b\": {\n
        \       \"input_cost_per_token\": 0.0000002,\n        \"output_cost_per_token\":
        0.0000002,\n        \"litellm_provider\": \"fireworks_ai\"\n    },\n    \"fireworks-ai-4.1b-to-16b\":
        {\n        \"input_cost_per_token\": 0.0000002,\n        \"output_cost_per_token\":
        0.0000002,\n        \"litellm_provider\": \"fireworks_ai\"\n    },\n    \"fireworks-ai-above-16b\":
        {\n        \"input_cost_per_token\": 0.0000009,\n        \"output_cost_per_token\":
        0.0000009,\n        \"litellm_provider\": \"fireworks_ai\"\n    },\n    \"fireworks-ai-moe-up-to-56b\":
        {\n        \"input_cost_per_token\": 0.0000005,\n        \"output_cost_per_token\":
        0.0000005,\n        \"litellm_provider\": \"fireworks_ai\"\n    },\n    \"fireworks-ai-56b-to-176b\":
        {\n        \"input_cost_per_token\": 0.0000012,\n        \"output_cost_per_token\":
        0.0000012,\n        \"litellm_provider\": \"fireworks_ai\"\n    },\n    \"fireworks-ai-default\":
        {\n        \"input_cost_per_token\": 0.0,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"fireworks_ai\"\n    },\n    \"fireworks-ai-embedding-up-to-150m\":
        {\n        \"input_cost_per_token\": 0.000000008,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"fireworks_ai-embedding-models\"\n
        \   },\n    \"fireworks-ai-embedding-150m-to-350m\": {\n        \"input_cost_per_token\":
        0.000000016,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"fireworks_ai-embedding-models\"\n    },\n      \"anyscale/mistralai/Mistral-7B-Instruct-v0.1\":
        {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\": 16384,\n
        \       \"max_output_tokens\": 16384,\n        \"input_cost_per_token\": 0.00000015,
        \n        \"output_cost_per_token\": 0.00000015,\n        \"litellm_provider\":
        \"anyscale\", \n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"source\": \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mistral-7B-Instruct-v0.1\"\n
        \     },\n      \"anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.00000015, \n        \"output_cost_per_token\":
        0.00000015,\n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"source\":
        \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x7B-Instruct-v0.1\"\n
        \     },\n      \"anyscale/mistralai/Mixtral-8x22B-Instruct-v0.1\": {\n        \"max_tokens\":
        65536,\n        \"max_input_tokens\": 65536,\n        \"max_output_tokens\":
        65536,\n        \"input_cost_per_token\": 0.00000090, \n        \"output_cost_per_token\":
        0.00000090,\n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"source\":
        \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/mistralai-Mixtral-8x22B-Instruct-v0.1\"\n
        \     },\n      \"anyscale/HuggingFaceH4/zephyr-7b-beta\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384,\n        \"input_cost_per_token\": 0.00000015, \n        \"output_cost_per_token\":
        0.00000015,\n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\"\n      },\n      \"anyscale/google/gemma-7b-it\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.00000015, \n        \"output_cost_per_token\":
        0.00000015,\n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\",\n        \"source\": \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/google-gemma-7b-it\"\n
        \     },\n      \"anyscale/meta-llama/Llama-2-7b-chat-hf\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000015, \n        \"output_cost_per_token\":
        0.00000015, \n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\"\n      },\n      \"anyscale/meta-llama/Llama-2-13b-chat-hf\": {\n
        \       \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.00000025, \n        \"output_cost_per_token\":
        0.00000025, \n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\"\n      },\n      \"anyscale/meta-llama/Llama-2-70b-chat-hf\": {\n
        \       \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000001, \n        \"output_cost_per_token\":
        0.000001, \n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\"\n      },\n      \"anyscale/codellama/CodeLlama-34b-Instruct-hf\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000001, \n        \"output_cost_per_token\":
        0.000001, \n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\"\n      },\n      \"anyscale/codellama/CodeLlama-70b-Instruct-hf\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096,\n        \"input_cost_per_token\": 0.000001, \n        \"output_cost_per_token\":
        0.000001, \n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\",\n        \"source\" : \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/codellama-CodeLlama-70b-Instruct-hf\"\n
        \     },\n      \"anyscale/meta-llama/Meta-Llama-3-8B-Instruct\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.00000015, \n        \"output_cost_per_token\":
        0.00000015, \n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\",\n        \"source\": \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-8B-Instruct\"\n
        \     },\n      \"anyscale/meta-llama/Meta-Llama-3-70B-Instruct\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192,\n        \"input_cost_per_token\": 0.00000100, \n        \"output_cost_per_token\":
        0.00000100, \n        \"litellm_provider\": \"anyscale\", \n        \"mode\":
        \"chat\",\n        \"source\" : \"https://docs.anyscale.com/preview/endpoints/text-generation/supported-models/meta-llama-Meta-Llama-3-70B-Instruct\"\n
        \     },\n      \"cloudflare/@cf/meta/llama-2-7b-chat-fp16\": {\n        \"max_tokens\":
        3072, \n        \"max_input_tokens\": 3072, \n        \"max_output_tokens\":
        3072, \n        \"input_cost_per_token\": 0.000001923, \n        \"output_cost_per_token\":
        0.000001923, \n        \"litellm_provider\": \"cloudflare\", \n        \"mode\":
        \"chat\"\n      },\n      \"cloudflare/@cf/meta/llama-2-7b-chat-int8\": {\n
        \       \"max_tokens\": 2048, \n        \"max_input_tokens\": 2048, \n        \"max_output_tokens\":
        2048, \n        \"input_cost_per_token\": 0.000001923, \n        \"output_cost_per_token\":
        0.000001923, \n        \"litellm_provider\": \"cloudflare\", \n        \"mode\":
        \"chat\"\n      },\n      \"cloudflare/@cf/mistral/mistral-7b-instruct-v0.1\":
        {\n        \"max_tokens\": 8192, \n        \"max_input_tokens\": 8192, \n
        \       \"max_output_tokens\": 8192, \n        \"input_cost_per_token\": 0.000001923,
        \n        \"output_cost_per_token\": 0.000001923, \n        \"litellm_provider\":
        \"cloudflare\", \n        \"mode\": \"chat\"\n      },\n      \"cloudflare/@hf/thebloke/codellama-7b-instruct-awq\":
        {\n        \"max_tokens\": 4096, \n        \"max_input_tokens\": 4096, \n
        \       \"max_output_tokens\": 4096, \n        \"input_cost_per_token\": 0.000001923,
        \n        \"output_cost_per_token\": 0.000001923, \n        \"litellm_provider\":
        \"cloudflare\", \n        \"mode\": \"chat\"\n      },\n      \"voyage/voyage-01\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"voyage\",\n        \"mode\": \"embedding\"\n    },\n    \"voyage/voyage-lite-01\":
        {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\": 4096,\n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"voyage\",\n        \"mode\": \"embedding\"\n    },\n    \"voyage/voyage-large-2\":
        {\n        \"max_tokens\": 16000,\n        \"max_input_tokens\": 16000,\n
        \       \"input_cost_per_token\": 0.00000012,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"voyage\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"voyage/voyage-finance-2\": {\n        \"max_tokens\": 32000,\n
        \       \"max_input_tokens\": 32000,\n        \"input_cost_per_token\": 0.00000012,\n
        \       \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"voyage\",\n        \"mode\": \"embedding\"\n    },\n    \"voyage/voyage-lite-02-instruct\":
        {\n        \"max_tokens\": 4000,\n        \"max_input_tokens\": 4000,\n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"voyage\",\n        \"mode\": \"embedding\"\n    },\n    \"voyage/voyage-law-2\":
        {\n        \"max_tokens\": 16000,\n        \"max_input_tokens\": 16000,\n
        \       \"input_cost_per_token\": 0.00000012,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"voyage\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"voyage/voyage-code-2\": {\n        \"max_tokens\": 16000,\n
        \       \"max_input_tokens\": 16000,\n        \"input_cost_per_token\": 0.00000012,\n
        \       \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"voyage\",\n        \"mode\": \"embedding\"\n    },\n    \"voyage/voyage-2\":
        {\n        \"max_tokens\": 4000,\n        \"max_input_tokens\": 4000,\n        \"input_cost_per_token\":
        0.0000001,\n        \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"voyage\",\n        \"mode\": \"embedding\"\n    },\n    \"voyage/voyage-3-large\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 32000,\n
        \       \"input_cost_per_token\": 0.00000018,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"voyage\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"voyage/voyage-3\": {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\":
        32000,\n        \"input_cost_per_token\": 0.00000006,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"voyage\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"voyage/voyage-3-lite\": {\n        \"max_tokens\": 32000,\n
        \       \"max_input_tokens\": 32000,\n        \"input_cost_per_token\": 0.00000002,\n
        \       \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"voyage\",\n        \"mode\": \"embedding\"\n    },\n    \"voyage/voyage-code-3\":
        {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\": 32000,\n
        \       \"input_cost_per_token\": 0.00000018,\n        \"output_cost_per_token\":
        0.000000,\n        \"litellm_provider\": \"voyage\",\n        \"mode\": \"embedding\"\n
        \   },\n    \"voyage/voyage-multimodal-3\": {\n        \"max_tokens\": 32000,\n
        \       \"max_input_tokens\": 32000,\n        \"input_cost_per_token\": 0.00000012,\n
        \       \"output_cost_per_token\": 0.000000,\n        \"litellm_provider\":
        \"voyage\",\n        \"mode\": \"embedding\"\n    },\n    \"voyage/rerank-2\":
        {\n        \"max_tokens\": 16000,\n        \"max_input_tokens\": 16000,\n
        \       \"max_output_tokens\": 16000,\n        \"max_query_tokens\": 16000,\n
        \       \"input_cost_per_token\": 0.00000005,\n        \"input_cost_per_query\":
        0.00000005,\n        \"output_cost_per_token\": 0.0,\n        \"litellm_provider\":
        \"voyage\",\n        \"mode\": \"rerank\"\n    },\n    \"voyage/rerank-2-lite\":
        {\n        \"max_tokens\": 8000,\n        \"max_input_tokens\": 8000,\n        \"max_output_tokens\":
        8000,\n        \"max_query_tokens\": 8000,\n        \"input_cost_per_token\":
        0.00000002,\n        \"input_cost_per_query\": 0.00000002,\n        \"output_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"voyage\",\n        \"mode\": \"rerank\"\n
        \   },\n    \"databricks/databricks-claude-3-7-sonnet\": {\n        \"max_tokens\":
        200000,\n        \"max_input_tokens\": 200000,\n        \"max_output_tokens\":
        128000, \n        \"input_cost_per_token\": 0.0000025,\n        \"input_dbu_cost_per_token\":
        0.00003571,\n        \"output_cost_per_token\": 0.000017857,\n        \"output_db_cost_per_token\":
        0.000214286,\n        \"litellm_provider\": \"databricks\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\"notes\": \"Input/output cost per token is dbu cost
        * $0.070, based on databricks Claude 3.7 conversion. Number provided for reference,
        '*_dbu_cost_per_token' used in actual calculation.\"},\n        \"supports_assistant_prefill\":
        true,\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true\n    },\n    \"databricks/databricks-meta-llama-3-1-405b-instruct\":
        {\n        \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n
        \       \"max_output_tokens\": 128000, \n        \"input_cost_per_token\":
        0.000005,\n        \"input_dbu_cost_per_token\": 0.000071429,\n        \"output_cost_per_token\":
        0.00001500002,\n        \"output_db_cost_per_token\": 0.000214286,\n        \"litellm_provider\":
        \"databricks\",\n        \"mode\": \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\"notes\": \"Input/output cost per token is dbu cost
        * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for
        reference, '*_dbu_cost_per_token' used in actual calculation.\"},\n        \"supports_tool_choice\":
        true\n    },\n    \"databricks/databricks-meta-llama-3-1-70b-instruct\": {\n
        \       \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000, \n        \"input_cost_per_token\": 0.00000100002,\n        \"input_dbu_cost_per_token\":
        0.000014286,\n        \"output_cost_per_token\": 0.00000299999,\n        \"output_dbu_cost_per_token\":
        0.000042857,\n        \"litellm_provider\": \"databricks\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\"notes\": \"Input/output cost per token is dbu cost
        * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for
        reference, '*_dbu_cost_per_token' used in actual calculation.\"},\n        \"supports_tool_choice\":
        true\n    },\n    \"databricks/databricks-meta-llama-3-3-70b-instruct\": {\n
        \       \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000, \n        \"input_cost_per_token\": 0.00000100002,\n        \"input_dbu_cost_per_token\":
        0.000014286,\n        \"output_cost_per_token\": 0.00000299999,\n        \"output_dbu_cost_per_token\":
        0.000042857,\n        \"litellm_provider\": \"databricks\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\"notes\": \"Input/output cost per token is dbu cost
        * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for
        reference, '*_dbu_cost_per_token' used in actual calculation.\"},\n        \"supports_tool_choice\":
        true\n    },\n    \"databricks/databricks-llama-4-maverick\": {\n        \"max_tokens\":
        128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000, \n        \"input_cost_per_token\": 0.000005,\n        \"input_dbu_cost_per_token\":
        0.00007143,\n        \"output_cost_per_token\": 0.000015,\n        \"output_dbu_cost_per_token\":
        0.00021429,\n        \"litellm_provider\": \"databricks\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\"notes\": \"Databricks documentation now provides
        both DBU costs (_dbu_cost_per_token) and dollar costs(_cost_per_token).\"},\n
        \       \"supports_tool_choice\": true\n    },\n    \"databricks/databricks-dbrx-instruct\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 32768, \n        \"input_cost_per_token\":
        0.00000074998,\n        \"input_dbu_cost_per_token\": 0.000010714,\n        \"output_cost_per_token\":
        0.00000224901,\n        \"output_dbu_cost_per_token\": 0.000032143,\n        \"litellm_provider\":
        \"databricks\",\n        \"mode\": \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\"notes\": \"Input/output cost per token is dbu cost
        * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for
        reference, '*_dbu_cost_per_token' used in actual calculation.\"},\n        \"supports_tool_choice\":
        true\n    },\n    \"databricks/databricks-meta-llama-3-70b-instruct\": {\n
        \       \"max_tokens\": 128000,\n        \"max_input_tokens\": 128000,\n        \"max_output_tokens\":
        128000, \n        \"input_cost_per_token\": 0.00000100002,\n        \"input_dbu_cost_per_token\":
        0.000014286,\n        \"output_cost_per_token\": 0.00000299999,\n        \"output_dbu_cost_per_token\":
        0.000042857,\n        \"litellm_provider\": \"databricks\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\"notes\": \"Input/output cost per token is dbu cost
        * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for
        reference, '*_dbu_cost_per_token' used in actual calculation.\"},\n        \"supports_tool_choice\":
        true\n    },\n    \"databricks/databricks-llama-2-70b-chat\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.00000050001,\n        \"input_dbu_cost_per_token\":
        0.000007143,\n        \"output_cost_per_token\": 0.0000015,\n        \"output_dbu_cost_per_token\":
        0.000021429,\n        \"litellm_provider\": \"databricks\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\"notes\": \"Input/output cost per token is dbu cost
        * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for
        reference, '*_dbu_cost_per_token' used in actual calculation.\"},\n        \"supports_tool_choice\":
        true\n    },\n    \"databricks/databricks-mixtral-8x7b-instruct\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.00000050001,\n        \"input_dbu_cost_per_token\":
        0.000007143,\n        \"output_cost_per_token\": 0.00000099902,\n        \"output_dbu_cost_per_token\":
        0.000014286,\n        \"litellm_provider\": \"databricks\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\"notes\": \"Input/output cost per token is dbu cost
        * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for
        reference, '*_dbu_cost_per_token' used in actual calculation.\"},\n        \"supports_tool_choice\":
        true\n    },\n    \"databricks/databricks-mpt-30b-instruct\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192, \n        \"input_cost_per_token\": 0.00000099902,\n        \"input_dbu_cost_per_token\":
        0.000014286,\n        \"output_cost_per_token\": 0.00000099902,\n        \"output_dbu_cost_per_token\":
        0.000014286,\n        \"litellm_provider\": \"databricks\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\"notes\": \"Input/output cost per token is dbu cost
        * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for
        reference, '*_dbu_cost_per_token' used in actual calculation.\"},\n        \"supports_tool_choice\":
        true\n    },\n    \"databricks/databricks-mpt-7b-instruct\": {\n        \"max_tokens\":
        8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192, \n        \"input_cost_per_token\": 0.00000050001,\n        \"input_dbu_cost_per_token\":
        0.000007143,\n        \"output_cost_per_token\": 0.0,\n        \"output_dbu_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"databricks\",\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\"notes\": \"Input/output cost per token is dbu cost
        * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for
        reference, '*_dbu_cost_per_token' used in actual calculation.\"},\n        \"supports_tool_choice\":
        true\n    },\n    \"databricks/databricks-bge-large-en\": {\n        \"max_tokens\":
        512,\n        \"max_input_tokens\": 512,\n        \"output_vector_size\":
        1024, \n        \"input_cost_per_token\": 0.00000010003,\n        \"input_dbu_cost_per_token\":
        0.000001429,\n        \"output_cost_per_token\": 0.0,\n        \"output_dbu_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"databricks\",\n        \"mode\": \"embedding\",\n
        \       \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\"notes\": \"Input/output cost per token is dbu cost
        * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for
        reference, '*_dbu_cost_per_token' used in actual calculation.\"}\n    },\n
        \   \"databricks/databricks-gte-large-en\": {\n        \"max_tokens\": 8192,\n
        \       \"max_input_tokens\": 8192,\n        \"output_vector_size\": 1024,
        \n        \"input_cost_per_token\": 0.00000012999,\n        \"input_dbu_cost_per_token\":
        0.000001857,\n        \"output_cost_per_token\": 0.0,\n        \"output_dbu_cost_per_token\":
        0.0,\n        \"litellm_provider\": \"databricks\",\n        \"mode\": \"embedding\",\n
        \       \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n
        \       \"metadata\": {\"notes\": \"Input/output cost per token is dbu cost
        * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for
        reference, '*_dbu_cost_per_token' used in actual calculation.\"}\n    },\n
        \   \"sambanova/Meta-Llama-3.1-8B-Instruct\": {\n        \"max_tokens\": 16384,\n
        \       \"max_input_tokens\": 16384,\n        \"max_output_tokens\": 16384,
        \n        \"input_cost_per_token\": 0.0000001,\n        \"output_cost_per_token\":
        0.0000002,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n
        \   },\n    \"sambanova/Meta-Llama-3.1-405B-Instruct\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384, \n        \"input_cost_per_token\": 0.000005,\n        \"output_cost_per_token\":
        0.000010,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n
        \   },\n    \"sambanova/Meta-Llama-3.2-1B-Instruct\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384, \n        \"input_cost_per_token\": 0.00000004,\n        \"output_cost_per_token\":
        0.00000008,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n
        \   },\n    \"sambanova/Meta-Llama-3.2-3B-Instruct\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.00000008,\n        \"output_cost_per_token\":
        0.00000016,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n
        \   },\n    \"sambanova/Llama-4-Maverick-17B-128E-Instruct\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072, \n        \"input_cost_per_token\": 0.00000063,\n        \"output_cost_per_token\":
        0.0000018,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_vision\":
        true,\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\",\n
        \       \"metadata\": {\"notes\": \"For vision models, images are converted
        to 6432 input tokens and are billed at that amount\"}\n    },\n    \"sambanova/Llama-4-Scout-17B-16E-Instruct\":
        {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\": 8192,\n        \"max_output_tokens\":
        8192, \n        \"input_cost_per_token\": 0.0000004,\n        \"output_cost_per_token\":
        0.0000007,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_response_schema\": true,\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\",\n
        \       \"metadata\": {\"notes\": \"For vision models, images are converted
        to 6432 input tokens and are billed at that amount\"}\n    },\n    \"sambanova/Meta-Llama-3.3-70B-Instruct\":
        {\n        \"max_tokens\": 131072,\n        \"max_input_tokens\": 131072,\n
        \       \"max_output_tokens\": 131072, \n        \"input_cost_per_token\":
        0.0000006,\n        \"output_cost_per_token\": 0.0000012,\n        \"litellm_provider\":
        \"sambanova\",\n        \"mode\": \"chat\",\n        \"supports_function_calling\":
        true,\n        \"supports_response_schema\": true,\n        \"supports_tool_choice\":
        true,\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n
        \   },\n    \"sambanova/Meta-Llama-Guard-3-8B\": {\n        \"max_tokens\":
        16384,\n        \"max_input_tokens\": 16384,\n        \"max_output_tokens\":
        16384, \n        \"input_cost_per_token\": 0.0000003,\n        \"output_cost_per_token\":
        0.0000003,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n
        \   },\n    \"sambanova/Qwen3-32B\": {\n        \"max_tokens\": 8192,\n        \"max_input_tokens\":
        8192,\n        \"max_output_tokens\": 8192, \n        \"input_cost_per_token\":
        0.0000004,\n        \"output_cost_per_token\": 0.0000008,\n        \"litellm_provider\":
        \"sambanova\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n    },\n
        \   \"sambanova/QwQ-32B\": {\n        \"max_tokens\": 16384,\n        \"max_input_tokens\":
        16384,\n        \"max_output_tokens\": 16384, \n        \"input_cost_per_token\":
        0.0000005,\n        \"output_cost_per_token\": 0.0000010,\n        \"litellm_provider\":
        \"sambanova\",\n        \"mode\": \"chat\",\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n
        \   },\n    \"sambanova/Qwen2-Audio-7B-Instruct\": {\n        \"max_tokens\":
        4096,\n        \"max_input_tokens\": 4096,\n        \"max_output_tokens\":
        4096, \n        \"input_cost_per_token\": 0.0000005,\n        \"output_cost_per_token\":
        0.0001,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\": \"chat\",\n
        \       \"supports_audio_input\": true,\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n
        \   },\n    \"sambanova/DeepSeek-R1-Distill-Llama-70B\": {\n        \"max_tokens\":
        131072,\n        \"max_input_tokens\": 131072,\n        \"max_output_tokens\":
        131072, \n        \"input_cost_per_token\": 0.0000007,\n        \"output_cost_per_token\":
        0.0000014,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n
        \   },\n    \"sambanova/DeepSeek-R1\": {\n        \"max_tokens\": 32768,\n
        \       \"max_input_tokens\": 32768,\n        \"max_output_tokens\": 32768,
        \n        \"input_cost_per_token\": 0.000005,\n        \"output_cost_per_token\":
        0.000007,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\":
        \"chat\",\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n
        \   },\n    \"sambanova/DeepSeek-V3-0324\": {\n        \"max_tokens\": 32768,\n
        \       \"max_input_tokens\": 32768,\n        \"max_output_tokens\": 32768,
        \n        \"input_cost_per_token\": 0.0000030,\n        \"output_cost_per_token\":
        0.0000045,\n        \"litellm_provider\": \"sambanova\",\n        \"mode\":
        \"chat\",\n        \"supports_function_calling\": true,\n        \"supports_tool_choice\":
        true,\n        \"supports_reasoning\": true,\n        \"source\": \"https://cloud.sambanova.ai/plans/pricing\"\n
        \   },\n    \"assemblyai/nano\": {\n        \"mode\": \"audio_transcription\",\n
        \       \"input_cost_per_second\": 0.00010278,\n        \"output_cost_per_second\":
        0.00, \n        \"litellm_provider\": \"assemblyai\"\n    },\n    \"assemblyai/best\":
        {\n        \"mode\": \"audio_transcription\",\n        \"input_cost_per_second\":
        0.00003333,\n        \"output_cost_per_second\": 0.00, \n        \"litellm_provider\":
        \"assemblyai\"\n    },\n    \"jina-reranker-v2-base-multilingual\": {\n        \"max_tokens\":
        1024,\n        \"max_input_tokens\": 1024,\n        \"max_output_tokens\":
        1024,\n        \"max_document_chunks_per_query\": 2048,\n        \"input_cost_per_token\":
        0.000000018,\n        \"output_cost_per_token\": 0.000000018,\n        \"litellm_provider\":
        \"jina_ai\",\n        \"mode\": \"rerank\"\n    },\n    \"snowflake/deepseek-r1\":
        {\n        \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n
        \       \"max_output_tokens\": 8192,\n        \"litellm_provider\": \"snowflake\",\n
        \       \"supports_reasoning\": true,\n        \"mode\": \"chat\"\n    },\n
        \   \"snowflake/snowflake-arctic\": {\n        \"max_tokens\": 4096,\n        \"max_input_tokens\":
        4096,\n        \"max_output_tokens\": 8192,\n        \"litellm_provider\":
        \"snowflake\",\n        \"mode\": \"chat\"\n    },\n    \"snowflake/claude-3-5-sonnet\":
        {\n        \"supports_computer_use\": true,\n        \"max_tokens\": 18000,\n
        \       \"max_input_tokens\": 18000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/mistral-large\": {\n        \"max_tokens\": 32000,\n
        \       \"max_input_tokens\": 32000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/mistral-large2\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/reka-flash\": {\n        \"max_tokens\": 100000,\n
        \       \"max_input_tokens\": 100000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/reka-core\": {\n        \"max_tokens\": 32000,\n        \"max_input_tokens\":
        32000,\n        \"max_output_tokens\": 8192,\n        \"litellm_provider\":
        \"snowflake\",\n        \"mode\": \"chat\"\n    },\n    \"snowflake/jamba-instruct\":
        {\n        \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n
        \       \"max_output_tokens\": 8192,\n        \"litellm_provider\": \"snowflake\",\n
        \       \"mode\": \"chat\"\n    },\n    \"snowflake/jamba-1.5-mini\": {\n
        \       \"max_tokens\": 256000,\n        \"max_input_tokens\": 256000,\n        \"max_output_tokens\":
        8192,\n        \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/jamba-1.5-large\": {\n        \"max_tokens\": 256000,\n
        \       \"max_input_tokens\": 256000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/mixtral-8x7b\": {\n        \"max_tokens\": 32000,\n
        \       \"max_input_tokens\": 32000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/llama2-70b-chat\": {\n        \"max_tokens\": 4096,\n
        \       \"max_input_tokens\": 4096,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/llama3-8b\": {\n        \"max_tokens\": 8000,\n        \"max_input_tokens\":
        8000,\n        \"max_output_tokens\": 8192,\n        \"litellm_provider\":
        \"snowflake\",\n        \"mode\": \"chat\"\n    },\n    \"snowflake/llama3-70b\":
        {\n        \"max_tokens\": 8000,\n        \"max_input_tokens\": 8000,\n        \"max_output_tokens\":
        8192,\n        \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/llama3.1-8b\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/llama3.1-70b\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/llama3.3-70b\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/snowflake-llama-3.3-70b\": {\n        \"max_tokens\":
        8000,\n        \"max_input_tokens\": 8000,\n        \"max_output_tokens\":
        8192,\n        \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/llama3.1-405b\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/snowflake-llama-3.1-405b\": {\n        \"max_tokens\":
        8000,\n        \"max_input_tokens\": 8000,\n        \"max_output_tokens\":
        8192,\n        \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/llama3.2-1b\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/llama3.2-3b\": {\n        \"max_tokens\": 128000,\n
        \       \"max_input_tokens\": 128000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/mistral-7b\": {\n        \"max_tokens\": 32000,\n
        \       \"max_input_tokens\": 32000,\n        \"max_output_tokens\": 8192,\n
        \       \"litellm_provider\": \"snowflake\",\n        \"mode\": \"chat\"\n
        \   },\n    \"snowflake/gemma-7b\": {\n        \"max_tokens\": 8000,\n        \"max_input_tokens\":
        8000,\n        \"max_output_tokens\": 8192,\n        \"litellm_provider\":
        \"snowflake\",\n        \"mode\": \"chat\"\n    },\n    \"nscale/meta-llama/Llama-4-Scout-17B-16E-Instruct\":
        {\n        \"input_cost_per_token\": 9e-8,\n        \"output_cost_per_token\":
        2.9e-7,\n        \"litellm_provider\": \"nscale\",\n        \"mode\": \"chat\",\n
        \       \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\"\n
        \   },\n    \"nscale/Qwen/Qwen2.5-Coder-3B-Instruct\": {\n        \"input_cost_per_token\":
        1e-8,\n        \"output_cost_per_token\": 3e-8,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\"\n
        \   },\n    \"nscale/Qwen/Qwen2.5-Coder-7B-Instruct\": {\n        \"input_cost_per_token\":
        1e-8,\n        \"output_cost_per_token\": 3e-8,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\"\n
        \   },\n    \"nscale/Qwen/Qwen2.5-Coder-32B-Instruct\": {\n        \"input_cost_per_token\":
        6e-8,\n        \"output_cost_per_token\": 2e-7,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\"\n
        \   },\n    \"nscale/Qwen/QwQ-32B\": {\n        \"input_cost_per_token\":
        1.8e-7,\n        \"output_cost_per_token\": 2e-7,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\"\n
        \   },\n    \"nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-70B\": {\n        \"input_cost_per_token\":
        3.75e-7,\n        \"output_cost_per_token\": 3.75e-7,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\",\n
        \       \"metadata\": {\n            \"notes\": \"Pricing listed as $0.75/1M
        tokens total. Assumed 50/50 split for input/output.\"\n        }\n    },\n
        \   \"nscale/deepseek-ai/DeepSeek-R1-Distill-Llama-8B\": {\n        \"input_cost_per_token\":
        2.5e-8,\n        \"output_cost_per_token\": 2.5e-8,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\",\n
        \       \"metadata\": {\n            \"notes\": \"Pricing listed as $0.05/1M
        tokens total. Assumed 50/50 split for input/output.\"\n        }\n    },\n
        \   \"nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\": {\n        \"input_cost_per_token\":
        9e-8,\n        \"output_cost_per_token\": 9e-8,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\",\n
        \       \"metadata\": {\n            \"notes\": \"Pricing listed as $0.18/1M
        tokens total. Assumed 50/50 split for input/output.\"\n        }\n    },\n
        \   \"nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\": {\n        \"input_cost_per_token\":
        2e-7,\n        \"output_cost_per_token\": 2e-7,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\",\n
        \       \"metadata\": {\n            \"notes\": \"Pricing listed as $0.40/1M
        tokens total. Assumed 50/50 split for input/output.\"\n        }\n    },\n
        \   \"nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\": {\n        \"input_cost_per_token\":
        7e-8,\n        \"output_cost_per_token\": 7e-8,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\",\n
        \       \"metadata\": {\n            \"notes\": \"Pricing listed as $0.14/1M
        tokens total. Assumed 50/50 split for input/output.\"\n        }\n    },\n
        \   \"nscale/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\": {\n        \"input_cost_per_token\":
        1.5e-7,\n        \"output_cost_per_token\": 1.5e-7,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\",\n
        \       \"metadata\": {\n            \"notes\": \"Pricing listed as $0.30/1M
        tokens total. Assumed 50/50 split for input/output.\"\n        }\n    },\n
        \   \"nscale/mistralai/mixtral-8x22b-instruct-v0.1\": {\n        \"input_cost_per_token\":
        6e-7,\n        \"output_cost_per_token\": 6e-7,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\",\n
        \       \"metadata\": {\n            \"notes\": \"Pricing listed as $1.20/1M
        tokens total. Assumed 50/50 split for input/output.\"\n        }\n    },\n
        \   \"nscale/meta-llama/Llama-3.1-8B-Instruct\": {\n        \"input_cost_per_token\":
        3e-8,\n        \"output_cost_per_token\": 3e-8,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\",\n
        \       \"metadata\": {\n            \"notes\": \"Pricing listed as $0.06/1M
        tokens total. Assumed 50/50 split for input/output.\"\n        }\n    },\n
        \   \"nscale/meta-llama/Llama-3.3-70B-Instruct\": {\n        \"input_cost_per_token\":
        2e-7,\n        \"output_cost_per_token\": 2e-7,\n        \"litellm_provider\":
        \"nscale\",\n        \"mode\": \"chat\",\n        \"source\": \"https://docs.nscale.com/docs/inference/serverless-models/current#chat-models\",\n
        \       \"metadata\": {\n            \"notes\": \"Pricing listed as $0.40/1M
        tokens total. Assumed 50/50 split for input/output.\"\n        }\n    },\n
        \   \"nscale/black-forest-labs/FLUX.1-schnell\": {\n        \"mode\": \"image_generation\",\n
        \       \"input_cost_per_pixel\": 1.3e-9,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"nscale\",\n        \"supported_endpoints\":
        [\n            \"/v1/images/generations\"\n        ],\n        \"source\":
        \"https://docs.nscale.com/docs/inference/serverless-models/current#image-models\"\n
        \   },\n    \"nscale/stabilityai/stable-diffusion-xl-base-1.0\": {\n        \"mode\":
        \"image_generation\",\n        \"input_cost_per_pixel\": 3e-9,\n        \"output_cost_per_pixel\":
        0.0,\n        \"litellm_provider\": \"nscale\",\n        \"supported_endpoints\":
        [\n            \"/v1/images/generations\"\n        ],\n        \"source\":
        \"https://docs.nscale.com/docs/inference/serverless-models/current#image-models\"\n
        \   },\n    \"featherless_ai/featherless-ai/Qwerky-72B\": {\n        \"max_tokens\":
        32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        4096,\n        \"litellm_provider\": \"featherless_ai\",\n        \"mode\":
        \"chat\"\n    },\n    \"featherless_ai/featherless-ai/Qwerky-QwQ-32B\": {\n
        \       \"max_tokens\": 32768,\n        \"max_input_tokens\": 32768,\n        \"max_output_tokens\":
        4096,\n        \"litellm_provider\": \"featherless_ai\",\n        \"mode\":
        \"chat\"\n    }\n}\n"
    headers: {}
    status:
      code: 200
      message: OK
- request:
    body: '{"model": "claude-3-7-sonnet-20250219", "messages": [{"role": "user", "content":
      [{"type": "text", "text": "Who won the World Cup in 2018? Answer in one word
      with no punctuation."}]}], "thinking": {"type": "enabled", "budget_tokens":
      4000}, "max_tokens": 8096}'
    headers: {}
    method: POST
    uri: https://api.anthropic.com/v1/messages
  response:
    body:
      string: '{"id":"msg_011KX7d4TtALbugymC3Kb4oE","type":"message","role":"assistant","model":"claude-3-7-sonnet-20250219","content":[{"type":"thinking","thinking":"The
        World Cup in 2018 was won by France. They defeated Croatia 4-2 in the final
        match in Moscow, Russia.\n\nI need to answer in one word with no punctuation,
        so my answer should simply be:\nFrance","signature":"ErUBCkYIBBgCIkAOLwDXty2UNgzsRPd4O0tNxqhaxPqqLw9isc2bDqyVS7Y87Cefkib8FVE9iTTjTSynEjrrHb+vei4K5pQrVOUrEgzCGfpi49gURMlFYTwaDGTEJyP22/PoNkje2CIwyiqcZqRj6rxDwzG0ayl3JQ2mi8x3iDIEuyP92Pw19EPRhATbpYiORzbaVoPUBuPEKh3gUYNSZwcjUAYNO01Qqo7GYFF08xO0MuULheotLRgC"},{"type":"text","text":"France"}],"stop_reason":"end_turn","stop_sequence":null,"usage":{"input_tokens":54,"cache_creation_input_tokens":0,"cache_read_input_tokens":0,"output_tokens":65,"service_tier":"standard"}}'
    headers: {}
    status:
      code: 200
      message: OK
version: 1
