{"text": "**Have you ever tried to solve for x using the OpenAI playground?**\n-------------------------------------------------------------------\n\n\nFor example, solve for x:\n\n\n3 x + 4 = 66\n\n\nFirst you'd isolate terms with *x* to the left hand side like so:\n\n\n3 x + (4 - 4) = 66 - 4\n\n\nthen:\n\n\n3 x = 62\n\n\nto get the result:\n\n\nx = 62 / 3\n\n\n\n... simple, right? Unfortunately, you won\u2019t always get the same result from the [Playground](https://beta.openai.com/playground).\n\n\n\n**Our language models currently struggle with math**\n----------------------------------------------------\n\n\nThe models are not yet capable at performing consistently when asked to solve math problems. In other words if you were to try this example in our Playground using text-davinci-002 you will likely get inconsistent answers when performing math. With some generations you will get the correct answer, however we do not recommend you depend on the GPT models for math tasks.\n\n\n\n**What you can do to improve output consistency in our Playground**\n-------------------------------------------------------------------\n\n\n**Disclaimer**: Even implementing everything below there is only so far we can push the current model.\n\n\n1. The GPT models are great at recognizing patterns, but without enough data they\u2019ll try their best to interpret and recreate a pattern that seems most probable. With minimal data it\u2019s likely to produce a wide variety of potential outputs.\n2. A prompt designed like a homework assignment, will generally have clear instructions on the task and expected output, and may include an example task to further establish the expectations around the task and output format. The text-davinci-002 model does best with an instruction, so the request should be presented in a format that starts with an instruction. Without this the model may not understand your expectations and it will be a bit confused.\n\n**Using the \"solve for x where 3x + 4 = 66\" example:**\n------------------------------------------------------\n\n\nTo improve this [prompt](https://beta.openai.com/playground/p/undsPkd4LAdmFC4SILzvnJ6e) we can add the following:\n\n\n1. Start with an instruction like, \u201cGiven the algebraic equation below, solve for the provided variable\u201d, then test to see the results.\n2. Append to the instruction a description of the expected output, \u201cProvide the answer in the format of \u2018x=<insert answer>\u2019\u201c, then test once more\n3. If results are still inconsistent, append an example problem to the instructions. This example will help establish the pattern that you want the model to recognize and follow, \u201cProblem: 3x+4=66, solve for x. <newline> Answer: x=\u201d\n4. The final result will be a [prompt](https://beta.openai.com/playground/p/I4yzqABsUqjQASw6CwM1OftR) that looks like this:\n\n\n```\nGiven the algebraic equation below, solve for the provided variable. Provide the answer in the format of \u2018x=<insert answer>.   \nProblem1: y-1=0, solve for y  \nAnswer1: y=1  \n---  \nProblem2: 3x+4=66, solve for x.  \nAnswer2: x=\n```\n\n\n**Overall recommendation for math problems**\n\n\nWe are aware our currently available models are not yet capable at performing consistently when asked to solve math problems. Consider relying on tools like<https://www.wolframalpha.com/> for now when doing math such as algebraic equations.\n\n", "title": "Doing Math in the Playground", "article_id": "6681258", "url": "https://help.openai.com/en/articles/6681258-doing-math-in-the-playground"}