"""Attribute extractor module for extracting attributes from Bedrock trace data."""

from __future__ import annotations

import json
import logging
from typing import Any, Dict, Optional

from opentelemetry.util.types import AttributeValue

from openinference.instrumentation import (
    Message,
    TokenCount,
    ToolCall,
    ToolCallFunction,
    get_input_attributes,
    get_llm_attributes,
    get_llm_input_message_attributes,
    get_llm_output_message_attributes,
    get_llm_token_count_attributes,
    get_output_attributes,
    get_span_kind_attributes,
    get_tool_attributes,
)
from openinference.instrumentation.bedrock.utils.json_utils import (
    fix_loose_json_string,
    safe_json_loads,
)
from openinference.semconv.trace import (
    DocumentAttributes,
    OpenInferenceSpanKindValues,
    SpanAttributes,
)

logger = logging.getLogger(__name__)


class AttributeExtractor:
    """
    Extracts attributes from Bedrock trace data.

    This class provides methods to extract and process attributes from various types of
    trace data generated by Amazon Bedrock services. It handles different types of inputs
    and outputs, including model invocations, tool calls, knowledge base lookups, and more.
    """

    @classmethod
    def get_messages_object(cls, input_text: str) -> Any:
        """
        Parse input text into a list of Message objects.

        Args:
            input_text (str): The input text to parse.

        Returns:
            list[Message]: A list of parsed Message objects.
        """
        messages = list()
        try:
            input_messages = safe_json_loads(input_text)
            if system_message := input_messages.get("system"):
                messages.append(Message(content=system_message, role="system"))

            for message in input_messages.get("messages", []):
                role = message.get("role", "")
                if content := message.get("content"):
                    parsed_contents = fix_loose_json_string(content) or [content]
                    for parsed_content in parsed_contents:
                        message_content = content
                        if isinstance(parsed_content, dict):
                            if parsed_content_type := parsed_content.get("type"):
                                message_content = parsed_content.get(parsed_content_type, "")
                        messages.append(Message(content=message_content, role=role))
        except Exception:
            return [Message(content=input_text, role="assistant")]
        return messages

    @classmethod
    def get_attributes_from_message(cls, message: Dict[str, Any], role: str) -> Optional[Message]:
        """
        Extract attributes from a message dictionary.

        Args:
            message (dict[str, Any]): The message dictionary.
            role (str): The role of the message.

        Returns:
            Message | None: A Message object if attributes can be extracted, None otherwise.
        """
        if message.get("type") == "text":
            return Message(content=message.get("text", ""), role=role)
        if message.get("type") == "tool_use":
            tool_call_function = ToolCallFunction(
                name=message.get("name", ""), arguments=message.get("input", {})
            )
            tool_calls = [ToolCall(id=message.get("id", ""), function=tool_call_function)]
            return Message(tool_call_id=message.get("id", ""), role="tool", tool_calls=tool_calls)
        return None

    @classmethod
    def get_output_messages(cls, model_output: dict[str, Any]) -> Any:
        """
        Extract output messages from model output.

        Args:
            model_output (dict[str, Any]): The model output dictionary.

        Returns:
            list[Message] | None: A list of Message objects if messages can be extracted,
            None otherwise.
        """
        messages = list()
        if raw_response := model_output.get("rawResponse"):
            if output_text := raw_response.get("content"):
                try:
                    data = json.loads(str(output_text))
                    for content in data.get("content") or []:
                        if message := cls.get_attributes_from_message(
                            content, content.get("role", "assistant")
                        ):
                            messages.append(message)
                except Exception:
                    messages.append(Message(content=str(output_text), role="assistant"))
        return messages

    @classmethod
    def get_attributes_from_model_invocation_input(
        cls, model_invocation_input: dict[str, Any]
    ) -> dict[str, Any]:
        """
        Extract attributes from model invocation input.

        This method processes the model invocation input to extract relevant attributes
        such as the model name, invocation parameters, and input messages. It combines
        these attributes with LLM-specific attributes and span kind attributes.

        Args:
            model_invocation_input (dict[str, Any]): The model invocation input dictionary.

        Returns:
            dict[str, Any]: A dictionary of extracted attributes.
        """
        llm_attributes = {}

        # Get input text
        input_text = ""
        if model_invocation_input and "text" in model_invocation_input:
            input_text = model_invocation_input["text"]

        # Get model name and invocation parameters
        if model_name := AttributeExtractor.get_model_name(model_invocation_input or {}, {}):
            llm_attributes["model_name"] = model_name

        if invocation_parameters := AttributeExtractor.get_invocation_parameters(
            model_invocation_input or {}, {}
        ):
            llm_attributes["invocation_parameters"] = invocation_parameters

        # Get input and output messages
        llm_attributes["input_messages"] = AttributeExtractor.get_messages_object(input_text)

        # Set attributes
        return {
            **get_llm_attributes(**llm_attributes),  # type: ignore
            **get_span_kind_attributes(OpenInferenceSpanKindValues.LLM),
            **get_input_attributes(input_text),
        }

    @classmethod
    def get_attributes_from_model_invocation_output(
        cls, model_invocation_output: dict[str, Any]
    ) -> dict[str, Any]:
        """
        Extract attributes from model invocation output.

        This method processes the model invocation output to extract relevant attributes
        such as the model name, invocation parameters, output messages, and token counts.
        It combines these attributes with LLM-specific attributes and output attributes.

        Args:
            model_invocation_output (dict[str, Any]): The model invocation output dictionary.

        Returns:
            dict[str, Any]: A dictionary of extracted attributes.
        """
        llm_attributes = {}
        if model_name := AttributeExtractor.get_model_name({}, model_invocation_output or {}):
            llm_attributes["model_name"] = model_name

        if invocation_parameters := AttributeExtractor.get_invocation_parameters(
            {}, model_invocation_output or {}
        ):
            llm_attributes["invocation_parameters"] = invocation_parameters

        # Get input and output messages
        llm_attributes["output_messages"] = AttributeExtractor.get_output_messages(
            model_invocation_output or {}
        )

        # Set attributes
        request_attributes = {
            **get_llm_attributes(**llm_attributes),  # type: ignore
            **get_llm_token_count_attributes(
                AttributeExtractor.get_token_counts(model_invocation_output or {})
            ),
        }
        # Set output value
        if output_value := AttributeExtractor.get_output_value(model_invocation_output or {}):
            request_attributes = {**request_attributes, **get_output_attributes(output_value)}
        return request_attributes

    @classmethod
    def get_attributes_from_code_interpreter_input(
        cls, code_input: dict[str, Any]
    ) -> dict[str, Any]:
        """
        Extract attributes from code interpreter input.

        Args:
            code_input (dict[str, Any]): The code interpreter input dictionary.

        Returns:
            dict[str, Any]: A dictionary of extracted attributes.
        """
        tool_call_function = ToolCallFunction(
            name="code_interpreter",
            arguments={"code": code_input.get("code", ""), "files": code_input.get("files", "")},
        )
        tool_calls = [ToolCall(id="default", function=tool_call_function)]
        messages = [Message(tool_call_id="default", role="tool", tool_calls=tool_calls)]
        name = "code_interpreter"
        description = "Executes code and returns results"
        parameters = json.dumps({"code": {"type": "string", "description": "Code to execute"}})
        metadata = json.dumps(
            {
                "invocation_type": "code_execution",
                "execution_context": code_input.get("context", {}),
            }
        )
        return {
            **get_input_attributes(code_input.get("code", "")),
            **get_span_kind_attributes(OpenInferenceSpanKindValues.TOOL),
            **get_llm_input_message_attributes(messages),
            **get_tool_attributes(name=name, description=description, parameters=parameters),
            **{"metadata": metadata},
        }

    @classmethod
    def get_attributes_from_knowledge_base_lookup_input(
        cls, kb_data: dict[str, Any]
    ) -> dict[str, Any]:
        """
        Extract attributes from knowledge base lookup input.

        Args:
            kb_data (dict[str, Any]): The knowledge base lookup input dictionary.

        Returns:
            dict[str, Any]: A dictionary of extracted attributes.
        """
        metadata = {
            "invocation_type": "knowledge_base_lookup",
            "knowledge_base_id": kb_data.get("knowledgeBaseId"),
        }
        return {
            **get_input_attributes(kb_data.get("text", "")),
            **get_span_kind_attributes(OpenInferenceSpanKindValues.RETRIEVER),
            **{"metadata": json.dumps(metadata)},
        }

    @classmethod
    def get_attributes_from_action_group_invocation_input(
        cls, action_input: dict[str, Any]
    ) -> dict[str, Any]:
        """
        Extract attributes from action group invocation input.

        Args:
            action_input (dict[str, Any]): The action group invocation input dictionary.

        Returns:
            dict[str, Any]: A dictionary of extracted attributes.
        """
        name = action_input.get("function", "")
        tool_call_function = ToolCallFunction(
            name=name, arguments=action_input.get("parameters", {})
        )
        tool_calls = [ToolCall(id="default", function=tool_call_function)]
        messages = [Message(tool_call_id="default", role="tool", tool_calls=tool_calls)]
        description = action_input.get("description", "")
        parameters = json.dumps(action_input.get("parameters", []))
        llm_invocation_parameters = {
            "invocation_type": "action_group_invocation",
            "action_group_name": action_input.get("actionGroupName"),
            "execution_type": action_input.get("executionType"),
        }
        if invocation_id := action_input.get("invocationId"):
            llm_invocation_parameters["invocation_id"] = invocation_id
        if verb := action_input.get("verb"):
            llm_invocation_parameters["verb"] = verb
        return {
            **get_span_kind_attributes(OpenInferenceSpanKindValues.TOOL),
            **get_llm_input_message_attributes(messages),
            **get_tool_attributes(name=name, description=description, parameters=parameters),
            **{"metadata": json.dumps(llm_invocation_parameters)},
        }

    @classmethod
    def get_attributes_from_agent_collaborator_invocation_input(
        cls, collaborator_input: dict[str, Any]
    ) -> dict[str, Any]:
        """
        Extract attributes from agent collaborator invocation input.

        Args:
            collaborator_input (dict[str, Any]): The agent collaborator invocation input dictionary.

        Returns:
            dict[str, Any]: A dictionary of extracted attributes.
        """
        input_data = collaborator_input.get("input", {})
        input_type = input_data.get("type", "TEXT")

        # Extract content based on input type
        content = ""
        if input_type == "TEXT":
            content = input_data.get("text", "")
        elif input_type == "RETURN_CONTROL":
            if return_control_results := input_data.get("returnControlResults"):
                content = json.dumps(return_control_results)

        # Create message
        messages = [Message(content=content, role="assistant")]

        # Create metadata
        metadata = {
            "invocation_type": "agent_collaborator_invocation",
            "agent_collaborator_name": collaborator_input.get("agentCollaboratorName"),
            "agent_collaborator_alias_arn": collaborator_input.get("agentCollaboratorAliasArn"),
            "input_type": input_type,
        }

        return {
            **get_span_kind_attributes(OpenInferenceSpanKindValues.AGENT),
            **get_input_attributes(content),
            **get_llm_input_message_attributes(messages),
            **{"metadata": json.dumps(metadata)},
        }

    @classmethod
    def get_attributes_from_code_interpreter_output(
        cls, code_invocation_output: dict[str, Any]
    ) -> Dict[str, AttributeValue]:
        """
        Extract attributes from code interpreter output.

        Args:
            code_invocation_output (dict[str, Any]): The code interpreter output dictionary.

        Returns:
            Dict[str, AttributeValue]: A dictionary of extracted attributes.
        """
        output_value = None
        files = None

        if output_text := code_invocation_output.get("executionOutput"):
            output_value = output_text
        elif execution_error := code_invocation_output.get("executionError"):
            output_value = execution_error
        elif code_invocation_output.get("executionTimeout"):
            output_value = "Execution Timeout Error"
        elif files := code_invocation_output.get("files"):
            output_value = json.dumps(files)

        content = json.dumps(files) if files else str(output_value) if output_value else ""
        messages = [Message(role="tool", content=content)]
        return {
            **get_output_attributes(output_value),
            **get_llm_output_message_attributes(messages),
        }

    @classmethod
    def get_attributes_from_agent_collaborator_invocation_output(
        cls, collaborator_output: dict[str, Any]
    ) -> Dict[str, AttributeValue]:
        """
        Extract attributes from agent collaborator invocation output.

        Args:
            collaborator_output (dict[str, Any]): The agent collaborator invocation
            output dictionary.

        Returns:
            Dict[str, AttributeValue]: A dictionary of extracted attributes.
        """
        output_data = collaborator_output.get("output", {})
        output_type = output_data.get("type", "TEXT")

        # Extract content based on output type
        output_value = ""
        if output_type == "TEXT":
            output_value = output_data.get("text", "")
        elif output_type == "RETURN_CONTROL":
            if return_control_payload := output_data.get("returnControlPayload"):
                output_value = json.dumps(return_control_payload)

        # Create message
        messages = [Message(role="assistant", content=output_value)]

        # Create metadata
        metadata = {
            "agent_collaborator_name": collaborator_output.get("agentCollaboratorName"),
            "agent_collaborator_alias_arn": collaborator_output.get("agentCollaboratorAliasArn"),
            "output_type": output_type,
        }

        return {
            **get_output_attributes(output_value),
            **get_llm_output_message_attributes(messages),
            **{"metadata": json.dumps(metadata)},
        }

    @classmethod
    def get_attributes_from_knowledge_base_lookup_output(
        cls, knowledge_base_lookup_output: dict[str, Any]
    ) -> Dict[str, AttributeValue]:
        """
        Extract attributes from knowledge base lookup output.

        Args:
            knowledge_base_lookup_output (dict[str, Any]): The knowledge base lookup
            output dictionary.

        Returns:
            Dict[str, AttributeValue]: A dictionary of extracted attributes.
        """
        retrieved_refs = knowledge_base_lookup_output.get("retrievedReferences", [])
        attributes = dict()
        for i, ref in enumerate(retrieved_refs):
            base_key = f"{RETRIEVAL_DOCUMENTS}.{i}"
            if document_id := ref.get("metadata", {}).get("x-amz-bedrock-kb-chunk-id", ""):
                attributes[f"{base_key}.{DOCUMENT_ID}"] = document_id

            if document_content := ref.get("content", {}).get("text"):
                attributes[f"{base_key}.{DOCUMENT_CONTENT}"] = document_content

            if document_score := ref.get("score", 0.0):
                attributes[f"{base_key}.{DOCUMENT_SCORE}"] = document_score
            metadata = json.dumps(
                {
                    "location": ref.get("location", {}),
                    "metadata": ref.get("metadata", {}),
                    "type": ref.get("content", {}).get("type"),
                }
            )
            attributes[f"{base_key}.{DOCUMENT_METADATA}"] = metadata
        return attributes

    @classmethod
    def get_event_type(cls, trace_data: dict[str, Any]) -> str:
        """
        Identifies the type of trace event from the provided trace data.

        Args:
            trace_data (dict[str, Any]): The trace data containing information
            about the event.

        Returns:
            str: The identified event type if found, otherwise an empty string.
        """
        trace_events = [
            "preProcessingTrace",
            "orchestrationTrace",
            "postProcessingTrace",
            "failureTrace",
        ]
        for trace_event in trace_events:
            if trace_event in trace_data:
                return trace_event
        return ""

    @classmethod
    def get_attributes_from_invocation_input(
        cls, invocation_input: dict[str, Any]
    ) -> Optional[dict[str, Any]]:
        """
        Extract attributes from invocation input.

        Args:
            invocation_input (dict[str, Any]): The trace data dictionary.

        Returns:
            dict[str, Any] | None: A dictionary of extracted attributes if available,
            None otherwise.
        """
        if "actionGroupInvocationInput" in invocation_input:
            return cls.get_attributes_from_action_group_invocation_input(
                invocation_input["actionGroupInvocationInput"]
            )
        if "codeInterpreterInvocationInput" in invocation_input:
            return cls.get_attributes_from_code_interpreter_input(
                invocation_input["codeInterpreterInvocationInput"]
            )
        if "knowledgeBaseLookupInput" in invocation_input:
            return cls.get_attributes_from_knowledge_base_lookup_input(
                invocation_input["knowledgeBaseLookupInput"]
            )
        if "agentCollaboratorInvocationInput" in invocation_input:
            return cls.get_attributes_from_agent_collaborator_invocation_input(
                invocation_input["agentCollaboratorInvocationInput"]
            )
        return None

    @classmethod
    def get_attributes_from_observation(
        cls, observation: dict[str, Any]
    ) -> Dict[str, AttributeValue]:
        """
        Extract attributes from observation data.

        Args:
            observation (dict[str, Any]): The trace data dictionary.

        Returns:
            Dict[str, AttributeValue]: A dictionary of extracted attributes.
        """
        if "actionGroupInvocationOutput" in observation:
            tool_output = observation["actionGroupInvocationOutput"]
            return get_output_attributes(tool_output.get("text", ""))
        if "codeInterpreterInvocationOutput" in observation:
            return cls.get_attributes_from_code_interpreter_output(
                observation["codeInterpreterInvocationOutput"]
            )
        if "knowledgeBaseLookupOutput" in observation:
            return cls.get_attributes_from_knowledge_base_lookup_output(
                observation["knowledgeBaseLookupOutput"]
            )
        if "agentCollaboratorInvocationOutput" in observation:
            return cls.get_attributes_from_agent_collaborator_invocation_output(
                observation["agentCollaboratorInvocationOutput"]
            )
        return {}

    @classmethod
    def get_model_name(
        cls, input_params: dict[str, Any], output_params: dict[str, Any]
    ) -> str | None:
        """
        Get the model name from input or output parameters.

        Args:
            input_params (dict[str, Any]): The input parameters.
            output_params (dict[str, Any]): The output parameters.

        Returns:
            str | None: The model name if found, None otherwise.
        """
        if model_name := input_params.get("foundationModel"):
            return str(model_name)
        if raw_response := output_params.get("rawResponse"):
            if output_text := raw_response.get("content"):
                try:
                    data = json.loads(str(output_text))
                    model = data.get("model")
                    if model is not None:
                        return str(model)
                except Exception as e:
                    logger.debug(str(e))
        return None

    @classmethod
    def get_invocation_parameters(
        cls, input_params: dict[str, Any], output_params: dict[str, Any]
    ) -> str | None:
        """
        Get the invocation parameters from input or output parameters.

        Args:
            input_params (dict[str, Any]): The input parameters.
            output_params (dict[str, Any]): The output parameters.

        Returns:
            str | None: The invocation parameters as a JSON string if found, None otherwise.
        """
        if inference_configuration := input_params.get("inferenceConfiguration"):
            return json.dumps(inference_configuration)
        if inference_configuration := output_params.get("inferenceConfiguration"):
            return json.dumps(inference_configuration)
        return None

    @classmethod
    def get_token_counts(cls, output_params: dict[str, Any]) -> TokenCount | None:
        """
        Get token counts from output parameters.

        Args:
            output_params (dict[str, Any]): The output parameters.

        Returns:
            TokenCount | None: A TokenCount object if token counts are found, None otherwise.
        """
        if not output_params.get("metadata", {}):
            return None
        if usage := output_params.get("metadata", {}).get("usage"):
            completion, prompt, total = 0, 0, 0

            if input_tokens := usage.get("inputTokens"):
                prompt = input_tokens
            if output_tokens := usage.get("outputTokens"):
                completion = output_tokens
            if (input_tokens := usage.get("inputTokens")) and (
                output_tokens := usage.get("outputTokens")
            ):
                total = input_tokens + output_tokens
            return TokenCount(prompt=prompt, completion=completion, total=total)
        return None

    @classmethod
    def get_output_value(cls, output_params: dict[str, Any]) -> str | None:
        """
        Get the output value from output parameters.

        Args:
            output_params (dict[str, Any]): The output parameters.

        Returns:
            str | None: The output value if found, None otherwise.
        """
        if raw_response := output_params.get("rawResponse"):
            if output_text := raw_response.get("content"):
                return str(output_text)

        parsed_response = output_params.get("parsedResponse", {})
        if output_text := parsed_response.get("text"):
            # This block will be executed for Post Processing trace
            return str(output_text)
        if output_text := parsed_response.get("rationale"):
            # This block will be executed for Pre Processing trace
            return str(output_text)
        return None

    @classmethod
    def get_parent_input_attributes_from_invocation_input(
        cls, invocation_input: Dict[str, Any]
    ) -> Any:
        """
        Extract parent input attributes from invocation input.

        This method extracts input attributes from various types of invocation inputs
        (action group, code interpreter, knowledge base lookup, agent collaborator)
        to be set on the parent span.

        Args:
            invocation_input (dict[str, Any]): The invocation input dictionary.

        Returns:
            Optional[dict[str, AttributeValue]]: A dictionary of input attributes if available,
            None otherwise.
        """
        if action_group := invocation_input.get("actionGroupInvocationInput", {}):
            if input_value := action_group.get("text", ""):
                return get_input_attributes(input_value)

        if code_interpreter := invocation_input.get("codeInterpreterInvocationInput", {}):
            if input_value := code_interpreter.get("code", ""):
                return get_input_attributes(input_value)

        if kb_lookup := invocation_input.get("knowledgeBaseLookupInput", {}):
            if input_value := kb_lookup.get("text", ""):
                return get_input_attributes(input_value)

        if agent_collaborator := invocation_input.get("agentCollaboratorInvocationInput", {}):
            if input_data := agent_collaborator.get("input", {}):
                if input_type := input_data.get("type"):
                    if input_type == "TEXT":
                        if input_value := input_data.get("text", ""):
                            return get_input_attributes(input_value)
                    elif input_type == "RETURN_CONTROL":
                        if return_control_results := input_data.get("returnControlResults"):
                            input_value = json.dumps(return_control_results)
                            return get_input_attributes(input_value)

        return None


# Constants
DOCUMENT_ID = DocumentAttributes.DOCUMENT_ID
DOCUMENT_CONTENT = DocumentAttributes.DOCUMENT_CONTENT
DOCUMENT_SCORE = DocumentAttributes.DOCUMENT_SCORE
DOCUMENT_METADATA = DocumentAttributes.DOCUMENT_METADATA
RETRIEVAL_DOCUMENTS = SpanAttributes.RETRIEVAL_DOCUMENTS
