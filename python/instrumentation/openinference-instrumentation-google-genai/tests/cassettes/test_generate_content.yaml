interactions:
- request:
    body: '{"contents": [{"parts": [{"text": "What''s the weather like?"}], "role":
      "user"}, {"parts": [{"functionCall": {"id": "call_abc123", "args": {"location":
      "San Francisco"}, "name": "get_weather"}}], "role": "model"}, {"parts": [{"functionResponse":
      {"id": "call_abc123", "name": "get_weather", "response": {"location": "San Francisco",
      "temperature": 65, "unit": "fahrenheit", "condition": "foggy", "humidity": "85%"}}}],
      "role": "user"}], "systemInstruction": {"parts": [{"text": "You are a helpful
      assistant that can answer questions and help with tasks."}], "role": "user"},
      "generationConfig": {}}'
    headers: {}
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent
  response:
    body:
      string: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\":
        [\n          {\n            \"text\": \"The weather in San Francisco is foggy
        with 85% humidity. The temperature is 65 degrees Fahrenheit.\\n\"\n          }\n
        \       ],\n        \"role\": \"model\"\n      },\n      \"finishReason\":
        \"STOP\",\n      \"avgLogprobs\": -0.026007329424222309\n    }\n  ],\n  \"usageMetadata\":
        {\n    \"promptTokenCount\": 45,\n    \"candidatesTokenCount\": 24,\n    \"totalTokenCount\":
        69,\n    \"promptTokensDetails\": [\n      {\n        \"modality\": \"TEXT\",\n
        \       \"tokenCount\": 45\n      }\n    ],\n    \"candidatesTokensDetails\":
        [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 24\n
        \     }\n    ]\n  },\n  \"modelVersion\": \"gemini-2.0-flash\"\n}\n"
    headers: {}
    status:
      code: 200
      message: OK
version: 1
