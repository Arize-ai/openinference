[tox]
isolated_build = True
skipsdist = True
envlist =
  py3{9,13}-ci-agno-latest
  py3{9,13}-ci-semconv
  py3{9,13}-ci-instrumentation
  py3{9,13}-ci-{bedrock,bedrock-latest}
  py3{9,13}-ci-{mistralai,mistralai-latest}
  py3{9,13}-ci-{openai,openai-latest}
  py3{9,13}-ci-{openai_agents,openai_agents-latest}
  py3{9,13}-ci-{google_adk,google_adk-latest}
  py3{9,13}-ci-{vertexai,vertexai-latest}
  py3{9,13}-ci-{llama_index,llama_index-latest}
  py3{9,13}-ci-{dspy,dspy-latest}
  py3{9,13}-ci-{langchain,langchain-latest}
  ; py3{9,13}-ci-{guardrails,guardrails-latest}
  py3{10,12}-ci-{crewai,crewai-latest}
  py3{9,13}-ci-{haystack,haystack-latest}
  py3{9,13}-ci-{groq,groq-latest}
  py3{9,13}-ci-{litellm,litellm-latest}
  py3{9,12}-ci-instructor
  py3{9,13}-ci-{anthropic,anthropic-latest}
  py3{10,13}-ci-{smolagents,smolagents-latest}
  py3{9,13}-ci-{autogen,autogen-latest}
  py3{11,13}-ci-{beeai,beeai-latest}
  py3{9,13}-ci-{portkey,portkey-latest}
  py3{9,13}-ci-{google_genai,google_genai-latest}
  py39-mypy-langchain_core
  py3{10,13}-ci-{mcp,mcp-latest}
  py3{10,13}-ci-{autogen_agentchat,autogen_agentchat-latest}
  py3{9,13}-ci-{pydantic_ai,pydantic_ai-latest}
  py3{9,13}-ci-{openllmetry,openllmetry-latest}
  py3{10,13}-ci-{openlit,openlit-latest}


[testenv]
package = wheel
wheel_build_env = .pkg
deps =
  -r dev-requirements.txt
changedir =
  semconv: openinference-semantic-conventions/
  instrumentation: openinference-instrumentation/
  agno: instrumentation/openinference-instrumentation-agno/
  bedrock: instrumentation/openinference-instrumentation-bedrock/
  mistralai: instrumentation/openinference-instrumentation-mistralai/
  openai: instrumentation/openinference-instrumentation-openai/
  openai_agents: instrumentation/openinference-instrumentation-openai-agents/
  google_adk: instrumentation/openinference-instrumentation-google-adk/
  vertexai: instrumentation/openinference-instrumentation-vertexai/
  llama_index: instrumentation/openinference-instrumentation-llama-index/
  dspy: instrumentation/openinference-instrumentation-dspy/
  langchain: instrumentation/openinference-instrumentation-langchain/
  langchain_core: instrumentation/openinference-instrumentation-langchain/src
  guardrails: instrumentation/openinference-instrumentation-guardrails/
  crewai: instrumentation/openinference-instrumentation-crewai/
  haystack: instrumentation/openinference-instrumentation-haystack/
  groq: instrumentation/openinference-instrumentation-groq/
  litellm: instrumentation/openinference-instrumentation-litellm/
  instructor: instrumentation/openinference-instrumentation-instructor/
  anthropic: instrumentation/openinference-instrumentation-anthropic/
  smolagents: instrumentation/openinference-instrumentation-smolagents/
  autogen: instrumentation/openinference-instrumentation-autogen/
  beeai: instrumentation/openinference-instrumentation-beeai/
  portkey: instrumentation/openinference-instrumentation-portkey/
  mcp: instrumentation/openinference-instrumentation-mcp/
  google_genai: instrumentation/openinference-instrumentation-google-genai/
  autogen_agentchat: instrumentation/openinference-instrumentation-autogen-agentchat/
  pydantic_ai: instrumentation/openinference-instrumentation-pydantic-ai/
  openllmetry: instrumentation/openinference-instrumentation-openllmetry/
  openlit: instrumentation/openinference-instrumentation-openlit/

commands_pre =
  agno: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-agno[test]
  agno-latest: uv pip install -U agno
  bedrock: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-bedrock[test]
  bedrock-latest: uv pip install -U boto3 anthropic
  mistralai: uv pip uninstall -r test-requirements.txt
  mistralai: uv pip install --reinstall-package openinference-instrumentation-mistralai .
  mistralai: python -c 'import openinference.instrumentation.mistralai'
  mistralai: uv pip install -r test-requirements.txt
  mistralai-latest: uv pip install -U mistralai
  openai: uv pip uninstall -r test-requirements.txt
  openai: uv pip install --reinstall-package openinference-instrumentation-openai .
  openai: python -c 'import openinference.instrumentation.openai'
  openai: uv pip install -r test-requirements.txt
  openai-latest: uv pip install -U openai
  openai_agents: uv pip uninstall -r test-requirements.txt
  openai_agents: uv pip install --reinstall-package openinference-instrumentation-openai-agents .
  openai_agents: python -c 'import openinference.instrumentation.openai_agents'
  openai_agents: uv pip install -r test-requirements.txt
  openai_agents-latest: uv pip install -U openai_agents
  google_adk: uv pip uninstall -r test-requirements.txt
  google_adk: uv pip install --reinstall-package openinference-instrumentation-google-adk .
  google_adk: python -c 'import openinference.instrumentation.google_adk'
  google_adk: uv pip install -r test-requirements.txt
  google_adk-latest: uv pip install -U google_adk
  vertexai: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-vertexai[test]
  vertexai-latest: uv pip install -U vertexai
  llama_index: uv pip uninstall -r test-requirements.txt
  llama_index: uv pip install --reinstall-package openinference-instrumentation-llama-index .
  llama_index: python -c 'import openinference.instrumentation.llama_index'
  llama_index: uv pip install -r test-requirements.txt
  llama_index-latest: uv pip install -U llama-index llama-index-core llama-index-llms-openai openai llama-index-llms-anthropic anthropic banks
  dspy: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-dspy[test]
  dspy-latest: uv pip install -U dspy-ai
  langchain: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-langchain[test]
  langchain-latest: uv pip install -U langchain langchain_core langchain_anthropic langchain_openai langchain_community
  langchain_core: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-langchain[type-check]
  guardrails: uv pip uninstall -r test-requirements.txt
  guardrails: uv pip install --reinstall-package openinference-instrumentation-guardrails .
  guardrails: python -c 'import openinference.instrumentation.guardrails'
  guardrails: uv pip install -r test-requirements.txt
  guardrails-latest: uv pip install -U 'guardrails-ai<0.5.1'
  crewai: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-crewai[test]
  crewai-latest: uv pip install -U crewai crewai-tools
  haystack: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-haystack[test]
  haystack-latest: uv pip install -U haystack-ai
  groq: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-groq[test]
  groq-latest: uv pip install -U groq
  litellm: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-litellm[test]
  litellm-latest: uv pip install -U --only-binary=tokenizers litellm 'tokenizer<=0.20.3'
  instructor: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-instructor[test]
  instructor-latest: uv pip install -U instructor
  anthropic: uv pip uninstall -r test-requirements.txt
  anthropic: uv pip install --reinstall-package openinference-instrumentation-anthropic .
  anthropic: python -c 'import openinference.instrumentation.anthropic'
  anthropic: uv pip install -r test-requirements.txt
  anthropic-latest: uv pip install -U anthropic
  smolagents: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-smolagents[test]
  autogen: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-autogen[test]
  portkey: uv pip uninstall -r test-requirements.txt
  portkey: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-portkey[test]
  portkey: uv pip install -r test-requirements.txt
  portkey-latest: uv pip install -U portkey_ai
  google_genai: uv pip uninstall -r test-requirements.txt
  google_genai: uv pip install --reinstall-package openinference-instrumentation-google-genai .
  google_genai: python -c 'import openinference.instrumentation.google_genai'
  google_genai: uv pip install -r test-requirements.txt
  google_genai-latest: uv pip install -U google-genai
  autogen_agentchat: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-autogen-agentchat
  autogen_agentchat: uv pip uninstall -r test-requirements.txt
  autogen_agentchat: uv pip install --reinstall-package openinference-instrumentation-autogen-agentchat .
  autogen_agentchat: python -c 'import openinference.instrumentation.autogen_agentchat'
  autogen_agentchat: uv pip install -r test-requirements.txt
  autogen_agentchat-latest: uv pip install -U autogen-agentchat
  uv pip install --reinstall {toxinidir}/openinference-instrumentation # reinstall comes last to ensure it is installed from source
  instrumentation: uv pip install --reinstall {toxinidir}/openinference-instrumentation[test]
  uv pip install --reinstall {toxinidir}/openinference-semantic-conventions  # reinstall comes last to ensure it is installed from source
  beeai: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-beeai[test]
  mcp: uv pip uninstall -r test-requirements.txt
  mcp: uv pip install --reinstall-package openinference-instrumentation-mcp .
  mcp: python -c 'import openinference.instrumentation.mcp'
  mcp: uv pip install -r test-requirements.txt
  mcp-latest: uv pip install -U mcp
  pydantic_ai: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-pydantic-ai[test]
  pydantic_ai-latest: uv pip install -U pydantic-ai
  openllmetry: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-openllmetry[test]
  openllmetry-latest: uv pip install -U opentelemetry-instrumentation-openai
  openlit: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-openlit[test]
  openlit-latest: uv pip install -U openlit

commands =
  ruff: ruff format .
  ruff: ruff check --fix .
  mypy: mypy .
  test: pytest -rfEs -l --nf {posargs:.}
  ci: ruff format --diff .
  ci: ruff check --no-fix .
  ci: mypy .
  ci: pytest -n auto -x -ra {posargs:.}

[testenv:add_symlinks]
description = Add symlinks to packages (for editable install)
changedir = openinference-instrumentation/src/openinference/instrumentation
commands =
  python -c 'from pathlib import Path;[(l.symlink_to(t,True) if not (l:=Path.cwd()/(name := d.name[30:].replace("-","_"))).exists() and (t:=d/"src"/"openinference"/"instrumentation"/name).exists() else None) for d in (Path.cwd().parent.parent.parent.parent/"instrumentation").iterdir() if d.is_dir()]'

[testenv:remove_symlinks]
description = Remove symlinks to packages
changedir = openinference-instrumentation/src/openinference/instrumentation
allowlist_externals = find
commands =
  find . -maxdepth 1 -type l -exec unlink {} \;

[testenv:codegen_anthropic_models_for_bedrock]
description = Generate Anthropic Models for Bedrock Instrumentor
changedir = {toxinidir}/instrumentation/openinference-instrumentation-bedrock/scripts/codegen/anthropic/
setenv =
  OUTPUT = {toxinidir}/instrumentation/openinference-instrumentation-bedrock/src/openinference/instrumentation/bedrock/__generated__/anthropic/_types.py
commands =
  uv pip install -U anthropic pydantic
  uv pip list -v
  python -c "import pathlib; pathlib.Path('{env:OUTPUT}').unlink(missing_ok=True)"
  python json_schema.py anthropic_schema.json
  uv tool run --from datamodel-code-generator datamodel-codegen \
    --input anthropic_schema.json \
    --input-file-type jsonschema \
    --output {env:OUTPUT} \
    --output-model-type dataclasses.dataclass \
    --collapse-root-models \
    --enum-field-as-literal all \
    --target-python-version 3.9 \
    --use-default-kwarg \
    --use-double-quotes \
    --wrap-string-literal \
    --disable-timestamp
  python {env:OUTPUT}
