[tox]
isolated_build = True
skipsdist = True
envlist =
  py3{9,13}-ci-semconv
  py3{9,13}-ci-instrumentation
  py3{9,13}-ci-{bedrock,bedrock-latest}
  py3{9,13}-ci-{mistralai,mistralai-latest}
  py3{9,13}-ci-{openai,openai-latest}
  py3{9,13}-ci-{vertexai,vertexai-latest}
  py3{9,13}-ci-{llama_index,llama_index-latest}
  py3{9,13}-ci-{dspy,dspy-latest}
  py3{9,13}-ci-{langchain,langchain-latest}
  ; py3{9,13}-ci-{guardrails,guardrails-latest}
  py3{10,12}-ci-{crewai,crewai-latest}
  py3{9,13}-ci-{haystack,haystack-latest}
  py3{9,13}-ci-{groq,groq-latest}
  py3{9,13}-ci-{litellm,litellm-latest}
  ; py3{9,13}-ci-instructor
  py3{9,13}-ci-{anthropic,anthropic-latest}
  py3{10,13}-ci-{smolagents,smolagents-latest}
  py3{9,13}-ci-{autogen,autogen-latest}
  py39-mypy-langchain_core

[testenv]
package = wheel
wheel_build_env = .pkg
deps =
  -r dev-requirements.txt
changedir =
  semconv: openinference-semantic-conventions/
  instrumentation: openinference-instrumentation/
  bedrock: instrumentation/openinference-instrumentation-bedrock/
  mistralai: instrumentation/openinference-instrumentation-mistralai/
  openai: instrumentation/openinference-instrumentation-openai/
  vertexai: instrumentation/openinference-instrumentation-vertexai/
  llama_index: instrumentation/openinference-instrumentation-llama-index/
  dspy: instrumentation/openinference-instrumentation-dspy/
  langchain: instrumentation/openinference-instrumentation-langchain/
  langchain_core: instrumentation/openinference-instrumentation-langchain/src
  guardrails: instrumentation/openinference-instrumentation-guardrails/
  crewai: instrumentation/openinference-instrumentation-crewai/
  haystack: instrumentation/openinference-instrumentation-haystack/
  groq: instrumentation/openinference-instrumentation-groq/
  litellm: instrumentation/openinference-instrumentation-litellm/
  instructor: instrumentation/openinference-instrumentation-instructor/
  anthropic: instrumentation/openinference-instrumentation-anthropic/
  smolagents: instrumentation/openinference-instrumentation-smolagents/
  autogen: instrumentation/openinference-instrumentation-autogen/
commands_pre =
  instrumentation: uv pip install --reinstall {toxinidir}/openinference-instrumentation[test]
  semconv: uv pip install --reinstall {toxinidir}/openinference-semantic-conventions
  bedrock: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-bedrock[test]
  bedrock-latest: uv pip install -U boto3 anthropic
  mistralai: uv pip uninstall -r test-requirements.txt
  mistralai: uv pip install --reinstall-package openinference-instrumentation-mistralai .
  mistralai: python -c 'import openinference.instrumentation.mistralai'
  mistralai: uv pip install -r test-requirements.txt
  mistralai-latest: uv pip install -U mistralai
  openai: uv pip uninstall -r test-requirements.txt
  openai: uv pip install --reinstall-package openinference-instrumentation-openai .
  openai: python -c 'import openinference.instrumentation.openai'
  openai: uv pip install -r test-requirements.txt
  openai-latest: uv pip install -U openai
  vertexai: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-vertexai[test]
  vertexai-latest: uv pip install -U vertexai
  llama_index: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-llama-index[test]
  llama_index-latest: uv pip install -U llama-index llama-index-core llama-index-llms-openai openai llama-index-llms-anthropic anthropic
  dspy: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-dspy[test]
  dspy-latest: uv pip install -U dspy-ai
  langchain: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-langchain[test]
  langchain-latest: uv pip install -U langchain langchain_core langchain_anthropic langchain_openai langchain_community
  langchain_core: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-langchain[type-check]
  guardrails: uv pip uninstall -r test-requirements.txt
  guardrails: uv pip install --reinstall-package openinference-instrumentation-guardrails .
  guardrails: python -c 'import openinference.instrumentation.guardrails'
  guardrails: uv pip install -r test-requirements.txt
  guardrails-latest: uv pip install -U 'guardrails-ai<0.5.1'
  crewai: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-crewai[test]
  crewai-latest: uv pip install -U crewai crewai-tools
  haystack: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-haystack[test]
  haystack-latest: uv pip install -U haystack-ai
  groq: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-groq[test]
  groq-latest: uv pip install -U groq
  litellm: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-litellm[test]
  litellm-latest: uv pip install -U --only-binary=tokenizers litellm 'tokenizer<=0.20.3'
  ; instructor: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-instructor[test]
  ; instructor-latest: uv pip install -U instructor
  anthropic: uv pip uninstall -r test-requirements.txt
  anthropic: uv pip install --reinstall-package openinference-instrumentation-anthropic .
  anthropic: python -c 'import openinference.instrumentation.anthropic'
  anthropic: uv pip install -r test-requirements.txt
  anthropic-latest: uv pip install -U anthropic
  smolagents: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-smolagents[test]
  autogen: uv pip install --reinstall {toxinidir}/instrumentation/openinference-instrumentation-autogen[test]
commands =
  ruff: ruff format {posargs:.}
  ruff: ruff check --fix {posargs:.}
  mypy: mypy {posargs:.}
  test: pytest -rfEs -l --nf {posargs:.}
  ci: ruff format --diff .
  ci: ruff check --no-fix .
  ci: mypy .
  ci: pytest -n auto -x -ra {posargs:.}

[testenv:add_symlinks]
description = Add symlinks to packages (for editable install)
changedir = openinference-instrumentation/src/openinference/instrumentation
commands =
  python -c 'from pathlib import Path;[(l.symlink_to(t,True) if not (l:=Path.cwd()/(name := d.name[30:].replace("-","_"))).exists() and (t:=d/"src"/"openinference"/"instrumentation"/name).exists() else None) for d in (Path.cwd().parent.parent.parent.parent/"instrumentation").iterdir() if d.is_dir()]'

[testenv:remove_symlinks]
description = Remove symlinks to packages
changedir = openinference-instrumentation/src/openinference/instrumentation
allowlist_externals = find
commands =
  find . -maxdepth 1 -type l -exec unlink {} \;

[testenv:codegen_anthropic_models_for_bedrock]
description = Generate Anthropic Models for Bedrock Instrumentor
changedir = {toxinidir}/instrumentation/openinference-instrumentation-bedrock/scripts/codegen/anthropic/
setenv =
  OUTPUT = {toxinidir}/instrumentation/openinference-instrumentation-bedrock/src/openinference/instrumentation/bedrock/__generated__/anthropic/_types.py
commands =
  uv pip install -U anthropic pydantic
  uv pip list -v
  python -c "import pathlib; pathlib.Path('{env:OUTPUT}').unlink(missing_ok=True)"
  python json_schema.py anthropic_schema.json
  uv tool run --from datamodel-code-generator datamodel-codegen \
    --input anthropic_schema.json \
    --input-file-type jsonschema \
    --output {env:OUTPUT} \
    --output-model-type dataclasses.dataclass \
    --collapse-root-models \
    --enum-field-as-literal all \
    --target-python-version 3.9 \
    --use-default-kwarg \
    --use-double-quotes \
    --wrap-string-literal \
    --disable-timestamp
  python {env:OUTPUT}
