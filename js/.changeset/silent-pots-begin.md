---
"@arizeai/openinference-semantic-conventions": patch
---

add semantic conventions to capture details in llm token counts: cached and reasoning
