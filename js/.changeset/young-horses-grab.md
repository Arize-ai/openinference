---
"@arizeai/openinference-vercel": patch
---

caputre input and output for tools, fix double count of tokens on llm spans / chains
