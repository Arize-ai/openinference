---
"@arizeai/openinference-semantic-conventions": patch
---

Add llm.token_count.prompt_details.cache_input semantic convention
